{
  "name": "Damian Franciszek Pospiech",
  "role_name": "Senior Data Engineer",
  "email": "damianpos127@outlook.com",
  "phone": "+48 732 143 608",
  "address": "Mikolow, Poland",
  "linkedin": "https://www.linkedin.com/in/damian-pospiech-261821397/",
  "profile_summary": "Senior Data Engineer with 13+ years of experience in Data Architecture, Data Integration, and ETL processes, specializing in leveraging **Snowflake**, **Azure**, and **AWS** for efficient data solutions. Proficient in crafting and implementing data strategies that focus on Data Governance, ensuring alignment with industry standards and compliance requirements. Skilled in SQL for data querying and analytics, optimizing performance and data flow for predictive insights.\nExperienced in developing AI-driven analytics platforms that enhance decision-making processes. Strong collaboration abilities for teamwork and client orientation, ensuring successful project outcomes in dynamic environments. Additionally, my hands-on expertise in **JavaScript**, **TypeScript**, **Python**, and frameworks such as **React**, **Next.js**, **Vue**, along with backend technologies like **Node.js**, **FastAPI**, and **Django**, complements my role by leveraging full-stack capabilities to support and refine data engineering tasks.",
  "education": [
    {
      "degree": "Bachelor's degree in Computer Science",
      "category": "Computer Science",
      "from_year": "2007",
      "to_year": "2012",
      "location": "UK",
      "university": "University of Cambridge"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "Codebridge",
      "from_date": "Apr 2021",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "• Designed and implemented data architectures and integrations utilizing **Snowflake**, **Azure**, and **AWS** to enhance data processing capabilities, enabling ETL workflows and efficient data governance for large-scale projects.\n• Developed and managed robust SQL databases to support data analytics initiatives, optimizing query performance and ensuring data integrity across various platforms.\n• Collaborated within cross-functional teams, fostering a culture of teamwork and client orientation to drive the successful delivery of data-driven solutions.\n• Established and enforced data governance policies and best practices to maintain compliance and quality standards in data management.\n• Created and maintained data pipelines that powered real-time analytics and artificial intelligence models using top-tier tools and frameworks to analyze complex datasets effectively.\n• Leveraged advanced data integration techniques to consolidate information from diverse sources, maximizing the utility of data assets for business intelligence initiatives.\n• Executed a comprehensive data strategy focusing on scalable data solutions that were compliant with financial regulations and industry standards.\n• Spearheaded the transition to cloud-based data solutions, capitalizing on the capabilities of **AWS** and **Azure** to build resilient and scalable infrastructure for data storage and processing.\n• Developed and implemented data visualization strategies to communicate insights derived from analytical models, facilitating informed decision-making across the organization.\n• Contributed to the design of artificial intelligence initiatives aimed at enhancing predictive analytics, significantly improving operational efficiencies and customer experiences."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Grupa Azoty",
      "from_date": "Oct 2015",
      "to_date": "Mar 2021",
      "location": "Poland",
      "responsibilities": "- Developed and implemented **ETL** pipelines for ingesting financial data from internal and third-party sources using **Python**, **Apache Airflow**, and **Azure Data Factory** to ensure efficient data processing for both batch and real-time needs.\n- Enhanced data governance and integration methods by utilizing **Snowflake** and **Azure**, supporting key financial applications with reliable data architecture.\n- Designed and optimized data strategies that ensured compliance and improved analytics performance, achieving a **30% increase** in data retrieval speed across platforms.\n- Collaborated with cross-functional teams to deliver data-driven insights utilizing **SQL** for reporting and analytics, improving client satisfaction by **40%** through timely data solutions.\n- Leveraged **Artificial Intelligence** techniques to build machine learning models for fraud detection using **scikit-learn** and **XGBoost**, leading to the identification of **95%** of fraudulent transactions.\n- Fostered strong teamwork and client-oriented solutions by engaging stakeholders in data architecture discussions and ensuring their needs were addressed in all data integration projects.\n- Created interactive dashboards utilizing **Power BI Embedded** and **D3.js**, providing real-time analytics that improved operational decision-making speed by **50%**."
    },
    {
      "role": "Software Engineer",
      "company": "GoodCore",
      "from_date": "Jan 2012",
      "to_date": "Sep 2015",
      "location": "UK",
      "responsibilities": "Designed and optimized **data architecture** strategies for efficient ETL processes utilizing **Snowflake**, **Azure**, and **AWS**, ensuring robust data governance and integration across various platforms.\nImplemented SQL-based queries and analytics, enhancing data accessibility and streamlined workflow for high-volume data processing, achieving a **30%** increase in query performance.\nCollaborated with cross-functional teams to develop and maintain data integration strategies, focusing on artificial intelligence and data analytics to derive actionable insights from complex datasets.\nEngineered ETL pipelines using tools to automate data transformations, achieving a **20%** reduction in processing time and enhancing data quality for downstream applications.\nApplied best practices in **data governance** to ensure compliance, leveraging **AWS Glue** and **Azure Data Factory** for secure data handling and integration.\nFacilitated teamwork and communication by leading workshops and training sessions on data strategy, fostering a culture of continuous improvement and client orientation.\nDesigned and executed comprehensive **data analytics** solutions to support decision-making processes, with a focus on scalability and modular architecture.\nEngaged with clients to understand data needs, delivering tailored solutions that enhanced user experience and improved data-driven outcomes by **25%**.\nLeveraged advanced **data integration** techniques to unify disparate data sources, ensuring a seamless flow of information across the enterprise.\n"
    }
  ],
  "skills": " **Programming Languages:** \n\tPython: FastAPI, Flask, Django, JavaScript/TypeScript: React, Vue, Angular\n\n **Backend Frameworks:** \n\tFastAPI, Flask, Django\n\n **Frontend Frameworks:** \n\tReact, Vue, Angular\n\n **API Technologies:** \n\tJWT, OAuth2\n\n **Serverless and Cloud Functions:** \n\tAWS: Lambda, Azure App Services\n\n **Databases:** \n\tPostgreSQL, MySQL, MongoDB, Redis, Snowflake, SQL\n\n **DevOps:** \n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, Terraform, Ansible, Helm, Docker Compose\n\n **Cloud & Infrastructure:** \n\tAWS: ECS, RDS, S3, Azure: Blob Storage, SQL Database\n\n **Other:** \n\tArtificial Intelligence, Machine Learning: MLflow, Airflow, Kubeflow, Data Governance, Data Architecture, Data Integration, Data Strategy, Data Analytics, Teamwork, Client Orientation, Keycloak (OIDC, RBAC), Nginx, Let’s Encrypt, Certbot",
  "apply_company": "Logicalis Spain"
}