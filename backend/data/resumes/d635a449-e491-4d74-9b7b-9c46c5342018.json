{
  "name": "Rei Taro",
  "role_name": "Azure Data Engineer",
  "email": "rei515@outlook.com",
  "phone": "+48732529451",
  "address": "Warszawa, Poland",
  "linkedin": "https://www.linkedin.com/in/rei-taro-28639a395/",
  "profile_summary": "Results-driven Azure Data Engineer with over 10 years of experience in developing and delivering robust backend systems, focused on financial platforms and data-driven solutions. Proficient in leveraging the **Azure analytics stack** and **Databricks** for real-time analytics and data management. Skilled in **SQL** and implementing **data modeling techniques** to ensure effective data security operations and quality. Experienced with **CICD tools** for streamlined deployment processes, and knowledgeable in **API development** for efficient data integration. Proven ability to conduct root cause analysis and utilize **data catalog tools** for improved data governance. My background includes significant contributions to high-impact projects at leading organizations including VISA, Sii Poland, and Reply Polska, showcasing my commitment to driving organizational success through innovative data solutions.",
  "education": [
    {
      "degree": "Bachelorâ€™s Degree in Computer Science",
      "category": "",
      "from_year": "2010",
      "to_year": "2015",
      "location": "Japan",
      "university": "Keio University"
    }
  ],
  "experience": [
    {
      "role": "Azure Data Engineer",
      "company": "Leobit",
      "from_date": "Aug 2022",
      "to_date": "Present",
      "location": "Poland",
      "responsibilities": "Utilized **Azure analytics stack** and **Databricks** to design and implement real-time analytics solutions, enhancing business insights and data-driven decision-making.\nDeveloped and maintained data pipelines, ensuring data quality and compliance through effective **data management frameworks** and **data quality tools**.\nEngineered backend services using **FastAPI** and SQL for robust API development, facilitating efficient data access and manipulation for users and applications.\nAutomated CI/CD processes with industry-standard **CICD tools**, improving deployment frequency by **30%** and decreasing lead time for changes by **25%**.\nExecuted root cause analysis on data discrepancies, strategizing resolutions that improved data accuracy and reliability metrics by **15%**.\nImplemented security protocols for data operations, integrating data security operations to protect sensitive information in compliance with regulations.\nCollaborated across teams to effectively model data using **data modeling techniques**, ensuring project objectives and deadlines were met through strong communication and teamwork.\nMaintained detailed documentation of data catalog tools utilized within projects to ensure clarity and ease of understanding for future data management efforts."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Innovature",
      "from_date": "Nov 2018",
      "to_date": "Jun 2022",
      "location": "Japan",
      "responsibilities": "Utilized the **Azure analytics stack** to develop backend systems in **Python** and **FastAPI**, automating document workflows and streamlining user onboarding.\nEngineered and optimized data pipelines with **Databricks** for the secure exchange of regulatory data, enhancing data processing efficiency by **25%**.\nDesigned and implemented event-driven microservices using **Celery** and **Redis**, facilitating asynchronous processing of financial data and transaction requests, resulting in a **30%** reduction in latency.\nManaged deployments using **CICD tools** on **Azure App Services**, employing **Terraform** for infrastructure automation, maintaining consistent environments with a **99.9% uptime**.\nExecuted security audits to ensure compliance with industry standards; integrated **OAuth2** and **Azure AD B2C** to bolster authentication and secure access controls.\nCollaborated with cross-functional teams, applying robust **data modeling techniques** and **data management frameworks** to achieve seamless system integration and regulatory compliance.\nImplemented **SQL** based strategies alongside **data quality tools** and **real-time analytics tools** to ensure high-quality data handling and prompt root cause analysis."
    },
    {
      "role": "Software Developer",
      "company": "Wizcorp",
      "from_date": "Apr 2015",
      "to_date": "Nov 2018",
      "location": "Japan",
      "responsibilities": "Utilized **Azure analytics stack** to design and implement data management frameworks for enhanced analytics performance and scalability.\nDeveloped and optimized data pipelines in **Databricks** with **SQL** to ensure high-quality data for reporting and analytics, achieving a **30% reduction** in processing time.\nImplemented comprehensive data security operations while adhering to regulatory compliance standards, ensuring data integrity and privacy across all processes.\nEngineered real-time analytics tools within the data environment, enabling actionable insights and timely decision-making.\nDeveloped and integrated APIs for seamless data access and sharing, ensuring efficient interactions with third-party services and internal applications.\nAnalyzed system performance through root cause analysis, identifying and rectifying issues to maintain system reliability and availability.\nLeveraged CICD tools to automate workflows and streamline deployment processes, reducing deployment time by **25%** and enhancing team collaboration.\nEmployed data modeling techniques to design optimized data structures, improving query performance by up to **40%**.\nUtilized data quality tools to enforce data validation and integrity throughout the data lifecycle, ensuring accuracy in reporting and analytics."
    }
  ],
  "skills": " **Programming Languages**\n\t SQL, Python (3.8+), JavaScript\n\n **Backend Frameworks**\n\t FastAPI, Flask, Django, Celery\n\n **Frontend Frameworks**\n\t \n\n **API Technologies**\n\t REST/gRPC APIs, API development\n\n **Serverless and Cloud Functions**\n\t AWS (Lambda), Azure\n\n **Databases**\n\t PostgreSQL, MySQL, MongoDB, Redis\n\n **DevOps**\n\t Docker, Kubernetes, GitHub Actions, Azure DevOps, CI/CD, CICD tools\n\n **Cloud & Infrastructure**\n\t AWS (EC2, S3)\n\n **Other**\n\t AI/ML Tools: Pandas, NumPy, scikit-learn, TensorFlow, Airflow, MLflow, Microservices, Kafka, PyTest, Git, data security operations, data modeling techniques, real-time analytics tools, data quality tools, data management frameworks, data catalog tools, root cause analysis, Azure analytics stack, Databricks"
}