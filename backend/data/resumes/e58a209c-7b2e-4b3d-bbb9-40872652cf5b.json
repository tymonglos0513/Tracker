{
  "name": "Marcin Karol Kotlinski",
  "role_name": "Senior Analytics Engineer",
  "email": "marcinkot55@outlook.com",
  "phone": "+48 732 779 243",
  "address": "Zgorzelec, Poland",
  "linkedin": "https://www.linkedin.com/in/marcin-k-152840397/",
  "profile_summary": "Results-driven Senior Analytics Engineer with 8 years of comprehensive experience in data visualization, dashboard design, and workflow automation. Proficient in **SQL**, **dbt**, **Airflow**, **Azure Data Factory**, **Snowflake**, **BigQuery**, **Looker**, **Power BI**, and KPI frameworks, I excel at creating high-performance analytical solutions tailored to the healthcare and financial sectors. \nSkilled in **Python** and **R**, I leverage advanced analytics techniques to derive actionable insights and enhance decision-making processes through effective data storytelling. My technical expertise is further complemented by experience in **Talend**, **n8n**, and **Make** for seamless workflow automation. \nBeyond analytics, I possess a robust foundation in full-stack development utilizing **React**, **Next.js**, **Vue**, **Node.js**, **FastAPI**, and **Django**, along with cloud solutions on **Azure** and **AWS**. My previous roles involved leading teams in the development of enterprise-grade platforms that integrate AI/ML capabilities, focusing on compliance standards such as HIPAA, FHIR, PCI DSS, and SOC 2.",
  "education": [
    {
      "degree": "Master’s Degree in Computer Science",
      "category": "",
      "from_year": "2017",
      "to_year": "2018",
      "location": "UK",
      "university": "University of Oxford"
    },
    {
      "degree": "Bachelor’s Degree in Computer Science",
      "category": "",
      "from_year": "2015",
      "to_year": "2017",
      "location": "UK",
      "university": "University of Oxford"
    }
  ],
  "experience": [
    {
      "role": "Senior Analytics Engineer",
      "company": "EVNE Developers",
      "from_date": "Oct 2023",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "Utilized **SQL** and **Python** to design and maintain data pipelines, ensuring efficient data ingestion and transformation processes for analytical tasks, optimizing performance by **30%** for data retrieval.\nEmployed **dbt** for data modeling and transformation in **Snowflake** and **BigQuery**, leading to improved query performance and reduced costs by **15%** across multiple projects.\nDeveloped and automated data workflows using **Apache Airflow**, integrating with **Azure Data Factory** for seamless data movement and orchestration, achieving an automated workflow success rate of **98%**.\nCreated interactive dashboards and data visualization tools using **Power BI** and **Looker**, facilitating real-time insights and enhancing reporting efficiency for KPIs by **25%**.\nCollaborated with cross-functional teams to implement **KPI frameworks**, ensuring alignment with business objectives, adding value through data-informed decision making.\nDesigned and implemented workflow automation solutions using **n8n** and **Talend**, streamlining repetitive tasks and saving an estimated **10 hours** per week in manual effort.\nDelivered complex analytical solutions by integrating **R** scripts for advanced statistical analysis, enriching data insights and enhancing predictive analytics capabilities.\nDeveloped custom dashboards for dynamic reporting and visualization, leading to more efficient decision-making for stakeholders, enhancing business intelligence metrics by **20%**.\nFacilitated training sessions for team members on best practices in data visualization and dashboard design, contributing to a **40%** increase in team productivity related to data reporting tasks.\nLeveraged advanced analytics to identify trends and patterns, significantly enhancing the overall analytical strategy within the organization."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Air Force",
      "from_date": "Oct 2021",
      "to_date": "Sep 2023",
      "location": "Poland",
      "responsibilities": "Utilized **SQL** and **dbt** to optimize data models and ensure clean, accurate data reporting for analytics projects, enhancing data reliability and accessibility for stakeholders.\nDeveloped and maintained ETL workflows in **Apache Airflow** and **Azure Data Factory**, facilitating seamless data integration from varied sources, with a focus on high data quality across **Snowflake** and **BigQuery**.\nCreated interactive dashboards in **Looker** and **Power BI**, providing real-time data visualization to track key performance indicators (KPIs) and support data-driven decision-making for the organization.\nImplemented workflow automation using **n8n** and **Make**, streamlining repetitive processes which decreased manual effort by **30%**, improving efficiency in data handling.\nDesigned and deployed comprehensive data visualization strategies, including KPI frameworks, to ensure critical insights are easily accessible and understandable to non-technical users, enhancing overall business intelligence.\nLeveraged **Python** and **R** for data analysis, employing statistical methods and machine learning techniques to derive actionable insights, leading to a **25%** increase in data accuracy.\nParticipated in the development of data governance policies that ensured compliance and sustainability in analytics practices, resulting in enhanced operational transparency and stakeholder trust."
    },
    {
      "role": "Software Engineer",
      "company": "DeepInspire",
      "from_date": "Sep 2018",
      "to_date": "Aug 2021",
      "location": "UK",
      "responsibilities": "Developed and optimized data pipelines using **Python** and **Airflow** to ensure efficient ETL processes, yielding a data processing speed increase of **40%** and a reduction in data latency.\nLeveraged **SQL**, **Snowflake**, and **BigQuery** to implement scalable data warehousing solutions, achieving data retrieval times of less than **5 seconds** for large data sets.\nDesigned and implemented interactive dashboards with **Power BI** and **Looker**, delivering real-time KPI tracking and ensuring end-users can visualize data effectively with a **25%** increase in engagement.\nUtilized **dbt** for data transformation, enhancing model performance and ensuring maintainable code with **0 bugs** reported during quarterly audits.\nAutomated repetitive tasks and workflows using **Talend**, **n8n**, and **Make**, reducing manual effort by **50%** and streamlining operations across various departments.\nEngineered insightful data visualizations adhering to best practices in **data visualization** and **dashboard design**, directly impacting decision-making speed and accuracy.\nCollaborated with cross-functional teams to define and monitor key performance indicators (KPIs), established frameworks for data governance, and ensured alignment with business objectives.\nImplemented data compliance measures and security protocols while managing access controls to guarantee GDPR compliance and user data protection throughout analytics processes."
    }
  ],
  "skills": " **Programming Languages:**\n\tPython, R\n\n **Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n **Frontend Frameworks:**\n\tJavaScript/TypeScript (React, Vue, Angular)\n\n **API Technologies:**\n\tKeycloak (OIDC, RBAC), JWT, OAuth2\n\n **Serverless and Cloud Functions:**\n\tAWS (Lambda), Azure (App Services)\n\n **Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare), MongoDB (Gaming), Redis, SQL, Snowflake, BigQuery\n\n **Data Tools:**\n\tdbt, Talend, Looker, Power BI\n\n **Data Workflow & Automation:**\n\tAirflow, Azure Data Factory, workflow automation, n8n, Make\n\n **DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, Terraform, Ansible, Helm, Docker Compose\n\n **Cloud & Infrastructure:**\n\tAWS (ECS, RDS, S3), Azure (Blob, SQL)\n\n **Other:**\n\tMLflow, Kubeflow, KPI frameworks, data visualization, dashboard design, Let’s Encrypt, Nginx, Certbot",
  "apply_company": "Contabo"
}