{
  "name": "Mariusz Jan Skobel",
  "role_name": "Senior Data Engineer",
  "email": "mariuszskobel15@outlook.com",
  "phone": "+48 735 343 548",
  "address": "Katowice, Poland",
  "linkedin": "https://www.linkedin.com/in/mariusz-skobel-927764397/",
  "profile_summary": "Senior Data Engineer with 10+ years of experience in Big Data solutions and cloud-native application development. Expertise in **Postgres**, **MongoDB**, **Kafka**, **Spark**, and **Docker** for robust data processing and scalable architecture. Strong knowledge of **JavaScript**, **TypeScript**, and AI integrations for enhancing data-driven decision-making. Proven ability to design and implement high-performance APIs and adhere to clean coding principles and testing methodologies.\n<br>Demonstrated success in remote collaboration and feedback-driven environments, focusing on building secure, maintainable solutions that adhere to compliance standards. Passionate about utilizing technology to create impactful data solutions and enhance operational efficiency.",
  "education": [
    {
      "degree": "Bachelor’s Degree",
      "category": "Computer Science",
      "from_year": "2012",
      "to_year": "2015",
      "location": "UK",
      "university": "University of Bristol"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "EitBiz",
      "from_date": "Oct 2022",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "• Utilized **PostgreSQL**, **MongoDB**, and **Redis** for optimizing big data storage, ingestion, and querying processes, successfully handling over **1 million** records for healthcare and financial applications.\n• Developed data processing pipelines using **Kafka** to facilitate efficient data flow and integration across microservices, ensuring real-time data accessibility and reliability.\n• Leveraged advanced AI techniques to enhance data analytic functions, incorporating machine learning models for predictive analytics in healthcare and finance, resulting in a **25%** improvement in prediction accuracy.\n• Engineered scalable data architectures using **Docker** and orchestrated containerization with **Kubernetes** (AKS/EKS), improving deployment efficiency by **40%** and reducing operational costs.\n• Collaborated remotely with cross-functional teams in an agile environment to design and deliver robust data solutions, receiving positive feedback for clean code practices and efficient collaboration strategies.\n• Established testing frameworks using **JUnit**, **Pytest**, and **Postman** for rigorous validation of data processes, achieving over **95%** code coverage across back-end services.\n• Conducted effective code reviews and integrated feedback mechanisms to uphold high-quality data engineering standards, leading to increased team productivity and code maintainability.\n• Designed data layer APIs using **JavaScript** and **TypeScript**, facilitating seamless interaction between front-end applications and back-end data services, ultimately enhancing user experience and application performance."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Tvn S.A.",
      "from_date": "Oct 2019",
      "to_date": "Sep 2022",
      "location": "Poland",
      "responsibilities": "• Leveraged **BigData** technologies to optimize data processing workflows, improving performance by **30%** in financial data ingestion and analysis.\n• Engineered and maintained data pipelines using **Kafka** and **Apache Spark**, ensuring efficient data streaming and transformation for real-time analytics in financial modeling.\n• Developed and optimized database solutions leveraging **Postgres**, **MongoDB**, and **Redis** to enhance data retrieval speeds by **25%**, supporting high-availability requirements of financial applications.\n• Implemented RESTful and event-driven APIs to integrate data services, ensuring seamless communication between microservices and reducing time-to-market for new features by **15%**.\n• Designed and deployed containerized applications using **Docker**, streamlining development and deployment processes across various environments.\n• Collaborated with cross-functional teams in a **remote** setting, fostering a culture of **clean code** principles and practices to enhance team productivity and code maintainability.\n• Championed testing strategies and conducted performance evaluations, enhancing software reliability by identifying bugs and optimizing code through continual feedback.\n• Utilized AI techniques to implement machine learning models for predictive analytics in transaction processing, improving anomaly detection accuracy by **20%**."
    },
    {
      "role": "Software Engineer",
      "company": "Timspark",
      "from_date": "Sep 2015",
      "to_date": "Aug 2019",
      "location": "UK",
      "responsibilities": "• Leveraged **PostgreSQL** and **MongoDB** for high-performance and scalable data storage solutions, ensuring efficient data access and retrieval for complex queries in e-commerce environments.\n• Implemented data processing pipelines leveraging **Kafka** for stream processing, ensuring real-time data flows for analytics and user behavior insights, significantly improving decision-making processes and data availability.\n• Developed and maintained **Redis** caching strategies to enhance application performance, resulting in a **40%** reduction in database load and faster response times for end-users.\n• Collaborated on **BigData** solutions using **Spark** for batch processing and analytics, allowing for the ingestion and processing of over **1 million** records per hour, optimizing the platform's data-handling capabilities.\n• Designed and built robust **API** interfaces to seamlessly integrate internal systems and external services, improving data interoperability and supporting scalable application architectures.\n• Applied best practices in **Clean Code** and thoughtful unit testing frameworks, leading to a **30%** reduction in bugs and enhanced maintainability across the codebase.\n• Engaged in **Remote Collaboration** with cross-functional teams, ensuring effective communication and project alignment within a globally distributed workforce.\n• Fostered a culture of continuous **Feedback** and collaborative improvement, contributing to the overall enhancement of team productivity and project success.\n• Spearheaded the implementation of **Docker** for containerization, streamlining the deployment process across different environments and reducing setup time by **50%**.\n• Championed the incorporation of AI-driven techniques into data analysis processes, providing insights that increased user engagement and optimization of business strategies."
    }
  ],
  "skills": " **Programming Languages:**\n\tJavaScript, TypeScript, Python\n\n **Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n **Frontend Frameworks:**\n\tReact, Vue, Angular\n\n **API Technologies:**\n\tAPI\n\n **Serverless and Cloud Functions:**\n\tAWS (ECS, Lambda, RDS, S3), Azure (App Services, Blob, SQL)\n\n **Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare), MongoDB (Gaming), Redis\n\n **DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, CI/CD & Infrastructure as Code: Terraform, Ansible, Helm, Docker Compose\n\n **Cloud & Infrastructure:**\n\tAWS (ECS, Lambda, RDS, S3), Azure (App Services, Blob, SQL)\n\n **Other:**\n\tBigData, Kafka, AI, DataProcessing, RemoteCollaboration, CleanCode, Testing, Collaboration, Feedback",
  "apply_company": "Abusix, Inc."
}