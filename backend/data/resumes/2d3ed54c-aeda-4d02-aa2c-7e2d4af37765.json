{
  "name": "Rei Taro",
  "role_name": "Data Engineer",
  "email": "rei515@outlook.com",
  "phone": "+48732529451",
  "address": "Warszawa, Poland",
  "linkedin": "https://www.linkedin.com/in/rei-taro-28639a395/",
  "profile_summary": "Results-driven Data Engineer with over 10 years of experience in designing and delivering data architecture solutions that empower financial platforms and AI/ML pipelines. Proficient in **Python** and advanced SQL skills, coupled with hands-on expertise in **DBT**, **Snowflake**, and **Databricks**. Skilled in deploying cloud-native solutions using **AWS** and **Azure**, and experienced with **Terraform**, **Airflow**, and **Prefect** for CI/CD processes. Adept at containerization with **Docker** and orchestration using **Kubernetes**, ensuring high-performance and scalable data workflows. Proven track record of significant contributions to projects at leading organizations such as VISA, Sii Poland, and Reply Polska.",
  "education": [
    {
      "degree": "Bachelorâ€™s Degree in Computer Science",
      "category": "",
      "from_year": "2010",
      "to_year": "2015",
      "location": "Japan",
      "university": "Keio University"
    }
  ],
  "experience": [
    {
      "role": "Data Engineer",
      "company": "Leobit",
      "from_date": "Aug 2022",
      "to_date": "Present",
      "location": "Poland",
      "responsibilities": "Utilized **Python** and **SQL** to engineer backend services for data processing and automation.\nDeveloped robust data architectures by deploying effective pipelines with **Apache Airflow** and **DBT**.\nImplemented asynchronous processing for performance improvement using **Celery** and **Redis** to handle demands of up to **1000** transaction requests per minute.\nBuilt and maintained scalable data storage solutions on **Snowflake** and integrated with **Databricks** for advanced analytics and machine learning workflows.\nManaged cloud infrastructure seamlessly with **Terraform**, ensuring compliance and operational excellence across a multi-cloud environment, particularly on **Azure**.\nDeployed containerized applications utilizing **Docker** and **Kubernetes** to ensure high availability and scalability in application delivery.\nExecuted CI/CD pipelines to facilitate regular updates and testing, resulting in a **30%** faster release cycle.\nConducted extensive security assessments and integrated modern authentication methods including **OAuth2** and **Azure AD B2C** to protect sensitive data."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Innovature",
      "from_date": "Nov 2018",
      "to_date": "Jun 2022",
      "location": "Japan",
      "responsibilities": "Utilized **Python** and **SQL** to develop robust backend systems, enhancing the automation of document workflows, improving user onboarding efficiency by **30%**, and managing complex reporting processes.\nImplemented **data architecture** by creating event-driven microservices with **Celery** and **Redis**, facilitating asynchronous processing of financial data and transaction requests, achieving a **20%** reduction in processing time.\nLeveraged **Terraform** for infrastructure automation and managed the deployment of microservices on **Azure App Services**, ensuring consistent and scalable environments, resulting in a **15%** decrease in deployment time.\nEngineered secure data pipelines for the compliant exchange of regulatory data, utilizing **Apache Airflow** and **Azure Functions**, to automate and streamline data flow between systems, improving data access by **25%**.\nConducted security audits to ensure compliance with industry standards; integrated **OAuth2** and **Azure AD B2C** for managing authentication and secure access controls across platforms.\nCollaborated with cross-functional teams, ensuring smooth system integration, regulatory compliance, and successful release management, contributing to a **10%** improvement in project delivery timelines."
    },
    {
      "role": "Software Developer",
      "company": "Wizcorp",
      "from_date": "Apr 2015",
      "to_date": "Nov 2018",
      "location": "Japan",
      "responsibilities": "Developed scalable data architecture solutions using **Python**, **SQL**, and **PostgreSQL** to enhance data processing and analytics capabilities for trade execution and portfolio management.\nUtilized **DBT** to transform and model data for reporting purposes, ensuring data integrity and accessibility for stakeholders.\nImplemented ETL pipelines leveraging **Airflow** and **Prefect** to automate data workflows, reducing processing times by **30%**.\nEngineered real-time data streaming processes with **Redis** and **asyncio** for timely analytics in high-frequency trading scenarios.\nManaged infrastructure as code using **Terraform**, facilitating seamless deployment of cloud resources and configurations in a **Docker** environment.\nCollaborated with cross-functional teams to integrate data flows with **Snowflake** and **Databricks**, enhancing data availability across platforms.\nEnsured compliance with regulatory standards, implementing data security measures aligned with GDPR and MiFID II.\nExecuted comprehensive CI/CD practices using **Docker** and Kubernetes, improving deployment efficiency by **50%** and maintaining high-quality standards for software releases."
    }
  ],
  "skills": "****Programming Languages****\n\tPython, SQL\n\n****Backend Frameworks****\n\tFastAPI, Flask, Django, Celery, Airflow, Prefect\n\n****Frontend Frameworks****\n\tJavaScript\n\n****API Technologies****\n\tREST/gRPC APIs\n\n****Serverless and Cloud Functions****\n\tAWS (EC2, S3, Lambda), Azure\n\n****Databases****\n\tPostgreSQL, MySQL, MongoDB, Redis, Snowflake, Databricks\n\n****DevOps****\n\tDocker, Kubernetes, GitHub Actions, Azure DevOps, Terraform, CI/CD\n\n****Cloud & Infrastructure****\n\tcloud, data architecture\n\n****Other****\n\tMicroservices, Kafka, PyTest, Git, Pandas, NumPy, scikit-learn, TensorFlow"
}