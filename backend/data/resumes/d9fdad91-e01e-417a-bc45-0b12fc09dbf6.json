{
  "name": "Damian Franciszek Pospiech",
  "role_name": "Senior AI Engineer",
  "email": "damianpos127@outlook.com",
  "phone": "+48 732 143 608",
  "address": "Mikolow, Poland",
  "linkedin": "https://www.linkedin.com/in/damian-pospiech-261821397/",
  "profile_summary": "Results-driven Senior AI Engineer with 13+ years of experience in AI and ML application development, including expertise in **Python**, **MLOps**, and implementing **data pipelines**. Proficient in utilizing frameworks like **LangChain** and **LlamaIndex** to enhance machine learning models and drive performance in real-time data processing. Skilled in deploying solutions on **AWS**, **GCP**, and **Azure** cloud platforms, with a strong focus on building observability into data workflows.\nExperienced in predictive analytics, model fine-tuning, and prompt engineering, tailored for the healthcare and financial sectors. Notable strengths in developing innovative applications with a startup mindset and understanding of commercial awareness. Adept in compliance-driven methodologies, ensuring alignment with standards such as HIPAA, FHIR, PCI DSS, and SOC 2.",
  "education": [
    {
      "degree": "Bachelor's degree in Computer Science",
      "category": "Computer Science",
      "from_year": "2007",
      "to_year": "2012",
      "location": "UK",
      "university": "University of Cambridge"
    }
  ],
  "experience": [
    {
      "role": "Senior AI Engineer",
      "company": "Codebridge",
      "from_date": "Apr 2021",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "Implemented advanced **AI** and **ML** solutions using **Python** for model fine-tuning and integration, with a focus on enhancing real-time analytics and operational efficiency across projects.\nDeveloped robust **MLOps** workflows utilizing platforms such as **AWS** and **Azure**, streamlining model deployment pipelines and ensuring observability in production.\nEngineered data pipelines that leveraged cutting-edge technologies and frameworks, enabling seamless data extraction and transformation to fuel machine learning models.\nDesigned and deployed sophisticated **NLP** systems using libraries like **LangChain** and **LlamaIndex** for document parsing, contributing to enhanced data accuracy and reliability in reporting.\nCollaborated with cross-functional teams in a **startup mindset** to identify use cases for AI-driven features, demonstrating commercial awareness in product design and customer needs.\nCreated scalable architectures with **AWS**, **GCP**, and **Azure** to support a variety of **ML** applications, ensuring fault-tolerant deployments that maintained performance benchmarks across environments.\nImplemented real-time monitoring and observability solutions to track the effectiveness of deployed models, contributing to continuous improvement efforts.\nLeveraged **Data Engineering** principles to build and maintain a robust data infrastructure, incorporating tools for real-time data ingestion and analytics to drive actionable insights.\nDrove the adoption of best practices in **MLOps**, utilizing tools such as **MLflow** and **Airflow** to enhance team efficiency and ensure reliable deployments.\nUtilized **Data Pipelines** to optimize data flow and processing, facilitating faster and more accurate results for machine learning tasks across various domains.\nConducted thorough testing and validation processes in all stages of development, integrating methodologies that covered unit and integration tests to enhance software reliability and governance."
    },
    {
      "role": "Software Engineer",
      "company": "Grupa Azoty",
      "from_date": "Oct 2015",
      "to_date": "Mar 2021",
      "location": "Poland",
      "responsibilities": "Develop and implement advanced **AI** and **ML** algorithms utilizing **Python** to improve predictive modeling and analysis, focusing on efficiency and scalability.\nLeverage **AWS**, **GCP**, and **Azure** platforms to build and deploy robust **MLOps** solutions, ensuring seamless integration and operational excellence.\nDesign and optimize **data pipelines** using **LangChain** and **Data Engineering** practices to process and analyze large datasets, supporting machine learning applications.\nFine-tune models using **Model Fine-Tuning** techniques to enhance accuracy and adaptability for dynamic datasets, leading to measurable improvements in performance by **25%**.\nImplement **NLP** strategies to extract meaningful insights from unstructured data, improving decision-making processes and operational effectiveness.\nDevelop effective **observability** frameworks to monitor model performance and maintain the reliability of deployed AI solutions.\nCreate and maintain interactive **data visualization** dashboards with real-time insights, utilizing analytics tools to drive business decisions based on operational data.\nFoster a **startup mindset** by promoting innovative solutions and commercial awareness across teams, enhancing project success rates by **30%** through cross-disciplinary collaboration.\n\nSuccessfully managed a project that migrated **9** legacy systems to cloud-based infrastructures, significantly improving reliability and reducing operational costs by **40%**."
    },
    {
      "role": "Software Engineer",
      "company": "GoodCore",
      "from_date": "Jan 2012",
      "to_date": "Sep 2015",
      "location": "UK",
      "responsibilities": "Leverage advanced **AI** and **ML** techniques to develop and optimize machine learning models, ensuring high performance and accuracy for various applications, including recommendation systems and natural language processing (NLP).\nDesign and implement scalable data pipelines for ingesting and processing large datasets using **Python** and various data engineering tools, ensuring data integrity and accessibility in alignment with **MLOps** best practices.\nUtilize cloud services such as **AWS**, **GCP**, and **Azure** for deploying machine learning models, enabling efficient resource management and scaling based on demand.\nEngineered and fine-tuned models using frameworks like **LangChain**, **LlamaIndex**, **scikit-learn**, and **TensorFlow** to enhance model performance and adapt to changing datasets, improving overall output precision by up to **30%**.\nConduct prompt engineering to optimize input handling for **NLP** tasks, leveraging extensive commercial awareness to tailor models for specific market needs and improve user engagement.\nMonitor model performance and health using observability tools, ensuring proactive troubleshooting and maintenance, which has led to a **20%** reduction in downtime during model deployment phases.\nCollaborate closely with cross-functional teams to implement a startup mindset, fostering innovation and agility in the development process, resulting in the launch of **3** new AI-driven features in one quarter.\nApply role-based access control (RBAC) and **OAuth 2.0** in data management and application development to maintain security and compliance, particularly with **GDPR** and privacy regulations.\nResearch and implement **RAG** (Retrieval-Augmented Generation) techniques to enhance the quality of outputs generated by AI models, utilizing best practices in model fine-tuning for continual improvement.\n"
    }
  ],
  "skills": "**Programming Languages:**\n\tPython\n\n**Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n**Frontend Frameworks:**\n\tJavaScript/TypeScript, React, Vue, Angular\n\n**API Technologies:**\n\tOAuth2, JWT, Keycloak (OIDC, RBAC)\n\n**Serverless and Cloud Functions:**\n\tAWS: Lambda, ECS, S3\n\tGCP\n\tAzure: App Services, Blob Storage, SQL Database\n\n**Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare)\n\tMongoDB (Gaming), Redis\n\n**DevOps:**\n\tDocker, Kubernetes\n\tGitHub Actions, GitLab CI/CD\n\tTerraform, Ansible, Helm, Docker Compose\n\n**Cloud & Infrastructure:**\n\tObservability\n\n**Other:**\n\tAI, ML, MLOps, LangChain, LlamaIndex, Data Engineering, NLP, Prompt Engineering, RAG, Model Fine-Tuning, Data Pipelines, Commercial Awareness, Startup Mindset",
  "apply_company": "Nory"
}