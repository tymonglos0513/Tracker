{
  "name": "Mariusz Jan Skobel",
  "role_name": "Remote Data Engineer",
  "email": "mariuszskobel15@outlook.com",
  "phone": "+48 735 343 548",
  "address": "Katowice, Poland",
  "linkedin": "https://www.linkedin.com/in/mariusz-skobel-789557397/",
  "profile_summary": "Detail-oriented Remote Data Engineer with a strong background in **real-time monitoring**, **operational planning**, and **risk assessment**. Proven problem-solver with 10+ years of experience effectively utilizing technical skills in data integration and cloud technologies. Proficient in **communication** and **team collaboration**, ensuring seamless execution of digital transformation initiatives. Skilled in delivering high-performance software solutions with a focus on compliance standards.\n\nExperienced with compliance frameworks, including HIPAA and PCI DSS, while maintaining a commitment to analytical excellence and stakeholder management. Passionate about leveraging technology to drive impactful results and enhance customer engagement through data-driven strategies.",
  "education": [
    {
      "degree": "Bachelor’s Degree",
      "category": "Computer Science",
      "from_year": "2012",
      "to_year": "2015",
      "location": "UK",
      "university": "University of Bristol"
    }
  ],
  "experience": [
    {
      "role": "Remote Data Engineer",
      "company": "EitBiz",
      "from_date": "Oct 2022",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "• Developed scalable, cloud-native data architecture leveraging **PostgreSQL**, **MongoDB**, and **Redis**, ensuring compliance with regulations to facilitate secure, real-time data processing in healthcare and finance sectors.\n• Applied strong analytical skills to design and implement efficient ETL processes, enabling seamless data ingestion, storage, and querying for large-scale applications in line with business requirements.\n• Collaborated with cross-functional teams, enhancing communication and team collaboration to execute projects adhering to timelines and operational plans.\n• Utilized **Python** with frameworks such as **FastAPI** for backend services, focusing on effective problem-solving to address data-related challenges and streamline workflows.\n• Implemented real-time monitoring strategies using tools to ensure system stability and performance, significantly improving reliability across **9+** applications.\n• Established compliance measures in system architectures, ensuring data integrity and security while navigating regulations such as HIPAA and GDPR.\n• Integrated **Azure Cognitive Search** and **ElasticSearch**, enhancing customer engagement through advanced search functionalities on platforms with millions of health and finance records.\n• Executed robust risk assessment strategies, leading to significant reductions in operational risk through well-structured data handling and processing methodologies.\n• Spearheaded the deployment of MLOps pipelines employing **MLflow** and **Apache Airflow**, ensuring effective versioning and continuous model training which maximized operational efficiency.\n• Integrated AI-driven solutions into applications, improving stakeholder management and increasing customer satisfaction through personalized experiences and predictive analytics.\n• Defined test strategies using tools like **Jest** and **Cypress**, ensuring high-quality deliverables through comprehensive testing across **5+** application environments."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Tvn S.A.",
      "from_date": "Oct 2019",
      "to_date": "Sep 2022",
      "location": "Poland",
      "responsibilities": "Demonstrated strong **communication** and **analytical skills** by leading the development and modernization of financial platforms through collaboration with stakeholders.\nUtilized **problem-solving** techniques to adopt a microservices-based architecture using **Node.js (NestJS/Express)** and **Python (FastAPI, Django)**, resulting in a **30%** improvement in scalability and maintainability for high-volume transaction systems.\nEnabled **real-time monitoring** by developing transaction analytics dashboards with **React (18)**, **D3.js**, and **Power BI Embedded**, allowing operations teams to track over **1,000** transactions per minute and swiftly detect anomalies.\nFostered **team collaboration** by integrating **Kafka**, **RabbitMQ**, and **Azure Service Bus** to create a robust event-driven architecture, resulting in a **25%** reduction in transaction processing time.\nExecuted compliance initiatives by building ETL pipelines with **Python**, **Apache Airflow**, and **Azure Data Factory**, facilitating efficient batch and real-time data ingestion from **5+** internal and third-party sources.\nManaged risk assessment for fraud detection systems by implementing AI/ML models using **scikit-learn**, **XGBoost**, and **Azure Machine Learning**, successfully analyzing **80%** of transaction patterns to identify suspicious activities.\nOrchestrated the creation of ML pipelines for credit scoring and churn prediction using **MLflow** and **Airflow**, integrating model inference into backend services to support real-time decision-making in banking operations."
    },
    {
      "role": "Software Engineer",
      "company": "Timspark",
      "from_date": "Sep 2015",
      "to_date": "Aug 2019",
      "location": "UK",
      "responsibilities": "• Collaborated with cross-functional teams to optimize data workflows and improve **real-time monitoring** capabilities, enhancing **customer engagement** and ensuring seamless operational execution across platforms.\n• Developed and maintained scalable backend systems that comply with industry standards, focusing on **compliance** with data protection regulations and **risk assessment** strategies.\n• Implemented effective **digital oilfield** solutions utilizing advanced **IT skills** to enhance data transmission protocols, facilitating better analysis and insights for stakeholders.\n• Utilized strong **problem-solving** and **analytical skills** to troubleshoot data discrepancies and enhance system performance, leading to a 30% increase in data processing efficiency.\n• Engaged in **team collaboration** to execute projects successfully under tight deadlines, demonstrating exceptional **multitasking** abilities during rollout phases.\n• Actively communicated project progress and challenges to stakeholders, ensuring alignment and fostering **stakeholder management** for successful project execution.\n• Designed operational plans that integrate **real-time monitoring** and data analysis, achieving a 25% reduction in operational costs through efficiency improvements.\n• Conducted rigorous testing and validation of data processes, addressing potential compliance issues and improving overall data integrity by 15%."
    }
  ],
  "skills": "Programming Languages:\n\tPython, JavaScript, TypeScript\n\n**Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n**Frontend Frameworks:**\n\tReact, Vue, Angular\n\n**API Technologies:**\n\tJWT, OAuth2, Keycloak (OIDC, RBAC)\n\n**Serverless and Cloud Functions:**\n\tAWS (ECS, Lambda), Azure (App Services)\n\n**Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare), MongoDB (Gaming), Redis\n\n**DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, Terraform, Ansible, Helm, Docker Compose\n\n**Cloud & Infrastructure:**\n\tAWS (RDS, S3), Azure (Blob, SQL), Nginx, Certbot\n\n**Other:**\n\tcommunication, problem-solving, digital oilfield, transmission protocols, IT skills, analytical skills, team collaboration, multitasking, compliance, job execution, risk assessment, operational planning, real time monitoring, customer engagement, stakeholder management"
}