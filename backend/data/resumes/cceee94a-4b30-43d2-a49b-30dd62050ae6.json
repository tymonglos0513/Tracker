{
  "name": "Damian Franciszek Pospiech",
  "role_name": "Senior Data Engineer",
  "email": "damianpos127@outlook.com",
  "phone": "+48 732 143 608",
  "address": "Mikolow, Poland",
  "linkedin": "https://www.linkedin.com/in/damian-pospiech-261821397/",
  "profile_summary": "Results-driven Senior Data Engineer with a robust 13+ years of experience in high-performance application development, primarily in the healthcare and financial sectors. Proficient in **Microsoft Fabric**, **SQL**, **Data Warehousing**, **ETL**, and **Power BI**, with a strong command of **SQL Server** and **SQL Server Integrated Services** for data processing and management. Experienced in implementing high availability and disaster recovery solutions, ensuring seamless and reliable data access.\n\nDemonstrated ability to manage time effectively and solve complex problems, coupled with excellent communication skills to collaborate with cross-functional teams. In addition to core engineering skills, I possess a solid foundation in **JavaScript/TypeScript**, **Python**, and **Flutter**, and have hands-on experience with **React**, **Next.js**, **Node.js**, **Django**, and **FastAPI** for full-stack development. \n\nExpert in deploying cloud-native systems on **AWS** and **Azure**, implementing microservices, and driving CI/CD best practices. Also, well-versed in building AI/ML-powered platforms for predictive analytics, aligning with compliance standards such as HIPAA, FHIR, PCI DSS, and SOC 2. Strong background in MLOps, including utilizing **MLflow**, **Airflow**, and **Kubeflow** for model management and deployment.",
  "education": [
    {
      "degree": "Bachelor's degree in Computer Science",
      "category": "Computer Science",
      "from_year": "2007",
      "to_year": "2012",
      "location": "UK",
      "university": "University of Cambridge"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "Codebridge",
      "from_date": "Apr 2021",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "- Utilized **SQL** for efficient data manipulation and queries, enhancing data retrieval processes  by **30%**.\n- Developed and maintained complex **ETL** workflows with **SQL Server Integrated Services** (SSIS) to ensure smooth data pipelining and transformation, resulting in reduced processing time by **20%**.\n- Designed and implemented data warehousing solutions using **Microsoft Fabric** that supported efficient reporting and analytics, including real-time capabilities.\n- Created and managed interactive reports and dashboards in **Power BI**, providing stakeholders with key insights and analyses in the finance and healthcare sectors.\n- Established robust **Database Administration** practices for **SQL Server**, ensuring high availability and effective disaster recovery strategies, leading to **99.9%** uptime.\n- Collaborated with cross-functional teams to refine data architectures and solutions, improving communication and problem-solving efforts.\n- Implemented monitoring and alerting systems, ensuring operational continuity and swift issue resolution within the data infrastructure.\n- Developed time management frameworks for project deliverables, ensuring timely completion of data projects and tasks.\n- Drove the adoption of best practices in data governance, ensuring data quality and compliance with regulatory standards.\n- Conducted training and mentoring sessions for junior data engineers, enhancing team skillsets and performance across data projects."
    },
    {
      "role": "Software Engineer",
      "company": "Grupa Azoty",
      "from_date": "Oct 2015",
      "to_date": "Mar 2021",
      "location": "Poland",
      "responsibilities": "Utilized **SQL** and **SQL Server** to create and manage extensive data warehousing solutions, ensuring high availability and disaster recovery practices across all financial data systems.\nImplemented and optimized ETL processes using **SQL Server Integrated Services** and **Python**, to efficiently ingest, transform, and load financial data from various sources, improving overall data accessibility by **30%**.\nDeveloped dynamic reports and dashboards with **Power BI** and **Microsoft Fabric**, enabling cross-functional teams to gain insights from financial data effectively and improve decision-making time by **25%**.\nApplied excellent time management and problem-solving skills to enhance data retrieval processes, reducing query response time by **40%** through the implementation of optimized database design and indexing strategies.\nCollaborated with cross-disciplinary teams to communicate data-driven insights and strategies, ensuring alignment with organizational goals and fostering a culture of data literacy.\nMonitored and maintained database performance, implementing backup strategies to uphold high availability and disaster recovery protocols for critical financial applications and services.\nConducted regular training sessions on database management and ETL processes for stakeholders, enhancing overall understanding and usage of data tools and systems."
    },
    {
      "role": "Software Engineer",
      "company": "GoodCore",
      "from_date": "Jan 2012",
      "to_date": "Sep 2015",
      "location": "UK",
      "responsibilities": "Utilized **SQL Server** for efficient data management and administration, optimizing database performance and ensuring high availability for critical data workflows.\nImplemented **Microsoft Fabric** for seamless data integration and warehousing, enhancing data accessibility and analytics capabilities.\nExecuted ETL processes using **SQL Server Integrated Services (SSIS)** to streamline data extraction, transformation, and loading across various platforms, improving data reliability by **30%**.\nDesigned and maintained comprehensive data warehousing solutions to support business intelligence initiatives and reporting requirements with **Power BI**, fostering data-driven decision-making.\nEngineered solutions for disaster recovery, guaranteeing data continuity and minimizing downtime impact by leveraging redundant infrastructures.\nDemonstrated effective time management and problem-solving skills through the successful delivery of data projects on tight deadlines, ensuring that **100%** of deliverables met stakeholder expectations.\nMaintained clear communication with cross-functional teams to gather requirements and provide updates, ensuring alignment on data strategy and priorities while enhancing collaboration efficiency.\nApplied experience in high availability setups to ensure optimal performance and reliability of data systems under high workloads, achieving an uptime of over **99.9%**.\n"
    }
  ],
  "skills": " **Programming Languages:**\n\tPython: FastAPI, Flask, Django\n\tJavaScript/TypeScript: React, Vue, Angular\n\n**Backend Frameworks:**\n\tFlask, Django\n\n**Frontend Frameworks:**\n\tReact, Vue, Angular\n\n**API Technologies:**\n\tAuthentication & Security:\n\t•\tKeycloak (OIDC, RBAC), OAuth2, JWT\n\tNginx, Let’s Encrypt, Certbot\n\n**Serverless and Cloud Functions:**\n\tAWS: ECS, Lambda, RDS, S3\n\tAzure: App Services, Blob Storage, SQL Database\n\n**Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare)\n\tMongoDB (Gaming), Redis\n\tSQL, SQL Server, Database Administration\n\n**DevOps:**\n\tDocker, Kubernetes\n\tGitHub Actions, GitLab CI/CD\n\tCI/CD & Infrastructure as Code:\n\t•\tTerraform, Ansible, Helm, Docker Compose\n\n**Cloud & Infrastructure:**\n\tHigh Availability, Disaster Recovery\n\n**Other:**\n\tMicrosoft Fabric, Data Warehousing, ETL, Power BI\n\tTime Management, Problem Solving, Communication",
  "apply_company": "IPRS Health"
}