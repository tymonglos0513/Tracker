{
  "name": "Mariusz Jan Skobel",
  "role_name": "Senior Analytics Engineer",
  "email": "mariuszskobel15@outlook.com",
  "phone": "+48 735 343 548",
  "address": "Katowice, Poland",
  "linkedin": "https://www.linkedin.com/in/mariusz-skobel-927764397/",
  "profile_summary": "Senior Analytics Engineer with over 10 years of experience leveraging data-driven solutions to enhance business performance in healthcare and finance sectors. Proficient in **SQL**, **BigQuery**, **Python**, and **R** to perform complex data analyses and develop robust analytics platforms. Hands-on experience with cloud services, including **GCP** and **AWS**, which facilitates cloud-native data integration and management. Skilled in data visualization using tools such as **Metabase** and **Tableau**, enabling impactful insights for stakeholders. Adept at employing **Agile** methodologies to streamline project timelines and enhance team collaboration.\n\nStrong technical background includes developing and deploying comprehensive software solutions utilizing **JavaScript/TypeScript**, **React**, **Next.js**, **Vue**, **Node.js**, **FastAPI**, and **Django**. Hands-on experience with MLOps techniques, employing tools like **MLflow**, **Airflow**, and **Kubeflow** to optimize machine learning workflows. Committed to building secure, scalable, and maintainable solutions that adhere to compliance standards while driving significant results.",
  "education": [
    {
      "degree": "Bachelor’s Degree",
      "category": "Computer Science",
      "from_year": "2012",
      "to_year": "2015",
      "location": "UK",
      "university": "University of Bristol"
    }
  ],
  "experience": [
    {
      "role": "Senior Analytics Engineer",
      "company": "EitBiz",
      "from_date": "Oct 2022",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "•\tLeveraged **GCP** and **AWS** for cloud-based data solutions, utilizing **BigQuery** and **SQL** to query large datasets, ensuring efficient data retrieval and analysis for business intelligence and reporting.\n•\tDeveloped comprehensive analytics dashboards and visualizations with **Tableau** and **Metabase**, facilitating data-driven decisions and insights for stakeholders.\n•\tUtilized **Python** and **R** for data manipulation and statistical analysis, building robust models in line with Agile methodologies to deliver iterative improvements to analytics processes.\n•\tImplemented data transformation workflows using **DBT**, optimizing ETL processes to ensure clean, accessible datasets for analytics.\n•\tCollaborated with cross-functional Agile teams to gather requirements, execute data-driven strategies, and deliver solutions aligned with business objectives and timelines.\n•\tMaintained version control and collaboration through **Git**, ensuring robust data pipeline development and review processes.\n•\tCreated and managed SQL queries for data extraction and reporting, enhancing accessibility for end-users while improving data accuracy and integrity.\n•\tDeveloped automated reporting systems to streamline analytics delivery, significantly reducing manual reporting time by **50%** through efficient workflow designs.\n•\tMonitored and analyzed performance metrics to identify trends and drive enhancements in data processing and visualization techniques, achieving a **30%** increase in data processing speed.\n•\tWorked closely with stakeholders to translate complex data findings into actionable business insights, successfully enhancing decision-making processes within teams."
    },
    {
      "role": "Software Engineer",
      "company": "Tvn S.A.",
      "from_date": "Oct 2019",
      "to_date": "Sep 2022",
      "location": "Poland",
      "responsibilities": "Utilized **DBT**, **BigQuery**, and **SQL** to model and transform complex data sets, ensuring consistent and reliable analytics outputs that drove decision-making processes.\nEmployed data visualization tools such as **Metabase** and **Tableau** to create interactive dashboards, increasing reporting efficiency by **30%** while providing stakeholders with actionable insights.\nCollaborated with cross-functional teams in an **Agile** environment to streamline data workflows, resulting in a **25%** reduction in project turnaround time through improved communication and task management.\nDeveloped data extraction and transformation pipelines with **Python**, ensuring seamless integration with both **GCP** and **AWS** cloud environments, which facilitated a **40%** increase in data accessibility.\nManaged version control and collaborative coding practices using **Git**, enhancing team productivity and code quality while reducing bugs by **15%**.\nAnalyzed large data sets, developing predictive models and analytics solutions that improved operational efficiency and customer experience metrics by **20%**.\nConducted regular training sessions to enhance team proficiency in analytics tools and methodologies, promoting a culture of continuous improvement and data literacy within the organization."
    },
    {
      "role": "Software Engineer",
      "company": "Timspark",
      "from_date": "Sep 2015",
      "to_date": "Aug 2019",
      "location": "UK",
      "responsibilities": "Utilized **GCP** and **AWS** to design and optimize data pipelines in cloud environments, ensuring efficient ETL processes for large-scale datasets while applying **SQL** and **DBT** for data transformation and analysis.\nDeveloped interactive dashboards and reports using **Tableau** and **Metabase**, presenting actionable insights to stakeholders for improved decision-making and strategic initiatives, focusing on a 30% increase in data visibility.\nImplemented version-controlled data models using **Git**, facilitating collaboration and enhancing version management across analytics projects, achieving a 20% reduction in deployment errors.\nLeveraged **Python** and **R** for data analysis, statistical modeling, and scripting, improving workflow automation and data processing speed by 15% through effective coding practices in environment setups.\nCollaborated in an **Agile** work environment to prioritize analytics features and improvements, contributing to bi-weekly sprints, which led to a 25% increase in team efficiency in delivering insights.\nMaintained comprehensive documentation of analytics systems and processes ensuring organizational knowledge transfer and consistency in analytics practices, with a focus on future scalability.\nMonitored, tested, and optimized database performance metrics in **BigQuery** to ensure fast query resolutions and data retrieval times, with an aim to achieve 99.9% uptime for critical analytics services.\nApplied best practices for data governance and compliance to protect data integrity and privacy while ensuring alignment with organizational policies as well as GDPR requirements."
    }
  ],
  "skills": " **Programming Languages:**\n\tPython, R\n\n **Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n **Frontend Frameworks:**\n\tJavaScript, TypeScript, React, Vue, Angular\n\n **API Technologies:**\n\tKeycloak (OIDC, RBAC), JWT, OAuth2, Let’s Encrypt, Nginx, Certbot\n\n **Serverless and Cloud Functions:**\n\tAWS (ECS, Lambda, RDS, S3), Azure (App Services, Blob, SQL), GCP\n\n **Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare), MongoDB (Gaming), Redis, BigQuery, SQL\n\n **DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, Terraform, Ansible, Helm, Docker Compose, Git\n\n **Cloud & Infrastructure:**\n\tAWS, Azure, GCP\n\n **Other:**\n\tMLflow, Airflow, Kubeflow, Agile, Metabase, Tableau, DBT",
  "apply_company": "Top Doctors Group"
}