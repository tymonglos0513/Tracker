{
  "name": "Rei Taro",
  "role_name": "Azure Data Engineer",
  "email": "rei515@outlook.com",
  "phone": "+48732529451",
  "address": "Warszawa, Poland",
  "linkedin": "https://www.linkedin.com/in/rei-taro-28639a395/",
  "profile_summary": "Skilled Azure Data Engineer with over 10 years of experience in backend development, focusing on data engineering, data quality, and data modeling. Proficient in leveraging **Azure**, **Databricks**, and various **CICD tools** to build and optimize data pipelines that ensure high data quality and compliance with DataSecOps practices. Expertise in SQL for efficient data management and real-time analytics tools for actionable insights. Proven ability in API development, troubleshooting, and implementing data management frameworks. Successfully contributed to large-scale projects in reputed organizations like VISA, Sii Poland, and Reply Polska, delivering high-performing solutions and scalable services.",
  "education": [
    {
      "degree": "Bachelor’s Degree in Computer Science",
      "category": "",
      "from_year": "2010",
      "to_year": "2015",
      "location": "Japan",
      "university": "Keio University"
    }
  ],
  "experience": [
    {
      "role": "Azure Data Engineer",
      "company": "Leobit",
      "from_date": "Aug 2022",
      "to_date": "Present",
      "location": "Poland",
      "responsibilities": "Utilized **Azure** and **Databricks** to develop and manage robust **data pipelines** that improved data processing efficiency by **30%**.\nImplemented **CICD tools** for automated deployment and integration, reducing deployment time by **50%**.\nEngineered APIs using **FastAPI** for seamless data integration and real-time analytics capabilities with a focus on **data quality**.\nPerformed data modeling and implemented best practices for **data management frameworks**, ensuring compliance with established data governance standards.\nExecuted **data engineering** tasks for regulatory data exchange with **SQL**, optimizing the data flow for a **99%** accuracy rate.\nConducted proactive troubleshooting to maintain system integrity and enhanced **data security operations** by integrating **Azure AD B2C** for authentication.\nLed data quality assessments and employed **real-time analytics tools** to monitor and improve data consistency across the organization."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Innovature",
      "from_date": "Nov 2018",
      "to_date": "Jun 2022",
      "location": "Japan",
      "responsibilities": "• Developed data pipelines using **Azure** and **Databricks** to enhance data flow and management, implementing robust data quality practices and data modeling techniques for efficient reporting.\n• Utilized **CICD tools** for automated deployments and version control, ensuring streamlined integration and delivery of data engineering projects.\n• Engineered backend systems with **FastAPI** to facilitate API development and real-time analytics tools integration, optimizing data retrieval processes across platforms.\n• Designed and constructed secure data solutions using **Azure** Functions for real-time data processing and reporting, ensuring adherence to **DataSecOps** compliance.\n• Executed SQL queries for data analysis, troubleshooting issues effectively while maintaining industry standards for data security operations.\n• Managed deployment and configuration of data environments on **Azure**, applying best practices for infrastructure automation with consistent results in **84%** of deployments.\n• Collaborated with cross-functional teams to ensure regulatory compliance and successful release management, achieving an **80%** improvement in project timelines."
    },
    {
      "role": "Software Developer",
      "company": "Wizcorp",
      "from_date": "Apr 2015",
      "to_date": "Nov 2018",
      "location": "Japan",
      "responsibilities": "• Designed and implemented **data pipelines** using **Azure** and **Databricks** to streamline data flow and enhance overall **data management frameworks** for real-time analytics.\n• Developed and maintained SQL databases (e.g., PostgreSQL) to ensure data integrity and quality for analytical operations, facilitating regulatory compliance and auditing practices.\n• Engineered robust **API development** processes by integrating REST APIs and WebSockets, which supported data delivery and real-time analytics.\n• Developed comprehensive testing strategies utilizing **CICD tools** and frameworks like PyTest and mock servers, leading to a **25% decrease** in development time and increased deployment frequency.\n• Collaborated with cross-functional teams to implement **data quality** measures and ensure adherence to **DataSecOps** practices while maintaining regulatory standards such as GDPR and MiFID II.\n• Optimized backend processes through job queuing and scheduling solutions with **Celery** and **RabbitMQ**, enhancing task execution efficiency by **30%**.\n• Utilized advanced troubleshooting techniques for backend services, ensuring a seamless trading experience and minimizing downtime for high-frequency transactions by reducing incident response time by **40%**."
    }
  ],
  "skills": "**Programming Languages**\n\tPython (3.8+), SQL, Bash, JavaScript\n\n**Backend Frameworks**\n\tFastAPI, Flask, Django, Celery\n\n**Frontend Frameworks**\n\t\n\n**API Technologies**\n\tREST/gRPC APIs, API development\n\n**Serverless and Cloud Functions**\n\tAWS (EC2, S3, Lambda), Azure\n\n**Databases**\n\tPostgreSQL, MySQL, MongoDB, Redis\n\n**DevOps**\n\tDocker, Kubernetes, GitHub Actions, Azure DevOps, CICD tools\n\n**Cloud & Infrastructure**\n\t\n\n**Other**\n\tAI/ML Tools: Pandas, NumPy, scikit-learn, TensorFlow, Airflow, MLflow, Microservices, Kafka, CI/CD, PyTest, Git, data engineering, data quality, data modeling, DataSecOps, data pipelines, real-time analytics tools, data management frameworks, troubleshooting, data security operations"
}