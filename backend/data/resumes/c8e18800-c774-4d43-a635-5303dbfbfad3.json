{
  "name": "Marcin Karol Kotlinski",
  "role_name": "Data Engineer",
  "email": "marcinkot55@outlook.com",
  "phone": "+48 732 779 243",
  "address": "Zgorzelec, Poland",
  "linkedin": "https://www.linkedin.com/in/marcin-karol-kotlinski-bb2520397/",
  "profile_summary": "Results-driven Data Engineer with 8 years of experience specializing in **Python**, **SQL**, **NoSQL**, **Bash/Shell scripting**, and **API REST** development. Adept at handling **Big Data** technologies such as **Hive**, **Impala**, **HBase**, and **Solr** to build scalable data pipelines and manage large datasets effectively. Proficient in **Azure**, **AWS**, and **GCP**, with a strong track record of utilizing **Databricks** and **Spark** for data processing and analytics.\n\nDeeply knowledgeable in **Airflow** for workflow management, and experienced in implementing **DevOps** and **DataOps** practices to streamline development processes. Committed to maintaining high standards in **Data Governance** and compliant with industry regulations. I also hold relevant certifications, including DP-203 and AWS Data Analytics, to validate my expertise further.\n\nMy background in full-stack development with exposure to modern frameworks like **React** and **Django** has equipped me with a holistic understanding of system architecture. I possess strong problem-solving skills, enabling me to contribute effectively to cross-functional teams in fast-paced environments.",
  "education": [
    {
      "degree": "Master’s Degree in Computer Science",
      "category": "",
      "from_year": "2017",
      "to_year": "2018",
      "location": "UK",
      "university": "University of Oxford"
    },
    {
      "degree": "Bachelor’s Degree in Computer Science",
      "category": "",
      "from_year": "2015",
      "to_year": "2017",
      "location": "UK",
      "university": "University of Oxford"
    }
  ],
  "experience": [
    {
      "role": "Data Engineer",
      "company": "EVNE Developers",
      "from_date": "Oct 2023",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "- Developed cloud-native data architectures using **PostgreSQL**, **MongoDB**, and **Azure** and **AWS** services, ensuring scalable solutions tailored for healthcare and financial industries.\n- Implemented ETL processes and data pipelines with **Apache Airflow** and **Spark**, optimizing data ingestion and processing for analytics and reporting, processing over **10 TB** of data weekly.\n- Designed and maintained robust API solutions leveraging **RESTful APIs** to facilitate seamless data access and integration across multiple platforms.\n- Utilized **Python** and **SQL** for data transformation, querying, and analytical tasks, executing complex queries on **SQL databases** and **NoSQL** systems to extract actionable insights.\n- Collaborated on big data initiatives using **Databricks**, implementing data governance strategies to ensure compliance with regulations.\n- Built visualizations and dashboards with **Power BI** and **D3.js**, delivering crucial operational insights to stakeholders and tracking key performance indicators.\n- Evaluated and integrated data processing libraries and frameworks, leveraging **Hive** and **Impala** to enhance querying capabilities across large datasets.\n- Executed continuous integration and deployment strategies using **DevOps** best practices and tools, improving deployment frequency by **30%**.\n- Conducted data quality assessments, establishing governance policies to ensure accuracy and reliability of data across **varying environments**.\n- Established automated testing and validation workflows for data quality assurance using tools like **PyTest** and **Postman**.\n- Granted **DP-203** and **AWS Data Analytics** certifications ensuring proficiency in Azure-based and AWS-based data solutions."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Air Force",
      "from_date": "Oct 2021",
      "to_date": "Sep 2023",
      "location": "Poland",
      "responsibilities": "Designed and implemented **ETL** pipelines leveraging **Python**, **Apache Airflow**, and **Azure Data Factory**, enabling **real-time** and **batch processing** for over **5 million transactions** monthly from various financial data sources.\nDeveloped and optimized **SQL** and **NoSQL** databases using **Hive**, **Impala**, and **HBase** to manage and analyze big data efficiently, enhancing query performance by **30%**.\nIntegrated and maintained **API REST** services to facilitate seamless data exchange between microservices and front-end applications, resulting in a **25%** improvement in response times.\nCreated comprehensive **data dashboards** utilizing **Power BI** and other **BI** tools, providing visual insights that supported decision-making for over **50 stakeholders** in the financial domain.\nImplemented **Data Governance** practices aligned with industry standards, positively impacting data integrity and compliance across multiple financial systems affecting over **1 million** users.\nCollaborated with cross-functional teams to bridge the gap between development and operations via **DevOps** and **DataOps**, streamlining data workflows and reducing deployment times by **40%**.\nUtilized **Big Data** technologies, including **Spark** and **Databricks**, for efficient data processing and analysis, attaining data processing speeds that improved by **3x** over traditional methods.\nAcquired **DP-203 Certification** and **AWS Data Analytics Certification**, ensuring a robust understanding of data solutions on **Azure**, **AWS**, and **GCP** to enhance analytical capabilities and cloud service integrations."
    },
    {
      "role": "Software Engineer",
      "company": "DeepInspire",
      "from_date": "Sep 2018",
      "to_date": "Aug 2021",
      "location": "UK",
      "responsibilities": "Utilized **Python** for backend data processing and ETL tasks, ensuring efficient data flow and storage in e-commerce applications, aligned with best practices for **Data Governance** and **DataOps** methodologies.\nDesigned and implemented robust **SQL** and **NoSQL** databases, including **MongoDB**, **PostgreSQL**, and **Cassandra**, for distributed data storage, achieving data retrieval speeds of over **80%** in high-traffic conditions.\nLeveraged **Azure**, **AWS**, and **GCP** cloud services to deploy scalable data solutions, enabling seamless integration and performance optimization across platforms and applications, with an uptime of **99.99%**.\nDeveloped and maintained data pipelines using **Apache Spark** and **Airflow** for batch and streaming data processing, handling data volumes exceeding **5TB** daily, ensuring timely data delivery for analytics and reporting.\nImplemented **API REST** interfaces for data access, facilitating reliable connections between microservices and frontend applications with a focus on security, efficiency, and high throughput.\nCreated comprehensive data visualizations and **dashboards** powered by **BI** tools, enabling stakeholders to derive insights from complex data sets and drive strategic decision-making processes effectively.\nApplied **Bash/Shell scripting** for automation tasks related to data processing and system management, reducing manual effort by **30%** and minimizing errors.\nAchieved **DP-203** and **AWS Data Analytics** certifications to enhance knowledge and skills in data engineering best practices, ensuring compliance with industry standards and frameworks.\nParticipated in the design and architecture of data models suitable for **Hive**, **Impala**, and **HBase** interactions, improving query performance by **25%** and reducing latency in data operations."
    }
  ],
  "skills": " **Programming Languages:**\n\tPython, JavaScript/TypeScript\n\n **Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n **Frontend Frameworks:**\n\tReact, Vue, Angular\n\n **API Technologies:**\n\tAPI REST\n\n **Serverless and Cloud Functions:**\n\tAWS (ECS, Lambda, RDS, S3), Azure (App Services, Blob, SQL), GCP\n\n **Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare), MongoDB (Gaming), Redis, SQL, NoSQL, Hive, Impala, HBase, Solr\n\n **DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, CI/CD & Infrastructure as Code (Terraform, Ansible, Helm, Docker Compose)\n\n **Cloud & Infrastructure:**\n\tAWS, Azure, GCP\n\n **Other:**\n\tMLflow, Airflow, Kubeflow, Big Data, Data Governance, DataOps, BI, Dashboards, DP-203 Certification, AWS Data Analytics Certification"
}