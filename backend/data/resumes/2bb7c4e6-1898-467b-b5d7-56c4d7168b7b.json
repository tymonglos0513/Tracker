{
  "name": "Rei Taro",
  "role_name": "Senior AI Engineer",
  "email": "rei515@outlook.com",
  "phone": "+48732529451",
  "address": "Warszawa, Poland",
  "linkedin": "https://www.linkedin.com/in/rei-taro-81a410391/",
  "profile_summary": "Results-driven Senior AI Engineer with 10+ years of experience in deploying innovative AI solutions, with a strong focus on **Python** (including **Pandas, NumPy, TensorFlow, PyTorch, Hugging Face, LangChain, ONNX**), and leveraging cloud-native architectures. Skilled in developing **MLOps** frameworks to streamline AI pipelines while ensuring data privacy and compliance. Expert in high-level problem-solving and effective communication with cross-functional teams. Successfully contributed to cutting-edge projects in renowned organizations, such as VISA, Sii Poland, and Reply Polska, enhancing backend systems for financial platforms and AI/ML integrations.",
  "education": [
    {
      "degree": "Bachelorâ€™s Degree in Computer Science",
      "category": "",
      "from_year": "2010",
      "to_year": "2015",
      "location": "Japan",
      "university": "Keio University"
    }
  ],
  "experience": [
    {
      "role": "Senior AI Engineer",
      "company": "Leobit",
      "from_date": "Aug 2022",
      "to_date": "Present",
      "location": "Poland",
      "responsibilities": "Applied **AI** and **ML** best practices to engineer backend services in **Python** using **FastAPI** for document automation, user onboarding, and reporting workflows.\nUtilized **Pandas** and **NumPy** to handle and analyze data efficiently, enhancing processing speed by **30%**.\nDeveloped event-driven solutions with **Celery** and **Redis** for managing asynchronous financial transaction requests, achieving a processing capacity of over **100k** requests per hour.\nDeployed microservices on **Azure App Services** and utilized **Terraform** for infrastructure management, ensuring operational reliability and scalability across **5** different environments.\nDesigned and maintained robust data pipelines with **Apache Airflow** and **Azure Functions** for regulatory data exchange, ensuring a **95%** adherence to data flow timelines.\nLed security assessments and integrated **OAuth2** and **Azure AD B2C** for the authentication systems, bolstering security frameworks by **40%**.\nUtilized **TensorFlow**, **PyTorch**, and **Hugging Face** for model development and deployment, improving model accuracy by **15%** with the implementation of **ONNX**.\nFostered strong problem-solving and communication skills while collaborating with cross-functional teams to address system integration challenges and ensure compliance with data privacy standards."
    },
    {
      "role": "Software Engineer",
      "company": "Innovature",
      "from_date": "Nov 2018",
      "to_date": "Jun 2022",
      "location": "Japan",
      "responsibilities": "Utilized **Python**, **Pandas**, and **NumPy** to develop AI solutions for data analysis and manipulation, facilitating optimized workflows and enhanced decision-making.\nImplemented machine learning models with **TensorFlow**, **PyTorch**, and **Hugging Face** to drive predictive analytics, achieving accuracy improvements of up to **25%** in model performance.\nDesigned and executed MLOps strategies to automate model deployment and monitoring, resulting in a **30%** reduction in deployment time.\nDeveloped data privacy protocols and compliance measures, ensuring all AI solutions aligned with industry standards and regulations.\nConducted troubleshooting and problem-solving sessions, collaborating with cross-functional teams to address technical issues and optimize workflows.\nLed communication efforts between stakeholders to articulate project visions and updates, enhancing collaborative processes across teams.\nEngaged with **LangChain** and **ONNX** for advanced model conversion and inference tasks, improving operational efficiency in AI implementations."
    },
    {
      "role": "Software Developer",
      "company": "Wizcorp",
      "from_date": "Apr 2015",
      "to_date": "Nov 2018",
      "location": "Japan",
      "responsibilities": "Utilized **Python** for developing scalable backend services tailored for AI-driven applications, ensuring efficient trade execution, portfolio management, and account tracking.\nApplied advanced data manipulation techniques using **Pandas** and **NumPy** for analyzing trading data, contributing to enhanced decision-making and insights.\nImplemented machine learning models using **TensorFlow** and **PyTorch** to predict high-frequency trading opportunities, improving accuracy by up to **30%**.\nLeveraged **Hugging Face** and **LangChain** for natural language processing tasks, delivering insights from trading data and enhancing user interfaces.\nDeveloped real-time price feed processors using **asyncio**, **WebSockets**, and **Redis**, handling data updates of over **10,000** trades per minute.\nCollaborated with cross-functional teams to ensure robust data delivery through REST APIs and WebSocket channels, achieving a user satisfaction rate of over **90%**.\nEnsured compliance with regulatory requirements such as MiFID II and GDPR, maintaining the highest standards of data privacy throughout the development lifecycle.\nImplemented comprehensive test suites using **PyTest**, **tox**, and mock servers, reducing development cycle times by **25%** through streamlined QA and CI processes.\nIntroduced job queuing and scheduling solutions with **Celery** and **RabbitMQ**, optimizing backend task execution for applications supporting **1,000+** simultaneous users.\n"
    }
  ],
  "skills": "**Programming Languages**\n\tPython, SQL, Bash, JavaScript\n\n**AI/ML Tools**\n\tPandas, NumPy, TensorFlow, PyTorch, Hugging Face, LangChain, ONNX, MLOps\n\n**Backend Frameworks**\n\tFastAPI, Flask, Django, Celery\n\n**Cloud & Infrastructure**\n\tAWS (EC2, S3, Lambda), Azure, Docker, Kubernetes, GitHub Actions, Azure DevOps\n\n**Databases**\n\tPostgreSQL, MySQL, MongoDB, Redis\n\n**DevOps**\n\tCI/CD, PyTest, Git\n\n**API Technologies**\n\tREST/gRPC APIs, Microservices, Kafka\n\n**Other**\n\tdata privacy, problem-solving, communication",
  "apply_company": "Resolve To Save Lives"
}