{
  "name": "Rei Taro",
  "role_name": "Senior Data Engineer",
  "email": "rei515@outlook.com",
  "phone": "+48732529451",
  "address": "Warszawa, Poland",
  "linkedin": "https://www.linkedin.com/in/rei-taro-81a410391/",
  "profile_summary": "Driven Senior Data Engineer with over 10 years of experience in Data Engineering, skilled in leveraging modern technologies such as **SQL**, **NoSQL**, **Python**, **AWS**, **Azure**, and **GCP** to design and implement robust data solutions. Proficient in stream processing using **Spark**, **Kafka**, and **Flink**, as well as orchestration with **Airflow** and **Luigi**. Strong background in building scalable, cloud-native architectures and CI/CD practices to automate workflows. Proven ability to collaborate in Agile environments, driving successful projects for top-tier firms including VISA, Sii Poland, and Reply Polska, and bringing innovative AI/ML solutions to life.",
  "education": [
    {
      "degree": "Bachelor’s Degree in Computer Science",
      "category": "",
      "from_year": "2010",
      "to_year": "2015",
      "location": "Japan",
      "university": "Keio University"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "Leobit",
      "from_date": "Aug 2022",
      "to_date": "Present",
      "location": "Poland",
      "responsibilities": "• Developed and maintained data pipelines utilizing **Apache Airflow** and **Azure Functions** for regulatory data exchange, ensuring timely and accurate data flow for over **1000** transactions daily.\n• Engineered backend data processing services in **Python** with **FastAPI** to optimize document automation and reporting workflows, achieving a **30%** increase in operational efficiency.\n• Managed and deployed microservices using **Azure App Services**, implementing **Terraform** for infrastructure as code to ensure seamless cloud operations across **5** different environments.\n• Executed event-driven architectures with **Celery** and **Redis** to establish asynchronous processing for financial transactions, significantly reducing processing time by **40%**.\n• Conducted security assessments and integrated **OAuth2** and **Azure AD B2C** to enable secure, scalable authentication systems for a user base of over **10,000**.\n• Collaborated effectively with cross-functional teams to resolve system integration issues and enhance compliance in an Agile environment, overseeing **12** major releases per year."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Innovature",
      "from_date": "Nov 2018",
      "to_date": "Jun 2022",
      "location": "Japan",
      "responsibilities": "• Developed and optimized data pipelines utilizing **Apache Airflow** for orchestration and **Azure Functions** to automate workflows, ensuring efficiency and scalability across **2** major projects.\n• Implemented robust data storage solutions using **SQL** and **NoSQL** databases, managing over **5TB** of data across **3** different systems.\n• Engineered backend systems in **Python** and **FastAPI** to enhance automation of document workflows, achieving improved processing times by **30%**.\n• Created event-driven microservices with **Celery** and **Redis**, allowing asynchronous handling of over **1,000** financial transactions per minute.\n• Deployed microservices on **Azure App Services**, using **Terraform** for infrastructure as code to maintain consistent deployment across **4** environments.\n• Conducted comprehensive security audits for data protection, ensuring compliance with industry standards and integrating **OAuth2** and **Azure AD B2C** for secure authentication mechanisms.\n• Collaborated effectively with cross-functional teams using **Agile** methodologies to facilitate seamless system integrations and successful release management across **5** major releases."
    },
    {
      "role": "Software Developer",
      "company": "Wizcorp",
      "from_date": "Apr 2015",
      "to_date": "Nov 2018",
      "location": "Japan",
      "responsibilities": "Utilized **Python** and **PostgreSQL** for backend services development, improving trade execution efficiency by **30%** through enhanced portfolio management and account tracking.\nDesigned and implemented high-performance real-time data processing systems using **asyncio**, **WebSockets**, and **Redis** to provide up-to-the-minute trading data, supporting transactions with latency under **50 milliseconds**.\nCollaborated with frontend teams to develop and deliver REST APIs and WebSocket channels, facilitating seamless user experiences and reducing response time by **25%**.\nEnsured compliance with regulatory standards such as MiFID II and GDPR while implementing robust internal data security protocols.\nEstablished reliable CI/CD processes with **PyTest**, **tox**, and mock servers, which decreased deployment times by **40%**, enhancing overall development efficiency.\nAdvanced backend task management through the integration of **Celery** and **RabbitMQ**, improving task execution speed and reliability by **20%**."
    }
  ],
  "skills": "  **Programming Languages**\n\tPython, SQL, Java, Scala\n\n  **Backend Frameworks**\n\tFastAPI, Flask, Django, Celery\n\n  **Frontend Frameworks**\n\t\n\n  **API Technologies**\n\tREST/gRPC APIs, Microservices, Kafka\n\n  **Serverless and Cloud Functions**\n\tAWS (EC2, S3, Lambda), Azure, GCP\n\n  **Databases**\n\tPostgreSQL, MySQL, MongoDB, Redis, NoSQL\n\n  **DevOps**\n\tDocker, Kubernetes, GitHub Actions, Azure DevOps, CI/CD\n\n  **Cloud & Infrastructure**\n\tAWS, Azure\n\n  **Other**\n\tPandas, NumPy, scikit-learn, TensorFlow, Airflow, MLflow, Spark, Flink, Luigi, Data Engineering, ML, Agile",
  "apply_company": "GFT"
}