{
  "name": "Tomasz Lee",
  "role_name": "Senior Data Engineer",
  "email": "tomasz.lee8@outlook.com",
  "phone": "+48 732 145 942",
  "address": "Warsaw, Poland",
  "linkedin": "https://www.linkedin.com/in/tomasz-lee-b9a25a391/",
  "profile_summary": "Results-driven Senior Data Engineer with 9+ years of experience in leveraging **Apache Spark**, **Python**, **Java**, and **Scala** to design and implement robust data processing solutions. Proficient in using **SQL** and **NoSQL** databases, skilled in **MLOps** practices, and experienced with cloud platforms including **Azure**, **AWS**, and **GCP**. Strong background in distributed systems with extensive hands-on expertise in **Apache Kafka** for real-time data streaming and processing. Proven track record of delivering high-quality solutions, optimizing performance, and collaborating effectively in Agile environments. Known for leadership in driving development projects to successful completion while enhancing team productivity.",
  "education": [
    {
      "degree": "Master of Computer Science",
      "category": "",
      "from_year": "Apr 2012",
      "to_year": "Oct 2014",
      "location": "",
      "university": "National University of Singapore"
    },
    {
      "degree": "Bachelor of Computer Science",
      "category": "",
      "from_year": "Apr 2008",
      "to_year": "Mar 2012",
      "location": "",
      "university": "National University of Singapore"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "CD Projekt RED",
      "from_date": "May 2022",
      "to_date": "Oct 2025",
      "location": "Warsaw, Poland",
      "responsibilities": "Leveraged **Apache Spark** and **Python** to build robust data pipelines, ensuring efficient data processing and analytics.\nUtilized **Kafka** for real-time data ingestion and processing, enhancing data flow efficiency by **30%**.\nDesigned and executed data storage solutions using **NoSQL** databases, scaling storage capabilities by **50%** to support increasing data volumes.\nImplemented data transformation processes within **Databricks**, optimizing resource usage and reducing operational costs by **20%**.\nCollaborated with cross-functional teams following **Agile** methodologies to streamline project workflows and deliver projects on time.\nDeveloped batch processing frameworks using **Java** and **Scala**, improving data analytics processes by **25%**.\nOptimized SQL queries and performed database tuning tasks, resulting in a **40%** reduction in query response times.\nIntegrated **Azure** and **AWS** cloud services for scalable data solutions, enhancing system reliability and availability.\nParticipated in the implementation of **MLOps** practices to deploy machine learning models efficiently, facilitating data-driven decision-making.\nFostered a culture of continuous improvement by regularly reviewing and refining development processes."
    },
    {
      "role": "Software Engineer",
      "company": "Sea Group",
      "from_date": "Mar 2018",
      "to_date": "Apr 2022",
      "location": "Shopee, Singapore",
      "responsibilities": "Utilized **Apache Kafka** for effective event streaming in data pipelines, improving data flow efficiency by 20%.\nDeveloped data processing solutions using **Python** in combination with **Apache Spark**, enhancing data analytics capabilities to handle over **1TB** of data daily.\nDesigned and implemented data storage solutions utilizing **SQL** and **NoSQL** databases, optimizing query performance to achieve a **15%** reduction in response times.\nLeveraged **Azure** and **AWS** cloud services for deploying scalable data engineering solutions, contributing to a cost-saving of up to **10%** on infrastructure.\nAdopted Agile methodologies to streamline project workflows, resulting in a **35%** faster project completion rate.\nCollaborated with cross-functional teams to define data requirements and establish best practices for data governance.\nBuilt and maintained ETL pipelines using **Apache Flume** and **Spark Streaming**, ensuring real-time data processing for analytics.\nCreated and managed data dashboards and reporting tools to visualize key metrics for business stakeholders, increasing data accessibility.\nLed training sessions on **MLOps** for team members to enhance knowledge transfer and implementation of machine learning models.\nConducted performance tuning and optimization of data systems, achieving an overall improvement in system throughput by **25%**.\n"
    },
    {
      "role": "Software Developer",
      "company": "Grab Holdings Inc",
      "from_date": "Jan 2015",
      "to_date": "Feb 2018",
      "location": "Singapore",
      "responsibilities": "Utilized **Apache Spark** and **Scala** to process large datasets efficiently, achieving a 30% reduction in data processing time.\nLeveraged **Python** for data manipulation and analysis, enhancing data accuracy and insight delivery.\nDesigned and managed **SQL** databases to improve data retrieval processes, resulting in a 25% faster query response rate.\nImplemented **Kafka** for real-time data streaming, optimizing communication between microservices and handling peaks with resiliency.\nWorked with **Databricks** to streamline data engineering workflows, enabling faster data transformation and analysis.\nCollaborated in an **Agile** environment, participating in daily standups and sprint planning to enhance team productivity by 15%.\nManaged cloud-based solutions on **Azure**, integrating with data lakes to enhance storage solutions and reduce costs by 20%.\nExecuted data ingestion pipelines using **Flume** and **Spark Streaming**, ensuring timely data availability for analytical processes.\nAssisted in constructing **NoSQL** data stores to support unstructured data processing, improving system scalability.\nDelivered comprehensive technical documentation and reports, facilitating effective knowledge transfer among team members and stakeholders."
    }
  ],
  "skills": " **Programming Languages**\n\t Java, Python, JavaScript, TypeScript, C#, SQL, Scala\n\n **Backend Frameworks**\n\t NodeJS, ExpressJS, NestJS, .NET, Entity Framework, Microservices\n\n **Frontend Frameworks**\n\t ReactJS, NextJS, VueJS, NuxtJS, Angular, Material UI, Three.js, D3.js, React Native, Flutter, Chakra UI, TailwindCSS\n\n **API Technologies**\n\t RESTful API, GraphQL, Apache Kafka\n\n **Serverless and Cloud Functions**\n\t AWS, Azure, GCP\n\n **Databases**\n\t MSSQL Server, MySQL, PostgreSQL, MongoDB, DynamoDB, CosmosDB, NoSQL\n\n **DevOps**\n\t CI/CD pipelines, MLOps\n\n **Cloud & Infrastructure**\n\t Apache Spark, Databricks, Spark Streaming, Flume\n\n **Other**\n\t UX/UI Design, Git, GitHub, Testing Tools: NUnit, xUnit, Selenium, Moq, Postman, Cypress, JMeter, Jest, Blockchain: Solidity, Ether.js, Web3.js, Ethereum, Agile",
  "apply_company": "EPAM Systems"
}