{
  "name": "Damian Franciszek Pospiech",
  "role_name": "AI Engineer",
  "email": "damianpos127@outlook.com",
  "phone": "+48 732 143 608",
  "address": "Mikolow, Poland",
  "linkedin": "https://www.linkedin.com/in/damian-pospiech-187801395/",
  "profile_summary": "AI Engineer with 13+ years of experience specializing in AI/ML engineering and large language models (LLMs), leveraging robust expertise in **Python**, **LangChain**, **Hugging Face Transformers**, and the **OpenAI API**. Proficient in designing and implementing **retrieval-augmented generation (RAG)** solutions and integrating vector databases to enhance AI capabilities.\n\nExperienced in developing scalable applications utilizing **FastAPI**, microservices, and deploying cloud-native systems on **AWS**, **Azure**, and **GCP**. Adept in building AI deployment pipelines with a strong focus on compliance and data privacy, ensuring adherence to industry standards such as HIPAA, FHIR, and PCI DSS.\n\nSkilled in orchestrating containerized applications with **Docker** and **Kubernetes**, and implementing event-driven architectures supported by **CI/CD** practices. Recognized for strong communication and collaboration skills, driving effective teamwork and project success across healthcare and financial sectors.",
  "education": [
    {
      "degree": "Bachelor's degree in Computer Science",
      "category": "Computer Science",
      "from_year": "2007",
      "to_year": "2012",
      "location": "UK",
      "university": "University of Cambridge"
    }
  ],
  "experience": [
    {
      "role": "AI Engineer",
      "company": "Codebridge",
      "from_date": "Apr 2021",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "Implemented AI/ML engineering solutions, deploying **Large Language Models (LLMs)** using **Hugging Face Transformers** and **OpenAI API** for intelligent feature integration.\nDesigned and built scalable microservices architectures utilizing **Docker** and **Kubernetes** (version AKS/EKS), ensuring secure and compliant data processing in alignment with data privacy standards.\nDeveloped and maintained REST and **GraphQL** APIs using **Python** and **FastAPI** to facilitate efficient data retrieval and processing, while ensuring adherence to compliance regulations including HIPAA and GDPR.\nIntegrated retrieval-augmented generation (RAG) capabilities leveraging vector databases for enhanced document parsing and anomaly detection.\nDevised AI deployment pipelines utilizing **MLflow** and **Airflow**, managing model training and deployment workflows across **Azure** and **AWS**, enabling fast iteration and production-level performance.\nCollaborated effectively with cross-functional teams, communicating complex technical concepts clearly and fostering a collaborative development environment.\nCreated robust testing strategies using **Postman**, **Jest**, and **PyTest**, ensuring comprehensive coverage across unit, integration, and E2E scenarios while maintaining high security standards.\nExecuted data privacy and security compliance measures across projects, aligning with strict regulations to protect sensitive information in the domains of health and finance.\nDeployed custom ML models for risk scoring and fraud detection with real-time monitoring capabilities integrated into existing systems for enhanced operational insights.\nMaintained cloud infrastructure and services across **Azure** and **AWS** platforms, leveraging scalability to support evolving business needs while ensuring 99.9% uptime.\n"
    },
    {
      "role": "Senior Software Engineer",
      "company": "Grupa Azoty",
      "from_date": "Oct 2015",
      "to_date": "Mar 2021",
      "location": "Poland",
      "responsibilities": "Developed AI/ML solutions leveraging **Python**, **LangChain**, and **Hugging Face Transformers** for implementing Large Language Models (LLMs) to enhance natural language processing capabilities in financial applications.\nDesigned and maintained robust **microservices** architectures in **FastAPI** for efficient model serving and integration, ensuring scalable deployment of AI applications in high-demand environments.\nImplemented **AI deployment pipelines** using **Docker** and **Kubernetes** to streamline the deployment and management of machine learning models, enhancing operational efficiency by **30%**.\nExecuted real-time data processing workflows utilizing **Azure** and **GCP** for compliance and data privacy, significantly reducing data handling errors by **25%**.\nCollaborated on the development of **retrieval-augmented generation (RAG)** models for improving information relevancy in financial tools, consequently increasing user engagement by **15%**.\nBuilt secure REST and GraphQL APIs for seamless interaction with AI services while adhering to industry standards for **security** and **compliance**, fostering user trust and reliability.\nManaged integration of **vector databases** to optimize retrieval processes in LLM applications, accelerating query performance by **40%**.\nEffectively communicated technical concepts to cross-functional teams, promoting collaboration and alignment on project goals while maintaining high standards of agile practices."
    },
    {
      "role": "Software Engineer",
      "company": "GoodCore",
      "from_date": "Jan 2012",
      "to_date": "Sep 2015",
      "location": "UK",
      "responsibilities": "Implemented AI/ML engineering strategies using **scikit-learn**, **LightGBM**, and **TensorFlow**, focusing on personalization of product listings and optimizing conversion rates through real-time behavioral insights.\nEngineered and deployed large language models (LLMs) using **LangChain**, **Hugging Face Transformers**, and **OpenAI API**, contributing to advanced data processing and enhancing user interaction.\nDeveloped and maintained **microservices** architecture with **Python** and **FastAPI**, ensuring seamless integration of AI features and high system reliability in the deployment to **Azure** and **AWS** platforms.\nUtilized **Docker** and **Kubernetes** for creating scalable AI deployment pipelines, ensuring efficient resource utilization and compliance with **data privacy** and **security** regulations.\nDesigned REST and GraphQL APIs for robust interaction with AI models, applying best practices in **security** to safeguard sensitive data and ensure compliance with industry standards.\nCollaborated across teams to reinforce **data privacy**, implement robust security measures, and streamline workflows, facilitating clear communication with stakeholders and enhancing project outcomes.\nArchitected data retrieval and storage solutions using **vector databases**, optimizing for retrieval-augmented generation (RAG) capabilities and enhancing the performance of AI-driven applications.\nAnalyzed and documented compliance processes, ensuring alignment with regulations and facilitating audits while fostering an environment of **clear communication** and **collaboration** throughout the organization.\nEngaged in continuous learning and improvement practices, leveraging cutting-edge technologies to align the AI capabilities with business goals, resulting in an increase in processing efficiency by **30%**."
    }
  ],
  "skills": " **Programming Languages:**\n\tPython, JavaScript/TypeScript\n\n**Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n**Frontend Frameworks:**\n\tReact, Vue, Angular\n\n**API Technologies:**\n\tREST, GraphQL, OpenAI API\n\n**Serverless and Cloud Functions:**\n\tAWS: Lambda, Azure: App Services\n\n**Cloud & Infrastructure:**\n\tAWS: ECS, RDS, S3, Azure: Blob Storage, SQL Database, GCP, Docker, Kubernetes\n\n**Databases:**\n\tPostgreSQL, MySQL, MongoDB, Redis, vector databases\n\n**DevOps:**\n\tGitHub Actions, GitLab CI/CD, Terraform, Ansible, Helm, Docker Compose\n\n**Other:**\n\tAI/ML engineering, Large Language Models (LLMs), LangChain, Hugging Face Transformers, microservices, retrieval-augmented generation (RAG), AI deployment pipelines, data privacy, security, compliance, clear communication skills, collaboration skills"
}