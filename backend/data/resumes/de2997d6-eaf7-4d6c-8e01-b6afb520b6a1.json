{
  "name": "Patryk Zaslawski",
  "role_name": "Senior Software Engineer - AI",
  "email": "patrykzas0428@outlook.com",
  "phone": "+48669862402",
  "address": "Gdanski, Poland",
  "linkedin": "https://www.linkedin.com/in/patryk-zaslawski-6b04a8397/",
  "profile_summary": "As a high-impact Senior Software Engineer specializing in AI, I bring 8+ years of experience in software engineering, focusing on developing robust machine learning solutions and data-driven applications. My proficiency lies in **Python**, particularly with **TensorFlow**, **PyTorch**, and **Scikit-learn** for AI model development, combined with expertise in cloud platforms like **Google Cloud Platform (GCP)** including **GKE**, **BigQuery**, **BigTable**, **GCS**, and **Dataproc** for scalable infrastructure. I have a strong background in database management using **MongoDB** and **Redis**, ensuring high performance and reliability. Additionally, I excel in orchestrating workflows with tools like **Kubeflow**, **Airflow**, and **Prefect**, as well as leveraging **Grafana** and **Sentry** for monitoring and optimization. My experience with CI/CD pipelines and Agile methodologies guarantees timely and efficient delivery of projects. Through the use of version control systems like **Gitlab** and project management tools such as **Jira**, **Productboard**, and **PagerDuty**, I ensure seamless collaboration and effective incident management, driving technology solutions aligned with business objectives.",
  "education": [
    {
      "degree": "Bachelor’s Degree",
      "category": "Computer Science",
      "from_year": "2014",
      "to_year": "2017",
      "location": "United Kingdom",
      "university": "The University of Manchester"
    }
  ],
  "experience": [
    {
      "role": "Senior Software Engineer - AI",
      "company": "Binary Studio",
      "from_date": "Aug 2023",
      "to_date": "Present",
      "location": "United Kingdom (Remote)",
      "responsibilities": "Developed and maintained scalable **Python** applications leveraging **GKE** and **Google Cloud Platform** for streamlined deployment and management, optimizing performance by up to **40%**.\nArchitected and implemented data processing pipelines using **Apache Airflow** and **Spark** on **Dataproc**, ensuring efficient handling of large datasets and real-time analytics.\nIntegrated machine learning models using **TensorFlow** and **PyTorch** within applications, resulting in improved predictive capabilities and a **25%** increase in model accuracy.\nDesigned robust data storage solutions with **BigQuery**, **BigTable**, **MongoDB**, and **Redis**, implementing indexing and caching strategies to enhance query performance by **30%**.\nLed CI/CD pipeline development using **Gitlab** and **Jira**, facilitating automated testing and deployment processes which reduced release times by **50%**.\nCollaborated on **Agile** development teams, enhancing project delivery speed and ensuring alignment with product goals through regular check-ins and reviews.\nImplemented monitoring and error tracking solutions using **Grafana** and **Sentry**, resulting in improved application uptime and quicker resolution of issues by **60%**.\nFostered a DevOps culture among team members by promoting MLOps practices, improving collaboration between development and operations teams.\nMentored junior engineers in **Python**, **MLOps**, and cloud-native design patterns while promoting the adoption of agile methodologies.\nOptimized data workflows and operations through **Prefect** and best practices in data orchestration to ensure high reliability and performance."
    },
    {
      "role": "Software Engineer",
      "company": "Ardigen",
      "from_date": "Mar 2020",
      "to_date": "Aug 2023",
      "location": "Poland",
      "responsibilities": "- Led the development of scalable microservices architecture using **Python** with frameworks such as **FastAPI**, **Django**, and **Flask** to enhance performance and maintainability.\n- Designed and implemented RESTful and gRPC APIs in **Python** for secure communication between banking mobile applications while ensuring real-time transaction updates.\n- Refactored legacy systems from **.NET/VB.NET** to **Python** microservices, preserving critical functionality while enhancing compatibility with modern platforms.\n- Developed user-centric frontends integrated with **Python** backends using frameworks like **Angular**, **React**, and **Next.js**, utilizing **Redux** for improved UI responsiveness.\n- Built a real-time transaction monitoring dashboard using **Python** APIs with an **Angular** UI, integrated with **Power BI** for advanced analytics and reporting.\n- Streamlined ACH transfers, credit card payments, and wire transfers through system integrations with **MuleSoft** and **Python** services, improving transaction efficiency by **30%**.\n- Ensured robust data protection in **Python** services by integrating **encryption**, **OAuth 2.0**, and **JWT** to maintain compliance with financial regulations.\n- Optimized query performance in **SQL Server**, **MongoDB**, and **Redis** via **Python** services to ensure high availability for transactional data, reducing response time by **50%**.\n- Employed **Kafka** and **RabbitMQ** with **Python** microservices to create an event-driven architecture capable of processing large-scale financial transactions.\n- Managed messaging between microservices by configuring and utilizing **Azure Service Bus** for improved modularity and decoupling.\n- Implemented secure authentication in **Python** APIs using **OAuth 2.0** and **OpenID Connect** for enhanced security.\n- Developed fraud detection mechanisms in **Python**, integrating **Azure Machine Learning** models, successfully identifying **95%** of suspicious activities.\n- Created secure payment gateway integrations in **Python** ensuring PCI compliance for **ACH**, credit card, and wire transfer interoperability.\n- Built serverless components in **Python** using **AWS Lambda** and **Azure Functions** for ETL processes, reducing infrastructure costs by **40%**.\n- Integrated the **ELK stack** (Elasticsearch, Logstash, Kibana) with **Python** services for centralized logging, enhancing monitoring efficiency.\n- Managed **Kubernetes** clusters for deploying **Python** microservices, ensuring high availability and enabling seamless rolling updates.\n- Applied best practices in **Python** development, including automated testing with **PyTest** and CI/CD pipelines with **Azure DevOps** for consistent delivery and reliability.\n- Contributed to the development of integration solutions in **Python** with **MuleSoft**, ensuring secure financial data exchanges with external partners.\n- Leveraged **CI/CD** practices using **GitLab** and **Jira** for automated quality assurance and continuous delivery, streamlining development processes."
    },
    {
      "role": "Software Engineer",
      "company": "Altum Software",
      "from_date": "Oct 2017",
      "to_date": "Feb 2020",
      "location": "United Kingdom",
      "responsibilities": "Utilized **Python** in conjunction with **Google Cloud Platform** tools such as **GKE**, **BigQuery**, **BigTable**, and **GCS** to design and optimize AI-centric backend services, enhancing performance and scalability in e-commerce applications.\nDeveloped robust RESTful APIs using **Python** to facilitate high-volume transaction processing, ensuring seamless integration with frontend interfaces for real-time user interactions, impacting **95%** of customer transactions.\nLeveraged **MongoDB** and **Redis** alongside **Python** to manage unstructured data efficiently, enhancing application performance metrics by **30%** through reduced response times.\nImplemented CI/CD pipelines using **Gitlab** and **Jira** to ensure efficient delivery cycles, achieving over **98%** uptime and continuous deployment of features.\nEngaged **Airflow** for orchestrating ML workflows with **TensorFlow** and **Scikit-learn**, optimizing training processes and enhancing model accuracy by **20%** through automation.\nDesigned data pipelines on **Dataproc** with **Spark** to process large datasets, resulting in a **50%** improvement in data analysis throughput.\nAutomated observability for AI services implementing **Grafana** and **Sentry** for monitoring, leading to quicker diagnosis and incident response times by **40%**.\nBuilt user-friendly frontends integrated with **Python** backends using frameworks like **React** and **Next.js**, ensuring cross-device compatibility and high engagement rates.\nConducted load and performance testing with **k6** and **Apache JMeter**, validating system capability to handle peak loads of **5000+** concurrent users.\nFacilitated agile principles and **MLOps** practices in the development lifecycle to enhance collaboration and iteration speed across teams.\nDeveloped and maintained scalable microservices architecture using **Kubeflow**, ensuring robust and efficient machine learning model deployment for production applications.\nCollaborated in cross-functional scrum teams to implement user-centric features, refining product backlog through **Productboard**, ultimately resulting in a **15%** increase in user satisfaction scores."
    }
  ],
  "skills": "**Programming Languages:**\n\tPython\n\n**Backend Frameworks:**\n\tFastAPI, Django, Flask, Spring Boot\n\n**Frontend Frameworks:**\n\tAngular (1–16), React (15–18), Next.js, Vue.js (2/3), Blazor\n\n**API Technologies:**\n\tREST & gRPC APIs\n\n**Serverless and Cloud Functions:**\n\tAWS (Lambda), GKE\n\n**Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare), MongoDB (Gaming), Redis\n\n**DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, CI/CD, Grafana, Sentry, Agile\n\n**Cloud & Infrastructure:**\n\tGoogle Cloud Platform, GCS, BigQuery, BigTable, Dataproc, VertexAI, Azure (App Services, Blob, SQL)\n\n**Other:**\n\tAuthentication & Security: Keycloak (OIDC, RBAC), JWT, OAuth2, Let’s Encrypt, Nginx, Certbot, MLOps, TensorFlow, PyTorch, Scikit-learn, Kubeflow, Airflow, Prefect, Jira, Productboard, PagerDuty"
}