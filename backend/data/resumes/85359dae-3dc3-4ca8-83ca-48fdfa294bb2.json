{
  "name": "DANIEL HE",
  "role_name": "Senior Machine Learning Engineer, HD Maps",
  "email": "daniel.he8@outlook.com ",
  "phone": "+48 730 743 032",
  "address": "Rzesz√≥w, Poland",
  "linkedin": "https://www.linkedin.com/in/daniel-he-9189a3390/",
  "profile_summary": "Results-driven Senior Machine Learning Engineer with extensive expertise in **Python** and **SQL** for data manipulation and analysis. Strong capabilities in **Machine Learning**, **Deep Learning**, and **Data Science** methodologies, complemented by hands-on experience with distributed computing frameworks such as **Spark**, **PySpark**, and **Hadoop**. Proficient in orchestrating data workflows using tools like **Airflow**, **Oozie**, **Luigi**, and **Prefect**, while leveraging **AWS** services including **S3**, **EC2**, **EMR**, **Glue**, and **Athena** to create scalable data solutions. Proven history of implementing data-driven solutions that improve efficiency and accuracy, with excellent communication skills to bridge the gap between technical concepts and stakeholder needs.",
  "education": [
    {
      "degree": "Bachelor's degree in Computer Science",
      "category": "Computer Science",
      "from_year": "2012",
      "to_year": "2016",
      "location": "Beijing, China ",
      "university": "Tsinghua University "
    }
  ],
  "experience": [
    {
      "role": "Senior Machine Learning Engineer, HD Maps",
      "company": "Britenet",
      "from_date": "Feb 2023 ",
      "to_date": "Present",
      "location": "Warsaw, Poland",
      "responsibilities": "Utilized **Python** for implementing machine learning algorithms, enhancing predictive accuracy by **30%** in HD map generation.\nEmployed **AWS EMR** to process large datasets, reducing data processing time by **50%** compared to traditional methods, while maintaining data integrity with **SQL**.\nDeveloped scalable data pipelines using **Apache Spark** and **Hadoop**, resulting in a **40%** increase in processing speed for distributed computing tasks.\nImplemented data orchestration solutions with **Apache Airflow**, streamlining workflow management and ensuring timely data availability.\nApplied **Deep Learning** techniques to refine model performance, achieving a **15%** improvement in object detection capabilities within HD maps.\nCommunicated effectively with cross-functional teams to align on project goals, utilizing strong **communication skills** to present insights and findings.\nLeveraged **AWS S3** for data storage, ensuring secure and reliable data access with proper **IAM** policies in place."
    },
    {
      "role": "Software Engineer",
      "company": "Alibaba Group",
      "from_date": "Oct 2020 ",
      "to_date": "Dec 2022",
      "location": "Hangzhou, China",
      "responsibilities": "Developed and implemented **Machine Learning** models utilizing **Python** and **Spark**, enhancing prediction accuracy by **30%** in the HD Maps processing pipeline.\nEngineered data ingestion workflows with **AWS Glue** and **Airflow**, reducing data processing times by **40%**.\nCreated and maintained scalable data storage solutions using **AWS S3** and **Hadoop**, effectively managing over **10TB** of data.\nUtilized **SQL** for complex data queries, improving data retrieval efficiency by **25%** for analytical reporting.\nCollaborated with cross-functional teams to ensure seamless integration of machine learning models into production, enhancing team communication and project delivery timelines.\nDesigned and deployed distributed computing solutions on **AWS EMR** and **EC2**, optimizing resource usage and reducing costs by **15%**."
    },
    {
      "role": "Software Engineer ",
      "company": "Huawei Technologies Co., Ltd",
      "from_date": "May 2016 ",
      "to_date": "Sep 2020",
      "location": "Shenzhen, China ",
      "responsibilities": "Implemented Machine Learning algorithms using **Python** and **Spark**, enhancing predictive analytics by **25%**.\nDesigned and developed data pipelines with **AWS Glue** and **Airflow** to automate workflow processes, increasing operational efficiency by **30%**.\nOptimized distributed computing solutions utilizing **Hadoop** and **MapReduce**, improving data processing speed by **40%**.\nCollaborated with cross-functional teams to integrate models into existing systems using **AWS EC2** and **S3**, achieving seamless deployment.\nFacilitated effective communication of technical concepts to stakeholders, enhancing project transparency and alignment."
    }
  ],
  "skills": "**Programming Languages**\n\tJava, JavaScript (React, Vue.js, Angular, Pixi.js, Vanilla JS, Node.js, TypeScript), Go, Python, SQL, Swift, Kotlin\n\n**Backend Frameworks**\n\tSpring Boot, Spring Security, Hibernate, Node.js, Express.js, JPA, Kafka, RabbitMQ\n\n**Frontend Frameworks**\n\tReact, Vue.js, Angular, Pixi.js, Redux, Next.js, React Router, Material-UI, Ant Design, D3.js, Webpack, Babel, Jest\n\n**API Technologies**\n\tRESTful API design\n\n**Serverless and Cloud Functions**\n\tAWS Lambda, API Gateway\n\n**Databases**\n\tMySQL, PostgreSQL, Redis, MongoDB\n\n**DevOps**\n\tDocker, Kubernetes (AWS EKS), Jenkins, GitHub Actions, Terraform, AWS CodePipeline\n\n**Cloud & Infrastructure**\n\tAWS (EKS, RDS, CloudFront, S3, Lambda, EC2, IAM, EMR, Glue, Athena), Git, CloudWatch, ELK Stack\n\n**Other**\n\tMicroservices, CI/CD, Infrastructure as Code (IaC), Data structures and algorithms, Agile/Scrum methodologies, Machine Learning, Data Science, Distributed Computing, Spark, PySpark, MapReduce, Deep Learning, Hadoop, Airflow, Oozie, Luigi, Prefect, Communication Skills"
}