{
  "name": "Damian Franciszek Pospiech",
  "role_name": "Senior Data Engineer",
  "email": "damianpos127@outlook.com",
  "phone": "+48 732 143 608",
  "address": "Mikolow, Poland",
  "linkedin": "https://www.linkedin.com/in/damian-pospiech-261821397/",
  "profile_summary": "Senior Data Engineer with 13+ years of experience leveraging **AWS** for scalable cloud solutions and adept in **CI/CD** practices, including **Infrastructure-as-Code** to streamline deployments. Proficient in **SQL** for robust data management and analytics, as well as **Python** and **Scala** for developing data processing applications. Highly experienced in **Monitoring** and **Logging** to ensure high availability and performance of data systems.\n\nFurthermore, I possess strong capabilities in building high-performance applications, particularly in the healthcare and financial sectors. My tech stack includes **JavaScript/TypeScript**, **Flutter**, **React**, **Next.js**, **Vue**, **Node.js**, **FastAPI**, and **Django**. I have also contributed to AI/ML platforms that facilitate predictive analytics and real-time processing. With hands-on expertise in compliance-driven development (HIPAA, FHIR, PCI DSS, SOC 2), and a solid background in MLOps using **MLflow**, **Airflow**, and **Kubeflow**, I excel at delivering innovative and secure solutions while fostering effective **communication** and demonstrating a strong sense of **ownership**.",
  "education": [
    {
      "degree": "Bachelor's degree in Computer Science",
      "category": "Computer Science",
      "from_year": "2007",
      "to_year": "2012",
      "location": "UK",
      "university": "University of Cambridge"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "Codebridge",
      "from_date": "Apr 2021",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "Implemented CI/CD practices for data engineering projects, ensuring smooth workflow integration using **AWS** and **Infrastructure-as-Code** tools, enabling seamless deployments across **5** environments.\nDeveloped data pipelines with **Python** and **SQL**, focusing on efficient data processing and transformation while maintaining data integrity and contract compliance for **5 million+** records per day.\nUtilized **Spark** for big data processing to support advanced analytics initiatives, achieving processing speeds **3x** faster than previous solutions.\nMonitored and logged data processes effectively with industry-standard tools, improving data reliability and minimizing downtime by **30%** through proactive troubleshooting.\nLed initiatives to improve user experiences (UX) by collaborating with cross-functional teams to ensure data products met organizational needs and user expectations.\nMaintained clear communication channels with stakeholders, providing regular project updates and incorporating feedback to enhance system performance and usability.\nTook ownership of project milestones and deliverables, ensuring alignment with business objectives and timelines, contributing to project success in **4** key areas: efficiency, reliability, scalability, and security.\nEvaluated and optimized existing data infrastructures using **AWS** services, implementing **monitoring** solutions that resulted in a **20%** increase in system performance and availability.\nEducated and trained team members on best practices related to **Python**, **Spark**, and **CI/CD methodologies**, fostering a culture of continuous improvement and knowledge sharing."
    },
    {
      "role": "Software Engineer",
      "company": "Grupa Azoty",
      "from_date": "Oct 2015",
      "to_date": "Mar 2021",
      "location": "Poland",
      "responsibilities": "Utilized **AWS** and **Spark** to enhance data processing capabilities, ensuring efficient data flow and management across large datasets.\nImplemented CI/CD pipelines leveraging **Python** and **Infrastructure-as-Code** tools, streamlining deployment processes and improving delivery speed by **30%**.\nMigrated legacy systems to modern architectures, employing **SQL** to optimize database interactions and performance metrics, achieving **25%** reduction in query time.\nDeveloped effective data contracts to ensure data integrity and reduce discrepancies in financial reporting.\nCollaborated effectively with cross-functional teams to improve user experience (UX) in data analytics tools, enhancing user satisfaction scores by **15%**.\nStreamlined logging and monitoring processes through robust solutions, ensuring proactive identification of bottlenecks and reducing downtime by **10%**.\nDemonstrated strong communication skills by leading project updates and engaging stakeholders, fostering ownership and buy-in for data initiatives.\nEmployed **Python** and **Scala** for advanced data manipulation and transformation, supporting complex analytics requirements in financial contexts."
    },
    {
      "role": "Software Engineer",
      "company": "GoodCore",
      "from_date": "Jan 2012",
      "to_date": "Sep 2015",
      "location": "UK",
      "responsibilities": "Utilized **AWS** for cloud infrastructure and deployed **CI/CD** pipelines, ensuring consistent and automated data processing workflows while maintaining high standards of **Monitoring** and **Logging**.\nDesigned data infrastructure and frameworks using **Python** and **Scala** to optimize data flow and analytics for large datasets, achieving processing speeds up to **5x** faster than previous implementations.\nDeveloped and maintained **SQL** databases for efficient data retrieval and storage while ensuring data integrity through robust **Data Contracts**, directly enhancing overall system reliability.\nCollaborated closely across teams to drive improvements in **UX**, fostering clear **Communication** to ensure all stakeholders are aligned on project goals and timelines, leading to an increase in project delivery speed by **30%**.\nExercised **Ownership** over multiple data engineering projects by establishing best practices in code management and deploys, resulting in reduced deployment errors by **40%**.\nImplemented structured data solutions in accordance with organizational standards, promoting easy accessibility and analytics capabilities across the organization.\nContributed to the team's agile practices by presenting data insights and fostering brainstorming sessions, significantly enhancing collective problem-solving abilities."
    }
  ],
  "skills": "**Programming Languages:**\n\tPython, Scala\n\n**Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n**Frontend Frameworks:**\n\tJavaScript/TypeScript: React, Vue, Angular\n\n**API Technologies:**\n\tKeycloak (OIDC, RBAC), OAuth2, JWT\n\n**Serverless and Cloud Functions:**\n\tAWS: Lambda, ECS\n\n**Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare), MongoDB (Gaming), Redis, SQL\n\n**DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, CI/CD, Terraform, Ansible, Helm, Docker Compose\n\n**Cloud & Infrastructure:**\n\tAWS: RDS, S3, Azure: App Services, Blob Storage, SQL Database, Infrastructure-as-Code\n\n**Other:**\n\tMLflow, Airflow, Kubeflow, Monitoring, Logging, Data Contracts, UX, Communication, Ownership",
  "apply_company": "Finanzguru"
}