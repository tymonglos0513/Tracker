{
  "name": "Marcin Karol Kotlinski",
  "role_name": "Junior Data Engineer",
  "email": "marcinkot55@outlook.com",
  "phone": "+48 732 779 243",
  "address": "Zgorzelec, Poland",
  "linkedin": "https://www.linkedin.com/in/marcin-karol-kotlinski-bb2520397/",
  "profile_summary": "As a data-focused professional with a strong foundation in **Python**, **Java**, and cloud technologies such as **AWS** and **Azure**, I bring a unique blend of Full Stack Development and data engineering expertise. With 8 years of overall experience, I specialize in building scalable solutions using **Big Data** technologies including **Spark**, **Hive**, and **Impala**. My skills in **Data Warehousing**, **Data Modeling**, and **HDFS** empower me to optimize database performance and enhance data management.\nI have successfully executed numerous projects integrating data pipelines with robust analytics capabilities, and my proficiency in **Bash** scripting aids in automating processes and ensuring efficiency. Through hands-on experience in developing high-performance applications, I contribute to innovative solutions that meet business goals while maintaining compliance with industry standards.",
  "education": [
    {
      "degree": "Master’s Degree in Computer Science",
      "category": "",
      "from_year": "2017",
      "to_year": "2018",
      "location": "UK",
      "university": "University of Oxford"
    },
    {
      "degree": "Bachelor’s Degree in Computer Science",
      "category": "",
      "from_year": "2015",
      "to_year": "2017",
      "location": "UK",
      "university": "University of Oxford"
    }
  ],
  "experience": [
    {
      "role": "Junior Data Engineer",
      "company": "EVNE Developers",
      "from_date": "Oct 2023",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "Utilized **Python** and **Bash** to develop data pipelines for processing and managing large-scale datasets in compliance with various data governance regulations.\nAssisted in the implementation of **Big Data** technologies such as **Apache Spark** and **Hive** for effective data storage and processing, leading to a **30%** decrease in query execution times.\nContributed to data warehousing efforts by designing and optimizing data models, ensuring efficient **database query execution plans** for enhanced performance.\nCollaborated with the team to maintain and manage cloud storage solutions using **AWS S3** and **Azure** services, facilitating **20%** cost reductions in data storage.\nParticipated in data transformation processes using **HDFS** and **HBase**, ensuring seamless data flow and integrity across different environments.\nSupported ETL processes using **Impala** for high-performance querying, enabling real-time data analytics and reporting capabilities.\nAssisted in the integration of data from multiple sources into cohesive datasets, employing **Data Modeling** techniques for improved data usability and analysis.\nEngaged in troubleshooting and fine-tuning existing data workflows to enhance processing speeds by over **15%**, ensuring timely data availability for analytics.\nParticipated in team discussions to analyze current data infrastructure, providing input based on insights from hands-on experience with **Big Data** tools and methodologies."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Air Force",
      "from_date": "Oct 2021",
      "to_date": "Sep 2023",
      "location": "Poland",
      "responsibilities": "Utilized **Python** and **Bash** to automate data processing tasks, ensuring seamless ETL pipelines for batch and real-time data ingestion in financial applications.\nEmployed **Azure** services alongside **HDFS** for data storage and management, optimizing access and retrieval times which improved data workflow efficiency by **30%**.\nImplemented data warehousing solutions using **AWS S3** to store large datasets, facilitating efficient querying and reporting for analytics teams.\nDeveloped and executed database query plans that enhanced performance metrics by **25%**, focusing on optimizing the speed of data retrieval in high-volume systems.\nEngaged with **Spark**, **Hive**, and **Impala** to process big data frameworks, achieving data processing thresholds of over **10TB** per day, which significantly boosted analytics capabilities.\nCollaborated with cross-functional teams to model data architecture effectively, ensuring alignment with business objectives and user needs.\nContributed to data analysis projects, leveraging programming skills for data cleansing and transformation to maximize data quality.\nAssisted in the integration of big data technologies with existing architecture to create cohesive solutions for improved analytics and reporting."
    },
    {
      "role": "Software Engineer",
      "company": "DeepInspire",
      "from_date": "Sep 2018",
      "to_date": "Aug 2021",
      "location": "UK",
      "responsibilities": "Utilized **Python** and **Bash** to develop data pipelines for processing large datasets, ensuring efficient data flow and transformation in compliance with **AWS** and **Azure** cloud services.\nExecuted complex queries using **Hive**, **Impala**, and **HBase** for data analysis and storage optimization, improving data retrieval speed by **30%**.\nImplemented **Spark** to handle batch and stream processing workflows, significantly enhancing data processing capabilities and reducing execution times by **40%**.\nDeveloped and maintained data models adhering to best practices in **Data Warehousing**, facilitating better reporting and analytics across platforms.\nManaged large-scale data storage solutions in **HDFS** and **S3**, ensuring secure and efficient access to data assets while maintaining compliance with **GDPR**.\nCollaborated with cross-functional teams to optimize database query execution plans, improving overall system performance and query response times by **25%**.\nAssisted in the implementation of big data strategies, leveraging expertise in **Big Data** technologies to support business objectives and enhance decision-making processes."
    }
  ],
  "skills": "**Programming Languages:**\n\tPython, Java, Bash\n\n**Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n**Frontend Frameworks:**\n\tJavaScript/TypeScript (React, Vue, Angular)\n\n**API Technologies:**\n\tNginx, Keycloak (OIDC, RBAC), JWT, OAuth2, Let’s Encrypt\n\n**Serverless and Cloud Functions:**\n\tAWS (ECS, Lambda, RDS, S3), Azure (App Services, Blob, SQL)\n\n**Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare), MongoDB (Gaming), Redis, HDFS, HBase\n\n**DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, Terraform, Ansible, Helm, Docker Compose\n\n**Cloud & Infrastructure:**\n\tAWS, Azure\n\n**Other:**\n\tMLflow, Airflow, Kubeflow, Spark, Hive, Impala, Data Warehousing, Data Modeling, Database Query Execution Plans"
}