{
  "name": "Patryk Zaslawski",
  "role_name": "Senior Data Engineer",
  "email": "patrykzas0428@outlook.com",
  "phone": "+48669862402",
  "address": "Gdanski, Poland",
  "linkedin": "https://www.linkedin.com/in/patryk-z-9b9455391/",
  "profile_summary": "Results-driven Senior Data Engineer with 8+ years of experience in software engineering, specializing in **Python**, **Machine Learning**, and **Deep Learning**. Expert in data processing and analysis using **Pandas**, **NumPy**, **Matplotlib**, and **SciPy** to drive actionable insights. Proficient in building and deploying scalable machine learning models leveraging frameworks such as **SageMaker**, **Kubeflow**, and **MLFlow**. Adept in cloud platforms including **AWS** and **Azure** for efficient data pipeline management in a **DevOps** environment with solid knowledge in **CI/CD** practices. Well-versed in designing microservices and RESTful APIs, and optimizing databases like **SQL** systems, enhancing system performance and reliability. Strong analytical thinking and communication skills ensure seamless collaboration across teams, focusing on delivering high-performance solutions tailored to business objectives.",
  "education": [
    {
      "degree": "Bachelor’s Degree",
      "category": "Computer Science",
      "from_year": "2014",
      "to_year": "2017",
      "location": "United Kingdom",
      "university": "The University of Manchester"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "Binary Studio",
      "from_date": "Aug 2023",
      "to_date": "Present",
      "location": "United Kingdom (Remote)",
      "responsibilities": "Utilized **Python** for data processing and automation, enhancing efficiency in healthcare workflows and improving patient scheduling by **30%** through custom solutions.\nImplemented robust data processing pipelines leveraging **Pandas**, **NumPy**, and **Spark**, optimizing performance for large datasets by **40%**.\nDeveloped and maintained CI/CD pipelines for Python applications using **Git**, ensuring seamless updates and reducing deployment times by **25%**.\nCollaborated with cross-functional teams to design and optimize machine learning models, enhancing prediction accuracy and efficiency in data handling, utilizing **MLFlow** and **SageMaker**.\nArchitected microservices that support data ingestion and processing, utilizing **REST** APIs and optimizing with **SQL** for efficient querying of structured data.\nApplied advanced analytics and machine learning techniques to derive insights from healthcare data, using **Deep Learning** frameworks, and facilitating complex use cases.\nLed initiatives in **MLOps** to streamline the deployment of machine learning models, thus improving the rollout time by an impressive **50%**.\nImplemented cloud-native solutions on **AWS** and **Azure**, improving scalability and availability while reducing operational costs by **20%**.\nUtilized tools such as **Matplotlib** and **SciPy** for visualizing data analysis results, enhancing stakeholder communication by providing clearer insights.\nCommunicated complex technical concepts to non-technical stakeholders, enhancing understanding and alignment on project goals.\nMentored junior engineers on best practices in **Python**, machine learning, and DevOps principles, elevating team capabilities and fostering growth.\nEngaged in strategic analytical thinking to assess system efficiencies and propose actionable improvements, resulting in better resource utilization across projects."
    },
    {
      "role": "Software Engineer",
      "company": "Ardigen",
      "from_date": "Mar 2020",
      "to_date": "Aug 2023",
      "location": "Poland",
      "responsibilities": "• Developed and optimized data processing workflows utilizing **Python**, **Pandas**, and **NumPy**, improving data handling efficiency by **25%**.\n• Leveraged **Machine Learning** and **Deep Learning** techniques integrated within **Azure** and **AWS** environments to predict and analyze trends in large datasets, enhancing decision-making processes.\n• Designed and implemented ETL pipelines with **PySpark** and **Databricks** for seamless data integration and transformation, reducing data preparation time by **30%**.\n• Managed CI/CD processes using **Git**, **Azure DevOps**, and **GitHub Actions** to enhance deployment frequency by **40%** and streamline collaborative workflows.\n• Built and deployed scalable microservices with **Python** while utilizing **REST** principles for efficient API development, contributing to a modular architecture that supported **90%** of application requests.\n• Conducted statistical analysis and visualizations using **Matplotlib** and **SciPy**, enhancing reporting capabilities and visualization for business intelligence, improving insights by **50%**.\n• Collaborated with cross-functional teams employing **UML** to ensure comprehensive documentation and clear communication of project requirements and solutions.\n• Developed and implemented secure machine learning pipelines using **MLOps** principles, integrating with **SageMaker** and **Kubeflow**, ensuring reproducibility and tracking of experiments.\n• Enhanced data storage solutions by integrating with **SQL** databases and exploring NoSQL options for specific use cases, ensuring high reliability and performance.\n• Engaged in strategic analytical thinking to identify improvements in data workflows that led to increased data quality and reduced redundancy by **15%**.\n• Applied **DevOps** principles to automate infrastructure provisioning and management, significantly reducing downtime during updates and maintenance operations.\n• Actively documented processes, results, and innovations to facilitate knowledge sharing and project continuity across teams."
    },
    {
      "role": "Software Engineer",
      "company": "Altum Software",
      "from_date": "Oct 2017",
      "to_date": "Feb 2020",
      "location": "United Kingdom",
      "responsibilities": "Utilized **Python** and **SQL** to design and optimize data processing pipelines for large datasets, improving overall performance and enabling seamless integration with machine learning models.\nDeveloped and maintained robust ETL processes leveraging **Pandas**, **NumPy**, and **Spark** for efficient data handling and transformation, enhancing data quality and processing speed by **30%**.\nImplemented CI/CD practices using **Git**, **Azure DevOps**, and **MLFlow**, ensuring consistent deployment of data engineering workflows and machine learning models.\nEngaged in strategic analytical thinking to identify and resolve data bottlenecks, leading to a **25%** improvement in data processing time.\nCollaborated with cross-functional teams to integrate machine learning solutions utilizing **SageMaker**, **Kubeflow**, and **Hadoop**, driving data-driven decision-making across the organization.\nDesigned scalable microservices architecture for data ingestion and processing, utilizing **REST** APIs and facilitating efficient data flow with **RabbitMQ** and **Kafka**.\nConducted thorough testing and validation of data pipelines, ensuring accuracy and reliability with industry best practices and performance metrics.\nMonitored and optimized database performance using **SQL** databases, improving query performance by **40%** with advanced indexing and query strategies.\nProduced visualizations and reports using **Matplotlib** and **SciPy** to communicate insights and trends effectively to stakeholders, enhancing data-driven initiatives.\nMigrated legacy systems to modern data architecture using **Python** and cloud services like **AWS** and **Azure**, ensuring high availability and scalability of data solutions.\nParticipated in DevOps practices to automate infrastructure and deployment processes, improving team productivity and deployment cycles by **50%**.\nFacilitated effective communication of complex data concepts to non-technical stakeholders, ensuring alignment of project goals and objectives."
    }
  ],
  "skills": " **Programming Languages:** \n\tPython, Java\n\n **Backend Frameworks:** \n\tFastAPI, Django, Flask, Spring Boot\n\n **Frontend Frameworks:** \n\tAngular (1–16), React (15–18), Next.js, Vue.js (2/3), Blazor\n\n **API Technologies:** \n\tREST, gRPC, JSON, XML, micro-services\n\n **Serverless and Cloud Functions:** \n\tAWS (ECS, Lambda, RDS, S3), Azure (App Services, Blob, SQL)\n\n **Databases:** \n\tPostgreSQL (Fintech), MySQL (Healthcare), MongoDB (Gaming), Redis\n\n **DevOps:** \n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, DevOps, CI/CD\n\n **Cloud & Infrastructure:** \n\tAWS, Azure\n\n **Other:** \n\tMachine Learning, Deep Learning, Large Language Models, Data Processing, Pandas, NumPy, Matplotlib, SciPy, Git, MLOps, SageMaker, Kubeflow, MLFlow, Spark, Hadoop, Databricks, UML, Strategic Analytical Thinking, Communication",
  "apply_company": "Elsevier"
}