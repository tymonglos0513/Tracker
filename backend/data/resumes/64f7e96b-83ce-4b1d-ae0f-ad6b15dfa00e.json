{
  "name": "Damian Franciszek Pospiech",
  "role_name": "Senior AI Engineer",
  "email": "damianpos127@outlook.com",
  "phone": "+48 732 143 608",
  "address": "Mikolow, Poland",
  "linkedin": "https://www.linkedin.com/in/damian-pospiech-261821397/",
  "profile_summary": "Senior AI Engineer with 13+ years in developing high-performance applications, specializing in **Python**, **Machine Learning**, and cloud solutions on **AWS** and **Azure**. Highly skilled in implementing **MLOps** practices, including model training, serving, and orchestration using **MLflow**, while seamlessly integrating CI/CD principles using **GitHub Actions**.\nExpert in leveraging advanced libraries such as **NumPy**, **Pandas**, **Scikit-Learn**, **PySpark**, and frameworks like **Streamlit**, **Transformers**, and **PyTorch** to build AI/ML-powered platforms supporting predictive analytics and real-time processing. Proven track record of aligning solutions with compliance standards such as HIPAA, FHIR, PCI DSS, and SOC 2.\nAdept at fostering innovation in healthcare and financial sectors through the design of event-driven architectures and deployment of cloud-native systems.",
  "education": [
    {
      "degree": "Bachelor's degree in Computer Science",
      "category": "Computer Science",
      "from_year": "2007",
      "to_year": "2012",
      "location": "UK",
      "university": "University of Cambridge"
    }
  ],
  "experience": [
    {
      "role": "Senior AI Engineer",
      "company": "Codebridge",
      "from_date": "Apr 2021",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "Utilized **Python** along with **NumPy**, **Pandas**, and **Scikit-Learn** for machine learning solutions, driving the development of models that enhance predictive analytics and statistical modeling, leading to a **30%** improvement in forecasting accuracy.\nImplemented **MLOps** practices integrating **MLflow** and **GitHub Actions**, streamlined model training and deployment pipelines, achieving a **40%** reduction in deployment time.\nDeveloped, trained, and optimized advanced **Machine Learning** models using **PyTorch** and **Transformers** for natural language processing, resulting in a **25%** increase in document classification efficiency.\nDeployed solutions on cloud platforms, leveraging **AWS** and **Azure** services to ensure scalability and reliability across applications, including the utilization of **Azure ML** for model hosting.\nConstructed CI/CD pipelines, ensuring high-quality deployments with tools like **GitHub Actions** and incorporating automated testing frameworks, ultimately establishing a **50%** faster release cycle.\nAnalyzed large datasets with **PySpark**, leading to the extraction of actionable insights and driving data-driven decision making in projects.\nDesigned and developed intelligent workflows within applications using **LangChain**, and implemented **Agentic Workflows**, which facilitated heightened user engagement and operational efficiency.\nCollaborated on cross-functional teams, applying rapid model prototyping techniques to assess the practicality of integrating **Large Language Models** to enhance user interfaces and experiences.\nUtilized **Streamlit** for creating interactive data applications, enhancing accessibility to machine learning outputs for stakeholders.\nDeveloped and executed robust test strategies using **PyTest**, guaranteeing the reliability and performance of all implementations across environments."
    },
    {
      "role": "Software Engineer",
      "company": "Grupa Azoty",
      "from_date": "Oct 2015",
      "to_date": "Mar 2021",
      "location": "Poland",
      "responsibilities": "Utilized **Python** and **Machine Learning** techniques to develop predictive models and analytics tools, significantly enhancing data-driven decision making processes.\nImplemented **Azure** services for machine learning model deployment and real-time data processing, ensuring efficient resource management and scalability during high transaction volumes.\nOrchestrated MLOps practices using **MLflow** and **GitHub Actions**, establishing streamlined CI/CD pipelines for continuous integration and deployment of machine learning models.\nDeveloped high-performance ETL pipelines with **PySpark** and **Azure Data Factory**, capable of processing over **1 million** records per hour from multiple internal and external data sources.\nApplied advanced statistical modeling and data analysis techniques using **NumPy** and **Pandas**, improving the accuracy of financial forecasts and reporting by up to **30%**.\nLeveraged **scikit-learn** and **XGBoost** for building machine learning models focused on fraud detection, achieving a detection accuracy rate of over **95%**.\nIntegrated large language models into operational systems through **LangChain**, exploring agentic workflows to automate consumer interactions effectively.\nDesigned and implemented interactive dashboards using **Power BI** and **D3.js**, providing key stakeholders with real-time access to insights derived from complex data sets.\nCoordinated cross-functional teams to ensure successful project delivery within tight timelines, leading initiatives that consistently met or exceeded project goals by **20%**."
    },
    {
      "role": "Software Engineer",
      "company": "GoodCore",
      "from_date": "Jan 2012",
      "to_date": "Sep 2015",
      "location": "UK",
      "responsibilities": "- Developed and implemented machine learning models using **Scikit-Learn**, **Pandas**, and **NumPy** to enhance decision-making capabilities, improving efficiency by **30%**.\n- Leveraged cloud services like **AWS** and **Azure** for scalable AI solutions and deployment, ensuring robust infrastructure and resource management for machine learning initiatives.\n- Engineered MLOps pipelines utilizing **MLflow** and **GitHub Actions** for continuous integration and deployment, enabling streamlined workflows and reducing deployment time by **50%**.\n- Created data processing workflows with **PySpark**, optimizing data handling for large volumes, achieving a processing speed improvement of **40%**.\n- Employed large language models and frameworks such as **Transformers** and **PyTorch** to implement advanced NLP features, resulting in a **20%** increase in user engagement through personalized interactions.\n- Conducted statistical modeling and analysis to drive data-informed decision-making, significantly enhancing forecasting accuracy for product development.\n- Designed agentic workflows that integrate machine learning systems into business processes, improving operational efficiency and reducing turnaround times by **15%**.\n- Implemented CI/CD practices to streamline deployment of machine learning models, fostering rapid iterations and increasing team productivity by **25%**."
    }
  ],
  "skills": "**Programming Languages:**\n\tPython, JavaScript/TypeScript\n\n**Artificial Intelligence & Machine Learning:**\n\tMachine Learning, MLflow, NumPy, Pandas, Scikit-Learn, PySpark, Streamlit, Transformers, PyTorch, LangChain, MLOps, Large Language Models, RAG, Agentic Workflows, Statistical Modeling\n\n**Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n**Frontend Frameworks:**\n\tReact, Vue, Angular\n\n**API Technologies:**\n\tKeycloak (OIDC, RBAC), OAuth2, JWT\n\n**Serverless and Cloud Functions:**\n\tAWS: ECS, Lambda, RDS, S3, Azure: App Services, Blob Storage, SQL Database\n\n**Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare), MongoDB (Gaming), Redis\n\n**DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, CI/CD, Terraform, Ansible, Helm, Docker Compose\n\n**Cloud & Infrastructure:**\n\tAWS, Azure\n\n**Other:**\n\tNginx, Letâ€™s Encrypt, Certbot",
  "apply_company": "PIB Group"
}