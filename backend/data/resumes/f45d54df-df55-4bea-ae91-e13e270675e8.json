{
  "name": "Marcin Karol Kotlinski",
  "role_name": "Lead Data Engineer",
  "email": "marcinkot55@outlook.com",
  "phone": "+48 732 779 243",
  "address": "Zgorzelec, Poland",
  "linkedin": "https://www.linkedin.com/in/marcin-karol-kotlinski-bb2520397/",
  "profile_summary": "Results-driven Lead Data Engineer with 8 years of experience in building and optimizing data pipelines leveraging **Azure Data Factory**, **Synapse**, **Databricks**, and **Data Lake** technologies. Proficient in implementing ETL and ELT processes using **SQL** and **Python**, alongside cloud-native data warehousing on **Microsoft Azure**, **AWS**, and **Google Cloud**. Expertise in DataOps and DevOps practices ensures the delivery of scalable, reliable, and efficient data solutions.\n\nI have a proven track record in developing and managing data governance strategies and data modeling efforts that meet stringent compliance standards. My background in full-stack development, utilizing **JavaScript**, **TypeScript**, and frameworks such as **React**, **Next.js**, and **Vue**, complements my data engineering skills, allowing for seamless integration of data-driven applications. Recognized for leadership and collaboration abilities, I effectively drive cross-functional teams towards successful project delivery while excelling in communication and stakeholder engagement.",
  "education": [
    {
      "degree": "Master’s Degree in Computer Science",
      "category": "",
      "from_year": "2017",
      "to_year": "2018",
      "location": "UK",
      "university": "University of Oxford"
    },
    {
      "degree": "Bachelor’s Degree in Computer Science",
      "category": "",
      "from_year": "2015",
      "to_year": "2017",
      "location": "UK",
      "university": "University of Oxford"
    }
  ],
  "experience": [
    {
      "role": "Lead Data Engineer",
      "company": "EVNE Developers",
      "from_date": "Oct 2023",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "Designed and implemented cloud-native data architecture leveraging **Azure Data Factory**, **Synapse**, and **Databricks** to optimize data ingestion, storage, and querying across large-scale healthcare and financial datasets, ensuring compliance with data governance standards and regulations.\nArchitected and maintained scalable data pipelines using **ETL** and **ELT** strategies, streamlining data processing and transformation workflows with **SQL** and **Python**, achieving a **30% reduction** in processing time.\nLed cross-functional collaboration efforts, fostering strong communication and leadership skills to work effectively with data scientists and software engineers on integrated projects.\nDevised and executed comprehensive **DataOps** strategies, implementing CI/CD practices for data workflows to enhance reliability and efficiency of data delivery.\nUtilized **Power BI** for data modeling and visualization, delivering dynamic dashboards that provided real-time insights into data trends and KPIs, driving actionable intelligence.\nOversaw the transition to a **cloud-native data warehouse** architecture across multi-cloud environments including **Microsoft Azure**, **AWS**, and **Google Cloud**, resulting in a **50% increase** in system availability.\nImplemented best practices for data monitoring and governance, ensuring data quality and compliance across varying data sources and platforms.\nEnhanced data analysis capabilities with effective communication strategies, collaborating with stakeholders to identify key metrics and insights through data exploration.\nDesigned and developed comprehensive documentation for data infrastructure, ensuring clarity and understanding for both technical and non-technical teams."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Air Force",
      "from_date": "Oct 2021",
      "to_date": "Sep 2023",
      "location": "Poland",
      "responsibilities": "• Spearheaded the design and implementation of ETL pipelines utilizing **Azure Data Factory**, enabling efficient batch and real-time data ingestion from both internal and third-party sources, achieving a throughput of over **2TB** per day.\n• Developed and managed scalable data pipelines on **Microsoft Azure** and **Databricks**, ensuring optimized data workflows and adherence to best practices in **DataOps** and **DevOps** strategy.\n• Oversaw the construction of a cloud-native data warehouse on **Azure Synapse**, supporting storage and analytics for varied financial datasets, with an emphasis on data modeling for enhanced reporting.\n• Collaborated cross-functionally to implement **Power BI** dashboards that delivered real-time insights and analytics, resulting in a **30%** reduction in reporting time for business stakeholders.\n• Leveraged **SQL** and **Python** to facilitate data governance and integrity, implementing rigorous validation checks that improved data accuracy by **25%**.\n• Engaged in leadership and mentorship initiatives within the team, fostering a collaborative environment that emphasized communication and knowledge transfer among team members.\n• Drove strategic projects focusing on the integration of cloud services such as **AWS** and **Google Cloud**, enhancing the overall operational efficiency of data processes across platforms."
    },
    {
      "role": "Software Engineer",
      "company": "DeepInspire",
      "from_date": "Sep 2018",
      "to_date": "Aug 2021",
      "location": "UK",
      "responsibilities": "Leveraged **Azure Data Factory**, **Databricks**, and **SQL** to design and implement robust ETL/ELT data pipelines, ensuring the integration and transformation of large data sets for analytical purposes across **Microsoft Azure** and **AWS** environments.\nEngineered cloud-native data solutions in **Azure Data Lake** and **Synapse**, optimizing data storage and retrieval strategies while maintaining high performance and scalability of data access.\nApplied **Python** for data manipulation and processing tasks, developing complex data models and enhancing the performance of **DataOps** workflows, contributing to a 30% increase in data processing efficiency.\nImplemented **Power BI** dashboards for visualizing key data metrics, facilitating data-driven decision-making processes, and improving operational oversight by 25%.\nEnsured data governance and compliance through robust security practices, including role-based access control and data validation mechanisms, to safeguard sensitive information and adhere to GDPR regulations.\nFostered collaboration among teams by leading cross-functional projects, enhancing communication strategies that resulted in a 40% improvement in project delivery timelines.\nDirected the adoption of **DevOps** practices in data engineering projects, streamlining workflows and increasing deployment frequency by 50%, ensuring reliable and repeatable data delivery.\nMentored junior data engineers, providing leadership and guidance on best practices in data modeling and pipeline development, which led to a noticeable enhancement in overall team productivity.\nConducted routine audits and optimization of data pipelines, achieving up to a 20% reduction in data processing costs and enhancing overall system performance."
    }
  ],
  "skills": "**Programming Languages:**\n\tPython, SQL\n\n**Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n**Frontend Frameworks:**\n\tJavaScript/TypeScript (React, Vue, Angular)\n\n**API Technologies:**\n\tNginx, JWT, OAuth2, Let’s Encrypt, Keycloak (OIDC, RBAC)\n\n**Serverless and Cloud Functions:**\n\tAWS (ECS, Lambda, RDS, S3), Azure (App Services, Blob, SQL)\n\n**Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare), MongoDB (Gaming), Redis\n\n**DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, Terraform, Ansible, Helm, Docker Compose\n\n**Cloud & Infrastructure:**\n\tMicrosoft Azure, Google Cloud, Cloud-native data warehouse\n\n**Other:**\n\tAzure Data Factory, Synapse, Databricks, Data Lake, ETL, ELT, DataOps, Power BI, Data modeling, Data pipelines, Data governance, Communication skills, Leadership, Collaboration"
}