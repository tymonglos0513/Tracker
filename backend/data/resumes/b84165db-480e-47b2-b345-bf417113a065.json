{
  "name": "Damian Franciszek Pospiech",
  "role_name": "Data Engineer/BI Developer",
  "email": "damianpos127@outlook.com",
  "phone": "+48 732 143 608",
  "address": "Mikolow, Poland",
  "linkedin": "https://www.linkedin.com/in/damian-pospiech-623a26390/",
  "profile_summary": "Data Engineer/BI Developer with 13+ years of experience in delivering robust data solutions across healthcare and financial sectors. Proficient in **Microsoft SQL Server BI stack**, **T-SQL**, and **SSIS**, specializing in comprehensive **ETL design and development**. Skilled in **Azure Data Factory (ADF)**, **Power BI**, and **DAX** for effective data visualization and transformation. Experienced in leveraging **Databricks** and **Spark** for big data processing. Strong command of **Python** for data manipulation and scripting.\nAdditionally, I have hands-on expertise in **JavaScript/TypeScript**, **Flutter**, **React**, **Next.js**, and **Node.js**, enabling seamless integration and enhancement of front-end and back-end functionalities. Well-versed in deploying cloud-native systems on **AWS** and **Azure**, and experienced in implementing microservices, CI/CD pipelines, and event-driven architectures. Committed to maintaining compliance with standards such as HIPAA, FHIR, PCI DSS, and SOC 2. Excellent communication skills and a solid background in MLOps, including model training and orchestration with **MLflow**, **Airflow**, and **Kubeflow**.",
  "education": [
    {
      "degree": "Bachelor's degree in Computer Science",
      "category": "Computer Science",
      "from_year": "2007",
      "to_year": "2012",
      "location": "UK",
      "university": "University of Cambridge"
    }
  ],
  "experience": [
    {
      "role": "Data Engineer/BI Developer",
      "company": "Codebridge",
      "from_date": "Apr 2021",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "• Developed and optimized data pipelines utilizing **Azure Data Factory** and **SSIS** for **ETL design and development**, ensuring efficient data flow and integrity across various systems.\n• Utilized **Microsoft SQL Server BI stack** to perform data transformations and analytics using **T-SQL** and **DAX**, enabling the delivery of actionable insights and business intelligence reports.\n• Designed and implemented advanced data visualization solutions in **Power BI**, enhancing the visibility of key performance indicators and driving data-driven decisions in the organization.\n• Employed **Databricks** and **Spark** for large-scale data processing, facilitating real-time analytics and supporting high-performance data workloads.\n• Engineered and maintained data structures optimized for performance and scalability, ensuring reliable data access and management for reporting and analytics needs.\n• Applied strong communication skills to collaborate effectively with cross-functional teams, translating complex technical requirements into understanding for stakeholders.\n• Contributed to team efforts by implementing version control practices using **Team Foundation Server** to manage project iterations and maintain code quality.\n• Engaged with users to gather feedback on reporting needs, adapting solutions iteratively to enhance user experience across **Azure SQL Server** environments.\n• Successfully implemented data governance best practices to ensure data quality and compliance with internal standards and industry regulations.\n• Conducted thorough testing and validation of data workflows, using proven methodologies to verify the accuracy and reliability of BI solutions."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Grupa Azoty",
      "from_date": "Oct 2015",
      "to_date": "Mar 2021",
      "location": "Poland",
      "responsibilities": "Designed and developed ETL processes using **Azure Data Factory** and **SSIS**, ensuring optimal data extraction, transformation, and loading for high-volume datasets, resulting in a **25%** improvement in processing time.\nUtilized **T-SQL** to perform data manipulation and querying against **Microsoft SQL Server BI stack**, optimizing database operations and maintaining accuracy in data reporting.\nImplemented data visualizations and reports with **Power BI** and **DAX**, facilitating decision-making processes by providing clear insights into business intelligence metrics.\nLeveraged **Python** and **Spark** within the **Databricks** ecosystem to process and analyze large datasets, achieving processing speeds that improved efficiency by **30%**.\nBuilt and maintained robust data structures to support complex queries and reporting needs, ensuring data integrity and accessibility for the analytics team.\nCollaborated effectively with cross-functional teams to gather requirements and translate them into technical specifications, enhancing communication skills and project delivery.\nDeveloped automated workflows and monitoring using **Azure Data Factory** for seamless data integration from various internal and third-party sources.\nEmployed best practices in data engineering to design and maintain scalable solutions that support continuous data flow for BI applications."
    },
    {
      "role": "Software Engineer",
      "company": "GoodCore",
      "from_date": "Jan 2012",
      "to_date": "Sep 2015",
      "location": "UK",
      "responsibilities": "Utilized the **Microsoft SQL Server BI stack** to develop and maintain robust ETL processes using **T-SQL**, **SSIS**, and **ADF**, ensuring seamless data integration and transformation for large datasets across various sources.\nDesigned and implemented data pipelines for **Azure Data Factory**, optimizing flow for analytics workloads and structured storage, enabling scalability and impactful data insights.\nDeveloped interactive data visualizations and reports using **Power BI** and **DAX**, enhancing data accessibility for stakeholders by delivering clear insights and actionable analytics.\nEngineered data processing frameworks using **Databricks** and **Spark**, optimizing ETL workflows to handle large-scale datasets while significantly improving processing times by over **30%**.\nCollaborated cross-functionally to gather business requirements, translating them into technical specifications, enhancing communication skills and fostering teamwork.\nManaged version control and deployment strategies using **Team Foundation Server**, ensuring smooth transitions and reliable versioning of data solutions.\nEmployed industry-standard data structures to enhance query performance and supported efficient data storage, achieving more than **99%** uptime and efficient data retrieval.\nImplemented rigorous data quality checks and validation processes to ensure accuracy and reliability of data pipelines, contributing to improved decision-making across the organization.\nLeveraged **Python** for scripting and automation tasks within the ETL processes, further enhancing efficiency and reducing manual workloads by **25%**."
    }
  ],
  "skills": " **Programming Languages:**\n\tPython, T-SQL, JavaScript/TypeScript\n\n **Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n **Frontend Frameworks:**\n\tReact, Vue, Angular\n\n **API Technologies:**\n\tKeycloak (OIDC, RBAC), OAuth2, JWT\n\n **Serverless and Cloud Functions:**\n\tAWS: Lambda, Azure: App Services\n\n **Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare), Microsoft SQL Server, MongoDB (Gaming), Redis\n\n **DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, Terraform, Ansible, Helm, Docker Compose\n\n **Cloud & Infrastructure:**\n\tAWS: ECS, RDS, S3, Azure: Blob Storage, SQL Database, Azure Data Factory, Databricks\n\n **Other:**\n\tMLflow, Airflow, Kubeflow, ETL design and development, Spark, Power BI, DAX, communication skills, data structures, Team Foundation Server, Nginx, Let’s Encrypt, Certbot"
}