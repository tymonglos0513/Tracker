{
  "name": "Damian Franciszek Pospiech",
  "role_name": "Senior Data Engineer",
  "email": "damianpos127@outlook.com",
  "phone": "+48 732 143 608",
  "address": "Mikolow, Poland",
  "linkedin": "https://www.linkedin.com/in/damian-pospiech-261821397/",
  "profile_summary": "Senior Data Engineer with 13+ years of experience in data analytics and visualization, adept in building robust data pipelines and ETL processes. Skilled in **SQL**, **PowerBI**, **Looker**, **Tableau**, **GitHub**, and **DBT** for effective data management and visualization. Proficient in orchestrating data workflows using **Airflow** and integrating data systems with tools like **Salesforce** and **Marketo**. \nExpert in storytelling and communication, with a strong ability to present complex data insights in a clear and compelling manner.\nAdditionally, I have a comprehensive background in full stack development, proficient in **JavaScript/TypeScript**, **Python**, and **Flutter**. My experience extends to both frontend and backend development with frameworks including **React**, **Next.js**, **Vue**, **Node.js**, **FastAPI**, and **Django**. I possess hands-on expertise in deploying cloud-native applications on **AWS** and **Azure**, implementing microservices and CI/CD pipelines. I also have a solid understanding of compliance-driven development, aligning solutions with legal standards such as HIPAA, FHIR, PCI DSS, and SOC 2.",
  "education": [
    {
      "degree": "Bachelor's degree in Computer Science",
      "category": "Computer Science",
      "from_year": "2007",
      "to_year": "2012",
      "location": "UK",
      "university": "University of Cambridge"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "Codebridge",
      "from_date": "Apr 2021",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "Utilized **SQL** to perform data extraction and transformation tasks, ensuring high-quality data for analysis in various healthcare and fintech applications.\nDeveloped advanced **data visualization** tools with **Power BI**, **Looker**, and **Tableau** to enable real-time analysis of financial activity, fraud trends, and operational KPIs, thus contributing to impactful data storytelling and presentations.\nDesigned and implemented robust **ETL** processes and **data pipelines** for heavy data ingestion and real-time analytics, ensuring seamless data flow across systems.\nCollaborated with cross-functional teams to provide insights and analytical solutions, enhancing communication channels and effectively conveying key metrics to stakeholders.\nOrchestrated **Airflow** workflows for managing data pipelines, ensuring smooth ETL operations with minimal downtime and successful data delivery across systems.\nManaged and optimized code repositories on **GitHub**, enabling collaboration and version control in development workflows.\nConducted comprehensive data analysis and visualization projects using various third-party tools while leveraging techniques to present data-driven insights to non-technical audiences in a clear and impactful manner.\nLed efforts to integrate **DBT** for data transformation, ensuring reliable and repeatable data modeling.\nShared analytical insights with the product team using **Amplitude**, driving decision-making processes and enhancing product features based on user engagement data.\nEngaged with project stakeholders to align data analytics objectives with business goals, facilitating teamwork through effective communication and presentation skills."
    },
    {
      "role": "Software Engineer",
      "company": "Grupa Azoty",
      "from_date": "Oct 2015",
      "to_date": "Mar 2021",
      "location": "Poland",
      "responsibilities": "Leveraged **SQL** to create complex queries and optimize database performance, enhancing data retrieval times by **30%**.\nUtilized **Power BI** and **Looker** for data visualization, delivering interactive dashboards which improved reporting efficiency by **25%**.\nImplemented and maintained **ETL** processes using **Apache Airflow** to automate workflows, reducing manual data handling errors by **40%**.\nCollaborated with cross-functional teams, effectively communicating insights and findings, enhancing stakeholder understanding of data and analytics through compelling storytelling and presentations.\nDeveloped and monitored **data pipelines** to ensure accurate data flow and availability, significantly decreasing downtime by **15%**.\nApplied version control and collaboration practices using **GitHub** to manage codebase for data projects, fostering team collaboration and project tracking.\nIntegrated analytics tools like **Tableau** and **Amplitude** to track user engagement metrics, yielding actionable insights for product enhancements.\nSupported marketing efforts by ensuring accurate data is available for platforms like **Salesforce** and **Marketo**, aligning analytics with organizational goals."
    },
    {
      "role": "Software Engineer",
      "company": "GoodCore",
      "from_date": "Jan 2012",
      "to_date": "Sep 2015",
      "location": "UK",
      "responsibilities": "Leveraged **SQL** for complex querying and database management, ensuring efficient data processing and integration across a large-scale data environment with **PostgreSQL** and **MongoDB**.\nDesigned and maintained robust ETL workflows using **Airflow** to automate data pipelines, ensuring timely availability of analytics for business intelligence initiatives.\nCreated interactive data visualizations and reports using **PowerBI**, **Looker**, and **Tableau**, translating complex data sets into insightful stories for stakeholders with a focus on clear communication and presentation.\nCollaborated closely with cross-functional teams utilizing **GitHub** for version control, promoting efficient teamwork and project management in a dynamic setting.\nImplemented data governance and best practices using **DBT** to ensure data integrity and accuracy within the data warehouse, contributing to high-quality data analytics.\nDeveloped analytics solutions integrated with **Salesforce** and **Marketo**, enhancing marketing insights through effective data visualization and actionable reporting mechanisms.\nUtilized **Amplitude** to analyze user behavior, enabling data-driven decision-making and strategic improvements in product offerings.\nEngaged in clear communication of data insights through storytelling, enhancing the decision-making process for non-technical stakeholders.\nMaintained a high standard of data access controls and security protocols, ensuring compliance with **GDPR** and protection of sensitive customer data."
    }
  ],
  "skills": " **Programming Languages:**\n\tPython: FastAPI, Flask, Django\n\tJavaScript/TypeScript: React, Vue, Angular\n\n **Backend Frameworks:**\n\tAirflow\n\n **Frontend Frameworks:**\n\n **API Technologies:**\n\n **Serverless and Cloud Functions:**\n\tAWS: ECS, Lambda, RDS, S3\n\tAzure: App Services, Blob Storage, SQL Database\n\n **Databases:**\n\tPostgreSQL (Fintech)\n\tMySQL (Healthcare)\n\tMongoDB (Gaming)\n\tRedis\n\tSQL\n\n **DevOps:**\n\tDocker\n\tKubernetes\n\tGitHub Actions\n\tGitLab CI/CD\n\tTerraform\n\tAnsible\n\tHelm\n\tDocker Compose\n\n **Cloud & Infrastructure:**\n\n **Other:**\n\tMLflow\n\tKubeflow\n\tKeycloak (OIDC, RBAC)\n\tOAuth2\n\tJWT\n\tNginx\n\tLetâ€™s Encrypt\n\tCertbot\n\tPowerBI\n\tLooker\n\tTableau\n\tGitHub\n\tDBT\n\tSalesforce\n\tMarketo\n\tAmplitude\n\tdata visualization\n\tdata analytics\n\tETL\n\tdata pipelines\n\tcommunication\n\tstorytelling\n\tpresentation\n",
  "apply_company": "Autodesk"
}