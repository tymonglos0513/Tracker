{
  "name": "DANIEL HE",
  "role_name": "AI Engineer",
  "email": "daniel.he8@outlook.com ",
  "phone": "+48 730 743 032",
  "address": "Rzesz√≥w, Poland",
  "linkedin": "https://www.linkedin.com/in/daniel-he-a5a536397/",
  "profile_summary": "Results-driven AI Engineer with expertise in **Machine Learning**, **GenAI**, and **MLOps**, adept at developing and deploying innovative AI solutions. Proficient in **Python** and cloud technologies including **AzureML**, **Databricks**, and **Spark** to create efficient data processing pipelines and with a deep understanding of **Data Engineering** principles. Experienced in leveraging **CI/CD** practices utilizing **GitHub Actions**, **GitLab**, and **Azure DevOps** to enhance software delivery processes. Skilled in containerization technologies like **Docker** and **Kubernetes** to maintain scalable applications. Proven track record of collaborating across teams, contributing to solid technical documentation, and employing strong problem-solving skills to drive impactful changes across industries such as healthcare, eCommerce, and finance.",
  "education": [
    {
      "degree": "Bachelor's degree in Computer Science",
      "category": "Computer Science",
      "from_year": "2012",
      "to_year": "2016",
      "location": "Beijing, China ",
      "university": "Tsinghua University "
    }
  ],
  "experience": [
    {
      "role": "AI Engineer",
      "company": "Britenet",
      "from_date": "Feb 2023 ",
      "to_date": "Present",
      "location": "Warsaw, Poland",
      "responsibilities": "- Leveraged **Python** for developing machine learning models, ensuring data integrity and accuracy across various projects.\n- Implemented MLOps practices using **AzureML** and **Databricks**, enhancing model deployment efficiency by **50%** and streamlining workflow.\n- Designed and optimized data processing pipelines with **Spark** and **PySpark**, achieving a **60%** reduction in data processing time.\n- Developed CI/CD processes utilizing **GitHub Actions** and **Azure DevOps**, increasing deployment frequency by **40%** and minimizing rollback incidences.\n- Employed **Docker** and **Kubernetes** to create scalable and manageable environments, maintaining a remarkable **99.8%** uptime for services.\n- Collaborated in a cross-functional team to produce high-quality technical documentation, improving knowledge transfer and reducing onboarding time for new team members by **30%**.\n- Utilized **Hive** for efficient data querying and analysis, optimizing performance for large datasets while enhancing accessibility for data engineering teams.\n- Communicated complex technical concepts clearly, fostering teamwork and enhancing problem-solving capabilities within the team."
    },
    {
      "role": "Software Engineer",
      "company": "Alibaba Group",
      "from_date": "Oct 2020 ",
      "to_date": "Dec 2022",
      "location": "Hangzhou, China",
      "responsibilities": "Utilized **Python** for developing and optimizing data processing pipelines, enhancing processing speed by **30%**.\nImplemented MLOps strategies to streamline machine learning model deployment, achieving a **40%** increase in deployment efficiency and reliability.\nLeveraged **AzureML** and **Databricks** for data analysis and model training, improving model accuracy by **15%**.\nIntegrated **Spark** and **PySpark** to process large datasets, reducing processing time from hours to minutes, demonstrating critical thinking and analytical skills.\nCollaborated cross-functionally to produce technical documentation, ensuring project transparency and clarity, while strengthening team communication.\nExecuted CI/CD practices using **GitHub Actions** and **GitLab**, which improved release cycles by **25%**.\nUtilized cloud computing principles on **Azure** to enhance scalability and flexibility, supporting dynamic project requirements.\nEngaged in team-driven problem-solving, resulting in innovative solutions that increased productivity and efficiency."
    },
    {
      "role": "Software Engineer ",
      "company": "Huawei Technologies Co., Ltd",
      "from_date": "May 2016 ",
      "to_date": "Sep 2020",
      "location": "Shenzhen, China ",
      "responsibilities": "Developed and optimized data processing pipelines leveraging **Python**, **Spark**, and **Databricks**, increasing processing speed by **25%**.\nImplemented machine learning models using **AzureML** and **MLOps**, yielding a model accuracy improvement of **15%**.\nManaged end-to-end CI/CD processes utilizing **GitHub Actions** and **Azure DevOps**, enabling smoother deployments with a **40%** reduction in rollout times.\nUtilized **Docker** and **Kubernetes** for containerization and orchestration, enhancing application scalability by **50%**.\nWrote and maintained technical documentation, ensuring clarity and understanding across teams, while fostering effective communication and teamwork."
    }
  ],
  "skills": "**Programming Languages**\n\tJava, JavaScript (React, Vue.js, Angular, Pixi.js, Vanilla JS, Node.js, TypeScript), Go, Python, SQL, Swift, Kotlin\n\n**Backend Frameworks**\n\tSpring Boot, Spring Security, Hibernate, Node.js, Express.js, JPA, Kafka, RabbitMQ\n\n**Frontend Frameworks**\n\tReact, Vue.js, Angular, Pixi.js, Redux, Next.js, React Router, Material-UI, Ant Design, D3.js, Webpack, Babel, Jest\n\n**API Technologies**\n\tRESTful API design, API Gateway\n\n**Serverless and Cloud Functions**\n\tAWS Lambda\n\n**Databases**\n\tMySQL, PostgreSQL, Redis, MongoDB\n\n**DevOps**\n\tDocker, Kubernetes (AWS EKS), Jenkins, GitHub Actions, Terraform, AWS CodePipeline, GitLab, Azure DevOps\n\n**Cloud & Infrastructure**\n\tAWS (EKS, RDS, CloudFront, S3), CloudWatch, ELK Stack, Cloud Computing\n\n**Other**\n\tMicroservices, CI/CD, Infrastructure as Code (IaC), Data structures and algorithms, Agile/Scrum methodologies, Machine Learning, GenAI, MLOps, LLMOps, AzureML, Databricks, Spark, PySpark, Hive, Data Engineering, Data Processing Pipelines, Technical Documentation, Communication Skills, Teamwork, Problem Solving, Critical Thinking, English Fluency"
}