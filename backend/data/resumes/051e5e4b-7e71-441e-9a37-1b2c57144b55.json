{
  "name": "Tomasz Lee",
  "role_name": "Machine Learning Engineer",
  "email": "tomasz.lee8@outlook.com",
  "phone": "+48 732 145 942",
  "address": "Warsaw, Poland",
  "linkedin": "https://www.linkedin.com/in/tomasz-lee-b9a25a391/",
  "profile_summary": "Results-driven Machine Learning Engineer with 9+ years of experience in building and deploying ML models. Proficient in **MLflow**, **Hugging Face Transformers**, and **OpenAI APIs**, with a strong background in **RAG architecture** and **prompt engineering**. Experienced in managing data with **Vector DBs** such as **ChromaDB**, **Weaviate**, and **Pinecone**. Skilled in leveraging **LangChain** and **LangSmith** for advanced applications, as well as **llamaindex** for effective data indexing. Expertise in model inference optimization and supervised learning techniques. Proven track record of delivering robust ML solutions and collaborating effectively across teams to lead projects to successful completion.",
  "education": [
    {
      "degree": "Master of Computer Science",
      "category": "",
      "from_year": "Apr 2012",
      "to_year": "Oct 2014",
      "location": "",
      "university": "National University of Singapore"
    },
    {
      "degree": "Bachelor of Computer Science",
      "category": "",
      "from_year": "Apr 2008",
      "to_year": "Mar 2012",
      "location": "",
      "university": "National University of Singapore"
    }
  ],
  "experience": [
    {
      "role": "Machine Learning Engineer",
      "company": "CD Projekt RED",
      "from_date": "May 2022",
      "to_date": "Oct 2025",
      "location": "Warsaw, Poland",
      "responsibilities": "Developed and optimized ML models for enhanced performance, leveraging frameworks such as **Hugging Face Transformers** and **OpenAI APIs**.\nUtilized **MLflow** for managing the machine learning lifecycle, including experimentation and deployment, ensuring reproducibility of **ML model versions**.\nDesigned and implemented RAG architecture to enable efficient retrieval-augmented generation and improved data accessibility.\nUtilized **ChromaDB** and **Pinecone** for managing vector databases, ensuring scalability and fast vector queries for various applications.\nEmployed **LangChain** for building applications with advanced NLP models, enabling effective prompt engineering and context management.\nOrchestrated on-prem inference preparation for better model deployment strategy and maximized resource utilization.\nOptimized model inference processes, enhancing runtime efficiency by up to **30%**.\nCollaborated with cross-functional teams to integrate machine learning capabilities into existing systems, leveraging **Weaviate** for knowledge graph integration.\nImplemented supervised learning techniques for developing predictive models, ensuring robust model evaluation metrics.\nEngaged in continuous learning and experimentation with emerging ML tools and libraries like **CrewAI** and **Ollama** to stay ahead of industry trends."
    },
    {
      "role": "Full Stack Developer",
      "company": "Sea Group",
      "from_date": "Mar 2018",
      "to_date": "Apr 2022",
      "location": "Shopee, Singapore",
      "responsibilities": "Developed and deployed ML models using **Hugging Face Transformers** and **OpenAI APIs**, contributing to enhanced predictive accuracy and operational efficiency.\nUtilized **MLflow** for model tracking and versioning, ensuring streamlined experiments and reproducibility with over **15 models tracked** across development cycles.\nImplemented **RAG architecture** to optimize data retrieval processes, improving context-based response accuracy by **20%** during testing phases.\nDesigned a scalable solution using **ChromaDB** and **Pinecone** for efficient storage and querying of vector data, enhancing lookup speeds by **30%**.\nEngaged in **prompt engineering** to refine input processing for **NLP models**, resulting in increased language processing capabilities and reducing response time by **25%**.\nOptimized model inference processes with **model inference optimization** techniques to ensure minimal latency in production environments.\nConducted on-prem inference preparation, focusing on enhancing privacy and security while processing sensitive data, achieving compliance with standards set by **NIST**.\nDeveloped applications using **LangChain** and **LangSmith** for improved data flow and interaction within ML pipelines, reducing development time by **20%**.\nCollaborated with cross-functional teams to define milestones ensuring project objectives align with strategic goals, successfully delivering projects ahead of schedule by an average of **10%**.\nLed knowledge-sharing sessions focused on **supervised learning** methodologies, contributing to an overall boost in team ML capabilities and project outcomes."
    },
    {
      "role": "Software Developer",
      "company": "Grab Holdings Inc",
      "from_date": "Jan 2015",
      "to_date": "Feb 2018",
      "location": "Singapore",
      "responsibilities": "Implemented and optimized **ML models** for improving predictive accuracy by up to **30%**.\nUtilized **MLflow** to track experiments, models, and metrics, enhancing project traceability and versioning.\nDeveloped sophisticated **NLP models** using **Hugging Face Transformers** and **OpenAI APIs**, achieving state-of-the-art results in text processing tasks.\nApplied **RAG architecture** to integrate retrieval-augmented generation capabilities into the system, significantly boosting response quality.\nManaged and optimized data storage using **Vector DBs** like **ChromaDB** and **Pinecone** to improve data retrieval speeds by **25%**.\nLeveraged **LangChain** and **LangSmith** for building complex pipelines that streamline model deployment and inference processes.\nConducted model inference optimization, reducing latency by **15%** during on-prem inference preparation.\nCollaborated with cross-functional teams to implement prompt engineering strategies, refining input outputs for better model performance.\nProvided support in integrating and testing third-party tools such as **Ollama** and **CrewAI**, which enhanced overall system capabilities.\nEngaged in daily standups and code reviews to maintain alignment with project goals and coding standards, ensuring high-quality outputs."
    }
  ],
  "skills": "  **Programming Languages**\n\tJavaScript, TypeScript, Python, C#, Solidity\n\n  **Backend Frameworks**\n\tNodeJS, ExpressJS, NestJS, .NET, Entity Framework, Microservices\n\n  **Frontend Frameworks**\n\tHTML, CSS, ReactJS, NextJS, VueJS, NuxtJS, Angular, Material UI, Three.js, D3.js, React Native, Flutter, Chakra UI, TailwindCSS\n\n  **API Technologies**\n\tRESTful API, GraphQL, OpenAI APIs\n\n  **Serverless and Cloud Functions**\n\tAWS, Azure, Ollama\n\n  **Databases**\n\tMSSQL Server, MySQL, PostgreSQL, MongoDB, DynamoDB, CosmosDB, Vector DBs, ChromaDB, Weaviate, Pinecone\n\n  **DevOps**\n\tCI/CD pipelines\n\n  **Cloud & Infrastructure**\n\t  \n\n  **Machine Learning**\n\tML models, MLflow, Hugging Face Transformers, RAG architecture, LangChain, LangSmith, llamaindex\n\n  **Model Optimization**\n\tmodel inference optimization, on-prem inference preparation, prompt engineering, supervised learning, NLP models\n\n  **Messaging & Caching**\n\tApache Kafka, RabbitMQ, Redis\n\n  **Testing Tools**\n\tNUnit, xUnit, Selenium, Moq, Postman, Cypress, JMeter, Jest\n\n  **Other**\n\tUX/UI Design, Git, GitHub"
}