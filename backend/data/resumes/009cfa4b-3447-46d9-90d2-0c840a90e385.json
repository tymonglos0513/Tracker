{
  "name": "Tomasz Lee",
  "role_name": "Senior Data Engineer",
  "email": "tomasz.lee8@outlook.com",
  "phone": "+48 732 145 942",
  "address": "Warsaw, Poland",
  "linkedin": "https://www.linkedin.com/in/tomasz-lee-b9a25a391/",
  "profile_summary": "Results-driven Senior Data Engineer with 9+ years of experience specializing in **Azure Data Factory**, **Snowflake**, **DBT**, **SQL**, and **Python** for effective data modeling and performance optimization. Proficient in monitoring, debugging, and utilizing version control tools like **Git** in CI/CD environments. A proven track record of delivering reliable data solutions, enhancing performance, and streamlining processes. Additionally experienced in **.NET**, **C#**, and full-stack development, with expertise in microservices architecture, and collaboration across diverse teams to drive successful project outcomes.",
  "education": [
    {
      "degree": "Master of Computer Science",
      "category": "",
      "from_year": "Apr 2012",
      "to_year": "Oct 2014",
      "location": "",
      "university": "National University of Singapore"
    },
    {
      "degree": "Bachelor of Computer Science",
      "category": "",
      "from_year": "Apr 2008",
      "to_year": "Mar 2012",
      "location": "",
      "university": "National University of Singapore"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "CD Projekt RED",
      "from_date": "May 2022",
      "to_date": "Oct 2025",
      "location": "Warsaw, Poland",
      "responsibilities": "Utilized **Azure Data Factory** for efficient data integration and orchestration, ensuring timely data availability for analysis.\nImplemented **Snowflake** for scalable data warehousing solutions, optimizing storage costs and query performance by **30%**.\nDeveloped and maintained **DBT** models for transforming raw data into analytics-ready datasets, enhancing data quality and reliability.\nDesigned robust **SQL** queries and optimized database schemas, reducing query execution time by **25%** while managing large datasets.\nProgrammed in **Python** to automate data processing tasks, increasing efficiency and reducing manual workload by **50%**.\nConducted performance optimization strategies that improved data processing jobs' run time by **40%**.\nApplied effective data modeling techniques to support analytical needs, leading to actionable insights.\nEngaged in performance monitoring and debugging to ensure system reliability and accuracy in data pipelines.\nCollaborated with cross-functional teams to enhance communication and integrate feedback into data solutions, ensuring alignment with business objectives.\nUtilized **Git** for version control, maintaining code integrity and facilitating collaborative development.\nImplemented CI/CD practices to streamline deployment processes, achieving seamless transitions between environments."
    },
    {
      "role": "Full Stack Developer",
      "company": "Sea Group",
      "from_date": "Mar 2018",
      "to_date": "Apr 2022",
      "location": "Shopee, Singapore",
      "responsibilities": "Utilized **Azure Data Factory** for efficient data integration and processing, ensuring high availability and performance optimization across workflows.\nApplied **Snowflake** for cloud-based data warehousing, leading to a **40%** reduction in query response time by implementing advanced data modeling techniques.\nManaged ETL processes using **DBT**, enhancing data transformation capabilities and streamlining data workflows across multiple datasets.\nDeveloped complex SQL queries for data retrieval and analysis, increasing reporting efficiency by **30%** through optimized query performance.\nImplemented performance monitoring solutions using techniques such as logging and alerting, proactively addressing data pipeline issues before they impact business operations.\nConducted thorough debugging processes to troubleshoot data discrepancies, resulting in a **20%** decrease in error resolution time.\nLeveraged **Git** for version control, ensuring the integrity and traceability of the codebase within collaborative projects.\nAutomated deployment processes through CI/CD practices, contributing to a **25%** reduction in time taken for data pipeline updates.\nCommunicated effectively with cross-functional teams to define clear data requirements and project timelines, facilitating alignment and timely project delivery.\nMentored junior data engineers on best practices for data modeling and performance optimization, fostering a culture of continuous improvement within the team."
    },
    {
      "role": "Software Developer",
      "company": "Grab Holdings Inc",
      "from_date": "Jan 2015",
      "to_date": "Feb 2018",
      "location": "Singapore",
      "responsibilities": "Utilized **Azure Data Factory** to orchestrate data workflows, achieving data processing efficiency improvements of up to **30%**.\nEmployed **Snowflake** for scalable data storage and analytics to manage large datasets, enhancing query performance by **25%**.\nImplemented **DBT** for data transformation processes, improving data modeling practices and ensuring consistency across data sets.\nCreated complex SQL queries for data retrieval and transformation, enhancing the overall efficiency of data operations, with a focus on **performance optimization**.\nDeveloped and executed **Python** scripts for data automation and monitoring tasks, leading to a reduction in manual data handling time by **40%**.\nApplied **version control** using **Git** for code teamwork and integrity, facilitating smooth collaboration and version tracking with **branching strategies**.\nDesigned and maintained data models aligned with best practices in **data modeling**, which positively impacted analytic reporting.\nContributed to CI/CD pipeline enhancements, automating deployment processes to improve development workflow and speed of delivery.\nParticipated in debugging and monitoring activities, proactively addressing issues and ensuring system reliability.\nEffectively communicated technical concepts to team members and stakeholders, enhancing collaboration and understanding across departments."
    }
  ],
  "skills": " **Programming Languages**\n\t Python, JavaScript, TypeScript\n\n **Backend Frameworks**\n\t NodeJS, ExpressJS, NestJS, C#, .NET, Entity Framework, Microservices\n\n **Frontend Frameworks**\n\t HTML, CSS, ReactJS, NextJS, VueJS, NuxtJS, Angular, Material UI, Three.js, D3.js, React Native, Flutter, Chakra UI, TailwindCSS\n\n **API Technologies**\n\t RESTful API, GraphQL\n\n **Serverless and Cloud Functions**\n\t AWS, Azure, Azure Data Factory, Cloud Functions\n\n **Databases**\n\t MSSQL Server, MySQL, PostgreSQL, MongoDB, DynamoDB, CosmosDB, SQL, Data Modeling\n\n **DevOps**\n\t CI/CD, CI/CD pipelines, Monitoring, Debugging, Version Control\n\n **Cloud & Infrastructure**\n\t Azure, AWS\n\n **Other**\n\t UX/UI Design, Git, GitHub, Testing Tools: NUnit, xUnit, Selenium, Moq, Postman, Cypress, JMeter, Jest, Blockchain: Solidity, Ether.js, Web3.js, Ethereum, Performance Optimization, Communication, Apache Kafka, RabbitMQ, Redis, DBT"
}