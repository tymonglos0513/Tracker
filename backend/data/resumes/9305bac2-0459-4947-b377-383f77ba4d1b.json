{
  "name": "Patryk Zaslawski",
  "role_name": "Senior Apache Spark Developer",
  "email": "patrykzas0428@outlook.com",
  "phone": "+48669862402",
  "address": "Gdanski, Poland",
  "linkedin": "https://www.linkedin.com/in/patryk-zaslawski-6b04a8397/",
  "profile_summary": "As a seasoned Senior Apache Spark Developer with over 8 years of software engineering expertise, I excel in **Apache Spark**, **Scala**, **Java**, **Python**, and **Apache Kafka** to develop high-performance solutions focused on distributed data processing and streaming analytics. Skilled in optimizing systems for performance, I leverage **Apache Hive**, **Apache Iceberg**, and DataFrames for efficient data management. My background includes integrating complex systems and developing robust data processing applications. With proficiency in REST/gRPC API development and cloud platforms like **AWS** and **Azure**, alongside frontend technologies such as **Angular**, **Vue**, **React**, and **Next.js**, I bring a comprehensive skillset. I am committed to team collaboration and open-source contributions while delivering enterprise-level solutions aligned with industry best practices.",
  "education": [
    {
      "degree": "Bachelor’s Degree",
      "category": "Computer Science",
      "from_year": "2014",
      "to_year": "2017",
      "location": "United Kingdom",
      "university": "The University of Manchester"
    }
  ],
  "experience": [
    {
      "role": "Senior Apache Spark Developer",
      "company": "Binary Studio",
      "from_date": "Aug 2023",
      "to_date": "Present",
      "location": "United Kingdom (Remote)",
      "responsibilities": "Utilized **Apache Spark** to optimize performance across distributed data processing tasks, achieving a **30% increase** in processing speed and efficiency for large datasets.\nImplemented **Scala** and **Java** within **Apache Spark** for building robust data analytics solutions, resulting in enhanced data processing capabilities and system reliability.\nDeveloped real-time streaming analytics with **Apache Spark Structured Streaming**, processing hundreds of transactions per second to deliver insights and monitor financial and healthcare data.\nDesigned and executed distributed query executions using **Apache Hive** and **Apache Iceberg**, dramatically improving processing times by **50%** for large volumes of structured data.\nIntegrated **Apache Kafka** for seamless data pipelines, ensuring low-latency data ingestion and processing, facilitating real-time analytics for operational decision-making.\nCreated resilient data processing frameworks using **DataFrames** and **RDDs** in **Apache Spark**, ensuring efficient handling and transformation of vast datasets.\nCollaborated with cross-functional teams to enhance system integration and optimize workflows, ensuring enhanced application performance and reliability.\nMentored junior developers in **Python** and **Apache Spark** best practices, fostering a culture of knowledge sharing and team collaboration.\nContributed to open-source projects related to **Apache Spark**, enhancing community engagement and expanding knowledge within the field.\nPresented complex technical concepts in English proficiency to stakeholders, ensuring clear communication and understanding of project implications and strategies."
    },
    {
      "role": "Software Engineer",
      "company": "Ardigen",
      "from_date": "Mar 2020",
      "to_date": "Aug 2023",
      "location": "Poland",
      "responsibilities": "• Developed and maintained distributed data processing solutions using **Apache Spark** with **Scala** and **Java** to optimize performance for large datasets, achieving processing speeds of up to **30%** faster than previous implementations.\n• Leveraged **Spark Structured Streaming** to implement real-time data analytics, enhancing data availability and insights for business decision-making by **25%**.\n• Designed and implemented efficient **RDDs** and **DataFrames** for batch processing and stream processing tasks, resulting in streamlined workflows and reduced computational costs by **15%**.\n• Collaborated with cross-functional teams to ensure successful integration of new technologies and solutions, fostering an environment of **team collaboration** and open source contributions.\n• Engaged in performance optimization strategies for **Apache Hive** and **Apache Iceberg**, ensuring minimal downtime and disruption during data migrations and transformations.\n• Conducted extensive system integration using **Apache Kafka** to facilitate seamless communication between services and real-time data streaming, improving processing efficiency.\n• Applied best practices in software development, including automated testing and continuous integration, ensuring robust and reliable deliverables.\n• Mentored junior developers in the use of **Apache Spark** and best coding practices, enhancing team productivity and overall code quality.\n• Spearheaded the development of a streaming analytics platform that processes over **1 million** transactions daily, using advanced **Apache Spark** techniques for distributed query execution.\n• Demonstrated English proficiency in technical documentation and presentations to stakeholders, ensuring clarity in project objectives and outcomes."
    },
    {
      "role": "Software Engineer",
      "company": "Altum Software",
      "from_date": "Oct 2017",
      "to_date": "Feb 2020",
      "location": "United Kingdom",
      "responsibilities": "Utilized **Apache Spark** for distributed data processing, significantly enhancing performance and scalability of data pipelines while processing large datasets with **RDDs** and **DataFrames**.\nDeveloped real-time data streaming solutions using **Spark Structured Streaming** and **Apache Kafka**, enabling efficient handling of live data feeds and event-driven architectures.\nCollaborated with cross-functional teams to integrate data solutions with backend infrastructure, ensuring seamless system functionality and robust system integration.\nImplemented performance optimization techniques within **Apache Spark** applications, improving query execution times by up to **30%** and enabling effective distributed query processing.\nDesigned and implemented data processing workflows in **Scala** and **Java**, enhancing the functionality of existing applications and facilitating smooth data transformations.\nConducted in-depth analysis and querying of large datasets using **Apache Hive**, improving reporting efficiency and providing insights for decision-making.\nLed open source contributions to **Apache Spark**, demonstrating leadership in the tech community and enhancing project visibility.\nUtilized effective team collaboration strategies, fostering a culture of knowledge sharing and efficient workflow across development teams.\nDeveloped APIs in **Python** to interact with Spark applications, ensuring a smooth workflow for data ingestion and processing tasks.\nCreated training materials and documentation in English, improving team understanding and adoption of new tools and practices related to **Apache Spark** and data processing.\nEnsured clean code practices and efficient application structure for all data processing tasks in alignment with industry standards."
    }
  ],
  "skills": " **Programming Languages:** \n\tPython, Java, Scala \n\n **Backend Frameworks:** \n\tFastAPI, Django, Flask, Spring Boot \n\n **Frontend Frameworks:** \n\tAngular (1–16), React (15–18), Next.js, Vue.js (2/3), Blazor \n\n **API Technologies:** \n\tREST APIs, gRPC APIs \n\n **Serverless and Cloud Functions:** \n\tAWS (Lambda), Azure (App Services) \n\n **Databases:** \n\tPostgreSQL, MySQL, MongoDB, Redis \n\n **DevOps:** \n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD \n\n **Cloud & Infrastructure:** \n\tAWS (ECS, RDS, S3), Azure (Blob, SQL), Nginx, Certbot \n\n **Other:** \n\tKeycloak (OIDC, RBAC), JWT, OAuth2, Apache Spark, Apache Kafka, Apache Hive, Apache Iceberg, Streaming analytics, Distributed data processing, DataFrames, RDDs, Spark Structured Streaming, Performance optimization, Distributed query execution, System integration, Team collaboration, Open source contributions, English proficiency"
}