{
  "name": "Patryk Zaslawski",
  "role_name": "Senior MLOps Engineer",
  "email": "patrykzas0428@outlook.com",
  "phone": "+48669862402",
  "address": "Gdanski, Poland",
  "linkedin": "https://www.linkedin.com/in/patryk-z-9b9455391/",
  "profile_summary": "Dynamic Senior MLOps Engineer with 8+ years of software engineering experience, specializing in **MLOps**, **Data Engineering**, and **Pipeline Orchestrators** such as **Dagster** and **Airflow**. Proven expertise in **Docker** and **Kubernetes** for containerization and orchestration to streamline deployment and scaling of machine learning models. Strong foundation in **Python** with skills in **FastAPI**, **Django**, and **Flask** to develop efficient data pipelines and integrations. Adept at leveraging distributed computing to enhance system performance and implementing data structures and algorithms for optimized solutions. My work in diverse sectors, including e-commerce and healthcare, allows me to create secure, reliable applications tailored to client needs while ensuring robust collaboration and proactivity within teams.",
  "education": [
    {
      "degree": "Bachelor’s Degree",
      "category": "Computer Science",
      "from_year": "2014",
      "to_year": "2017",
      "location": "United Kingdom",
      "university": "The University of Manchester"
    }
  ],
  "experience": [
    {
      "role": "Senior MLOps Engineer",
      "company": "Binary Studio",
      "from_date": "Aug 2023",
      "to_date": "Present",
      "location": "United Kingdom (Remote)",
      "responsibilities": "• Designed and implemented robust, scalable machine learning pipelines using **Python** and **Apache Airflow**, ensuring efficient orchestration and real-time data processing for healthcare applications.\n• Developed and optimized data engineering solutions leveraging **Python** libraries, ensuring high performance and reliability in handling large datasets through effective **data structures** and algorithms.\n• Implemented **MLOps** best practices to streamline the integration of machine learning models into production environments using **Docker** and **Kubernetes**, improving deployment efficiency by **45%**.\n• Led the architectural design of a cloud-native Healthcare Experience Platform using **Python** (FastAPI, Django, Flask) for secure data exchanges, achieving compliance with HIPAA, FHIR, and GDPR standards.\n• Mentored a cross-functional team of **10+** engineers in **Python** and **MLOps** methodologies, fostering a collaborative environment that enhances teamwork and proactivity.\n• Integrated **Docker** containers for microservices deployment which improved application scalability and reduced operational costs by **30%**.\n• Conducted performance analysis and supervised the deployment of machine learning models using tools such as **Dagster** for pipeline orchestrations, leading to continuous delivery and improvement.\n• Streamlined data processing and model training workflows using **distributed computing** paradigms, enhancing processing speeds for large data sets by as much as **50%**.\n• Championed the use of best programming practices and efficient data architectures, resulting in significant improvements in operational efficiency and model reliability.\n• Collaborated in refining project scopes and timelines, ensuring proactive tracking and accountability in project deliverables, leading to a **20%** increase in overall productivity."
    },
    {
      "role": "Software Engineer",
      "company": "Ardigen",
      "from_date": "Mar 2020",
      "to_date": "Aug 2023",
      "location": "Poland",
      "responsibilities": "• Developed and maintained scalable data pipelines using **Python**, **Dagster**, and **Airflow** to support various MLOps initiatives, ensuring high data quality and reliability.\n• Enhanced distributed computing capabilities with **Docker** and **Kubernetes**, automating the deployment of machine learning models and efficiently managing resources across microservices.\n• Designed robust data structures and algorithms to optimize machine learning workflows, ensuring efficient data processing and model training.\n• Collaborated with cross-functional teams to implement best practices in teamwork and proactivity, driving successful project outcomes and improving overall team efficiency.\n• Leveraged advanced **Python** libraries for data engineering tasks, optimizing data ingestion and transformation processes in real-time.\n• Implemented and managed containerized environments with **Kubernetes**, enabling rolling updates and enhancing the overall availability of MLOps services.\n• Created dynamic orchestration solutions to automate model training, evaluation, and deployment processes, improving response times by **30%**.\n• Developed and collaborated on MLOps solutions that effectively integrated with existing data infrastructure, supporting seamless workflows and reducing bottlenecks in machine learning pipelines.\n• Ensured compliance with data governance and security standards throughout the data engineering and MLOps processes, aligning with industry best practices.\n• Spearheaded the use of **ML models** in production environments, continuously monitoring performance and making necessary adjustments to adapt to changing data patterns.\n• Contributed to the innovation of data structures and algorithms in machine learning applications, improving model accuracy by an average of **15%** across various projects."
    },
    {
      "role": "Software Engineer",
      "company": "Altum Software",
      "from_date": "Oct 2017",
      "to_date": "Feb 2020",
      "location": "United Kingdom",
      "responsibilities": "Utilized **Python** for developing and optimizing MLOps pipelines, enhancing operational efficiency in machine learning model deployment and monitoring.\nDesigned and implemented data orchestration workflows using **Dagster** and **Airflow** to streamline data flow and ensure reliable data processing across distributed systems.\nLeveraged **Docker** for containerization of machine learning models, enabling consistent application deployment across various environments and ensuring scalability.\nImplemented distributed computing strategies to optimize model training times, improving overall efficiency by **30%** and reducing resource consumption.\nCollaborated with cross-functional teams to identify and address MLOps challenges, demonstrating strong teamwork and proactive problem-solving skills.\nDeveloped and maintained robust data pipelines for data engineering tasks, ensuring data integrity and accessibility for machine learning applications.\nApplied advanced data structures and algorithms to improve the efficiency of data processing and machine learning model performance.\nConducted performance testing and optimization, identifying bottlenecks in pipeline execution, resulting in a **25%** improvement in processing speed.\nConfigured and managed Kubernetes clusters for orchestration of machine learning workloads, ensuring high availability and fault tolerance.\nImplemented monitoring using tools like Prometheus and Grafana, providing insights into model performance and system health.\nFacilitated knowledge sharing within the team to foster a culture of continuous improvement in MLOps practices and technologies."
    }
  ],
  "skills": " **Programming Languages:**\n\tPython\n\n **Backend Frameworks:**\n\tFastAPI, Django, Flask, Spring Boot\n\n **Frontend Frameworks:**\n\tAngular (1–16), React (15–18), Next.js, Vue.js (2/3), Blazor\n\n **API Technologies:**\n\tREST & gRPC APIs\n\n **Serverless and Cloud Functions:**\n\tAWS (Lambda), Azure (App Services)\n\n **Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare), MongoDB (Gaming), Redis, SQLAlchemy\n\n **DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD\n\n **Cloud & Infrastructure:**\n\tAWS (ECS, RDS, S3), Azure (Blob, SQL), Proactivity\n\n **Other:**\n\tMLOps, Data Engineering, Pipeline Orchestrators, Airflow, Dagster, Distributed Computing, Machine Learning, Data Structures, Algorithms, Teamwork, Authentication & Security: Keycloak (OIDC, RBAC), JWT, OAuth2, Let’s Encrypt, Nginx, Certbot",
  "apply_company": "Fetcherr"
}