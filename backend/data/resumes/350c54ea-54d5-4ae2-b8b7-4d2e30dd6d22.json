{
  "name": "DANIEL HE",
  "role_name": "Big Data Engineer",
  "email": "daniel.he8@outlook.com ",
  "phone": "+48 730 743 032",
  "address": "Rzesz√≥w, Poland",
  "linkedin": "https://www.linkedin.com/in/daniel-he-a5a536397/",
  "profile_summary": "Results-driven Big Data Engineer with extensive experience in data analytics and processing using **Apache Spark**, **Python**, **SQL**, and cloud services like **AWS**. Proven expertise in leveraging **Redshift**, **Athena**, and **S3** for data management and storage, along with **Airflow** and **EMR** for workflow orchestration. Skilled in utilizing **Java** and proficient in database technologies including **MSSQL** and **Postgres**. Strong background in root cause analysis and unit testing to ensure high-quality deliverables. Recognized for enhancing healthcare, eCommerce, and finance applications through the development of scalable solutions, effective collaboration, and clear communication.",
  "education": [
    {
      "degree": "Bachelor's degree in Computer Science",
      "category": "Computer Science",
      "from_year": "2012",
      "to_year": "2016",
      "location": "Beijing, China ",
      "university": "Tsinghua University "
    }
  ],
  "experience": [
    {
      "role": "Big Data Engineer",
      "company": "Britenet",
      "from_date": "Feb 2023 ",
      "to_date": "Present",
      "location": "Warsaw, Poland",
      "responsibilities": "Utilized **AWS** services such as **S3**, **Redshift**, and **Athena** to manage and analyze large datasets, achieving up to **95%** accuracy in data retrieval and processing efficiency.\nEmployed **Apache Spark** for scalable data processing, optimizing query runtime by **40%** through efficient resource management and job scheduling.\nDeveloped and maintained ETL pipelines using **Airflow** and **EMR**, ensuring smooth data flow and validation across various sources.\nCollaborated with cross-functional teams to define project requirements and deliver data insights, enhancing team productivity by **30%**.\nConducted root cause analysis to troubleshoot complex data-related issues, significantly reducing error rates by implementing strategic logging and monitoring.\nExecuted unit testing practices in software development, improving the robustness of data processing applications by **25%**.\nLeveraged **Python** and **Scala** for data manipulation and analysis, ensuring the accuracy of metrics presented to stakeholders for decision-making."
    },
    {
      "role": "Software Engineer",
      "company": "Alibaba Group",
      "from_date": "Oct 2020 ",
      "to_date": "Dec 2022",
      "location": "Hangzhou, China",
      "responsibilities": "Utilized **AWS** services including **S3**, **Redshift**, and **Athena** to enhance data handling and analysis processes, achieving over a 30% improvement in data retrieval speeds.\nDeveloped ETL pipelines using **Apache Spark** and **Python**, processed large datasets and reduced data processing time by **40%**.\nImplemented **Airflow** for orchestration of data workflows, improving operational efficiency and ensuring timely data availability.\nConducted SQL queries and optimized performance on **MSSQL** and **Postgres**, which contributed to a **20%** increase in overall database performance.\nCollaborated with cross-functional teams to improve data architecture, contributing to a 15% decrease in redundancy and enhancing data accuracy.\nDeveloped and maintained unit testing protocols to ensure high data integrity and reliability.\nLed root cause analysis for production issues, demonstrating strong analytical skills and reducing downtime by **50%**."
    },
    {
      "role": "Software Engineer ",
      "company": "Huawei Technologies Co., Ltd",
      "from_date": "May 2016 ",
      "to_date": "Sep 2020",
      "location": "Shenzhen, China ",
      "responsibilities": "- Developed data processing pipelines using **Apache Spark** and **Python**, ensuring efficient data transformation and analysis.\n- Managed data storage solutions in **Redshift**, **Athena**, and **S3** to handle up to **50TB** of data.\n- Wrote optimized SQL queries to enhance data retrieval performance by **30%** using **PostgreSQL** and **MSSQL**.\n- Implemented and optimized ETL workflows with **Airflow**, achieving a **25%** reduction in processing time.\n- Conducted unit testing using **JUnit** and **Mockito**, leading to a **30%** decrease in production bugs.\n- Collaborated with cross-functional teams to streamline project communication, enhancing project delivery times by **20%**.\n- Performed root cause analysis on system issues, improving system uptime to **99%**."
    }
  ],
  "skills": " **Programming Languages**\n\tJava, JavaScript (React, Vue.js, Angular, Pixi.js, Vanilla JS, Node.js, TypeScript), Go, Python, SQL, Swift, Kotlin, Scala\n\n**Backend Frameworks**\n\tSpring Boot, Spring Security, Hibernate, Node.js, Express.js, JPA, Kafka, RabbitMQ\n\n**Frontend Frameworks**\n\tReact, Vue.js, Angular, Pixi.js, Redux, Next.js, React Router, Material-UI, Ant Design, D3.js, Webpack, Babel, Jest\n\n**API Technologies**\n\tRESTful API design, API Gateway\n\n**Serverless and Cloud Functions**\n\tAWS Lambda\n\n**Databases**\n\tMySQL, PostgreSQL, Redis, MongoDB, MSSQL, Redshift, Athena\n\n**DevOps**\n\tDocker, Kubernetes (AWS EKS), Jenkins, GitHub Actions, Terraform, AWS CodePipeline\n\n**Cloud & Infrastructure**\n\tAWS (EKS, RDS, CloudFront, S3), CloudWatch, ELK Stack\n\n**Other**\n\tMicroservices, CI/CD, Infrastructure as Code (IaC), Data structures and algorithms, Agile/Scrum methodologies, Unit Testing, Apache Spark, Airflow, EMR, Root Cause Analysis, Analytic Skills, Collaboration, Communication"
}