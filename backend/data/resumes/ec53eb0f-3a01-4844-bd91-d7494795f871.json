{
  "name": "Marcin Karol Kotlinski",
  "role_name": "Data Engineer",
  "email": "marcinkot55@outlook.com",
  "phone": "+48 732 779 243",
  "address": "Zgorzelec, Poland",
  "linkedin": "https://www.linkedin.com/in/marcin-karol-kotlinski-bb2520397/",
  "profile_summary": "As a Data Engineer with 8 years of experience, I specialize in developing robust and scalable data solutions leveraging **Python**, **SQL**, **NoSQL**, and **API REST** frameworks. My technical expertise includes using **Airflow** for orchestration, integrating data pipelines with **Databricks**, and executing analytics on **Big Data** technologies like **Spark**. I bring hands-on experience in **ETL** processes and am proficient with **Bash/Shell scripting** for automating data workflows.\n\nAdditionally, I have extensive knowledge of **cloud services** including **Azure**, **AWS**, and **GCP**, ensuring data governance and compliance with industry standards. My background in building comprehensive **Dashboards** and utilizing **BI** tools allows me to transform raw data into actionable insights. I am adept in managing data resources utilizing technologies such as **Hive**, **Impala**, **HBase**, and **Solr**. I excel in working with cross-functional teams, bringing a mixture of strong design skills and strategic data management capabilities.",
  "education": [
    {
      "degree": "Master’s Degree in Computer Science",
      "category": "",
      "from_year": "2017",
      "to_year": "2018",
      "location": "UK",
      "university": "University of Oxford"
    },
    {
      "degree": "Bachelor’s Degree in Computer Science",
      "category": "",
      "from_year": "2015",
      "to_year": "2017",
      "location": "UK",
      "university": "University of Oxford"
    }
  ],
  "experience": [
    {
      "role": "Data Engineer",
      "company": "EVNE Developers",
      "from_date": "Oct 2023",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "- Developed and maintained ETL pipelines using **Python**, **SQL**, and **NoSQL** databases, ensuring efficient data processing and integration for large-scale healthcare and financial systems.\n- Designed and optimized cloud-based data architectures utilizing **Azure**, **AWS**, and **GCP** services, improving data storage and retrieval performance.\n- Implemented data governance frameworks to ensure quality and compliance in data management across platforms, focusing on security and regulatory standards.\n- Built data visualization dashboards using **Power BI Embedded** and other BI tools, facilitating real-time insights and decision-making based on operational KPIs.\n- Automated data workflows and monitoring processes using **Airflow** and **Databricks**, enhancing operational efficiency by **30%**.\n- Collaborated with cross-functional teams to ensure alignment on data-related projects and support data-driven decision making, leading to a **25%** reduction in time to insights.\n- Streamlined data management operations through implementing **DevOps** principles, resulting in a **40%** improvement in deployment speed and reliability.\n- Engaged in data modeling and management using **Spark**, ensuring effective handling of big data workloads for analytics and reporting.\n- Conducted in-depth data analysis and processing using tools like **Hive**, **Impala**, and **HBase** for efficient querying and data manipulation.\n- Established robust API REST services to facilitate smooth data exchanges and integrations for various applications.\n- Implemented batch and real-time data processing methodologies, enabling **100%** data accuracy and timeliness for reporting.\n- Developed and maintained documentation for data processes and governance standards, ensuring consistency and clarity across teams."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Air Force",
      "from_date": "Oct 2021",
      "to_date": "Sep 2023",
      "location": "Poland",
      "responsibilities": "Utilized **Python**, **SQL**, and **NoSQL** technologies to design and implement scalable data pipelines that processed over **100,000** transactions daily, enabling efficient data governance and access for analytical purposes.\nEngineered robust **ETL** processes using **Apache Airflow** and **Azure Data Factory**, ensuring seamless data ingestion and transformation from various internal and third-party sources, significantly reducing processing time by **30%**.\nDeveloped and maintained high-performance **SQL** and **NoSQL** databases, including **HBase** and **Solr**, to support fast querying and storage of large datasets, improving data retrieval speeds by **40%**.\nCreated interactive dashboards and reports using **Power BI** and **D3.js**, enhancing data visualization for operational teams and stakeholders, which drove a **25%** increase in decision-making efficiency.\nImplemented **API REST** services for data retrieval and manipulation, integrating seamlessly with various data sources and enhancing data accessibility for services and applications.\nOptimized data storage and management strategies within **Azure**, **AWS**, and **GCP** cloud environments, adhering to best practices for **DataOps** and **Big Data** management, enabling scalable and cost-effective solutions.\nCollaborated with cross-functional teams to establish **Data Governance** frameworks, ensuring compliance and accuracy of financial and operational data across the organization.\nLeveraged **Spark** for data processing and analytics, effectively analyzing large datasets in real time and contributing actionable insights for operational improvements.\nDeveloped **Bash/Shell scripts** to automate routine tasks, increasing operational efficiency and reducing manual errors in data handling."
    },
    {
      "role": "Software Engineer",
      "company": "DeepInspire",
      "from_date": "Sep 2018",
      "to_date": "Aug 2021",
      "location": "UK",
      "responsibilities": "Utilized **Python** and SQL to design scalable data pipelines and ETL processes, ensuring seamless integration of diverse data sources into the analytics ecosystem.\nManaged **NoSQL** databases such as MongoDB and Cassandra, along with **SQL** databases like PostgreSQL, to maintain high availability and responsive data access.\nImplemented robust **API REST** services to facilitate efficient data interchange between various applications and services, optimizing performance and reducing latency across the platform.\nEmployed **Bash/Shell scripting** to automate data workflows and enhance operational efficiency, achieving a reduction in processing times by **30%** in critical ETL tasks.\nLeveraged **Apache Hive**, **Impala**, and **HBase** for large-scale data queries and storage, effectively handling datasets exceeding **10TB** in size.\nDeveloped data governance frameworks to ensure compliance with best practices and regulations, improving data quality and lineage tracking significantly.\nUtilized **Azure**, **AWS**, and **GCP** cloud services for data storage, processing, and management, successfully deploying solutions that scaled to support **500+** concurrent users.\nIntegrated **Databricks** and **Apache Spark** for real-time data processing and analytics, enhancing processing times for big data workloads by **40%**.\nOrchestrated workflows using **Apache Airflow**, streamlining pipeline dependencies and scheduling, which improved data processing reliability.\nCreated insightful **BI dashboards** and reports that provided key stakeholders with real-time data insights, driving data-informed decision-making processes.\n"
    }
  ],
  "skills": "**Programming Languages:**\n\tPython, SQL, Bash/Shell script\n\n**Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n**Frontend Frameworks:**\n\tJavaScript/TypeScript (React, Vue, Angular)\n\n**API Technologies:**\n\tAPI REST\n\n**Serverless and Cloud Functions:**\n\tAWS (ECS, Lambda, RDS, S3), Azure (App Services, Blob, SQL), GCP\n\n**Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare), MongoDB (Gaming), Redis, NoSQL, Hive, Impala, HBase, Solr\n\n**DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, CI/CD & Infrastructure as Code, Terraform, Ansible, Helm, Docker Compose\n\n**Cloud & Infrastructure:**\n\tAWS, Azure, GCP\n\n**Other:**\n\tMLflow, Airflow, Kubeflow, DataOps, Data Governance, Big Data, BI, Dashboards, ETL"
}