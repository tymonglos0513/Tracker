{
  "name": "Rei Taro",
  "role_name": "Senior Data Engineer",
  "email": "rei515@outlook.com",
  "phone": "+48732529451",
  "address": "Warszawa, Poland",
  "linkedin": "https://www.linkedin.com/in/rei-taro-81a410391/",
  "profile_summary": "Results-driven Senior Data Engineer with 10+ years of experience in data warehousing, SQL Server Administration, and ETL processes to build robust data models. Proficient in **Microsoft Fabric**, **SQL**, **Power BI**, and **SQL Server Integrated Services** for data analysis and visualization, along with a deep understanding of disaster recovery and backup strategies. Experienced in creating high-impact data pipelines and integrations in cloud-native environments, leveraging **Python** and **R** for data manipulation and analytics. Recognized for problem-solving abilities and keen attention to detail, successfully delivering projects for top-tier organizations including VISA and Reply Polska.",
  "education": [
    {
      "degree": "Bachelorâ€™s Degree in Computer Science",
      "category": "",
      "from_year": "2010",
      "to_year": "2015",
      "location": "Japan",
      "university": "Keio University"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "Leobit",
      "from_date": "Aug 2022",
      "to_date": "Present",
      "location": "Poland",
      "responsibilities": "Utilized **Microsoft Fabric** to optimize data integration and analysis processes, enhancing overall reporting capabilities.\nEngineered data transformation and ETL processes utilizing **Python** and **SQL** for effective data modeling and storage within **SQL Server**.\nDeveloped and maintained data warehouses to support analytics and reporting initiatives, ensuring data integrity and accessibility in line with business requirements.\nImplemented **SQL Server Integration Services (SSIS)** for automated data workflows and ensured efficient data migration by overseeing **disaster recovery** and **backup and recovery** plans, achieving **99.9%** uptime.\nCreated comprehensive reports and visualizations using **Power BI** to facilitate strategic decision-making based on analyzed data trends.\nLed data processing and management projects across cloud environments, particularly focusing on **Cloud Data Warehouses**, to improve data accessibility for stakeholders by reducing query times by up to **50%**.\nApplied strong **attention to detail** and **problem-solving** skills to troubleshoot data discrepancies, ensuring high-quality deliverables for product integration.\nFostered effective communication with cross-functional teams to align on project goals and objectives, ensuring smooth data pipeline operations."
    },
    {
      "role": "Software Engineer",
      "company": "Innovature",
      "from_date": "Nov 2018",
      "to_date": "Jun 2022",
      "location": "Japan",
      "responsibilities": "Utilized **Microsoft Fabric** for data integration to enhance reporting and analytics workflows, ensuring accessibility of insights for stakeholders.\nDesigned and implemented data models in **SQL Server** to optimize performance and support data integrity across the organization, resulting in improved data retrieval speed by **20%**.\nDeveloped and managed **ETL** processes to transform raw data into actionable insights, employing **SQL Server Integrated Services** and maintaining compliance with industry standards.\nExecuted disaster recovery and backup strategies, achieving a recovery point objective (RPO) of **30 minutes** and minimizing data loss risk.\nCreated comprehensive dashboards in **Power BI** for real-time data visualization, increasing report generation efficiency by **40%** and enhancing decision-making capabilities.\nEngineered solutions for **Data Warehousing**, improving data storage efficiency and supporting analytical workloads with structured data.\nApplied **Python** for developing scripts and automation processes that improved ETL pipeline efficiency, reducing runtime by **25%**.\nCollaborated with cross-functional teams to ensure consistent communication and problem-solving, resulting in streamlined projects and successful release management.\nConducted detailed requirements analysis and data modelling efforts, ensuring an attention to detail that led to a **15%** increase in data accuracy."
    },
    {
      "role": "Software Developer",
      "company": "Wizcorp",
      "from_date": "Apr 2015",
      "to_date": "Nov 2018",
      "location": "Japan",
      "responsibilities": "Utilized **Python** and **SQL** for data extraction and transformation processes, enhancing the efficiency of data pipelines in a **Cloud Data Warehouse** environment.\nImplemented and maintained **ETL** systems using **SQL Server Integration Services** (SSIS) to streamline data ingestion from multiple sources, processing over **100GB** of data daily.\nDesigned and managed **SQL Server Administration** services to ensure optimal performance and reliability, including disaster recovery strategies for data integrity with a **99.9% uptime**.\nDeveloped sophisticated data models within the data warehouse to support analytics and reporting using **Power BI**, enabling stakeholders to make informed decisions based on actionable insights.\nEmployed **Microsoft Fabric** to enhance data integration processes, facilitating seamless connectivity and collaboration across multiple data platforms.\nApplied attention to detail and problem-solving skills to troubleshoot and resolve data discrepancies, ensuring accuracy in reporting and analysis.\nCommunicated effectively with cross-functional teams to understand requirements for data delivery, ensuring that solutions met business needs and compliance standards.\nExecuted disaster recovery and backup strategies, successfully reducing downtime and ensuring data preservation in case of failure, contributing to overall organizational resilience.\nDelivered training sessions on **R** and data visualization techniques, empowering team members to leverage analytical tools for enhanced productivity."
    }
  ],
  "skills": "**Programming Languages**\n\tPython, SQL, R\n\n**Backend Frameworks**\n\tFastAPI, Flask, Django, Celery\n\n**Frontend Frameworks**\n\t\n\n**API Technologies**\n\tREST/gRPC APIs, Microservices\n\n**Serverless and Cloud Functions**\n\tAWS (EC2, S3, Lambda), Azure\n\n**Databases**\n\tPostgreSQL, MySQL, MongoDB, Redis, SQL Server Administration, Cloud Data Warehouses\n\n**DevOps**\n\tDocker, Kubernetes, GitHub Actions, Azure DevOps, CI/CD\n\n**Cloud & Infrastructure**\n\tMicrosoft Fabric, Data Warehouse, ETL, Data Modelling, SQL Server Integrated Services, Disaster Recovery, Backup and Recovery\n\n**Other**\n\tAttention to Detail, Problem Solving, Communication, AI/ML Tools (Pandas, NumPy, scikit-learn, TensorFlow, Airflow, MLflow), Kafka, PyTest, Git",
  "apply_company": "IPRS Health"
}