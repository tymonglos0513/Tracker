{
  "name": "Rei Taro",
  "role_name": "Senior Backend Engineer",
  "email": "rei515@outlook.com",
  "phone": "+48732529451",
  "address": "Warszawa, Poland",
  "linkedin": "https://www.linkedin.com/in/rei-taro-81a410391/",
  "profile_summary": "Senior Backend Engineer with over 10 years of experience in backend system design and delivery, specializing in financial platforms and AI/ML pipelines. Expert in **Python**, particularly with frameworks such as **Django** and **Django REST**, and proficient in **Celery** for asynchronous processing. Skilled in database management with **PostgreSQL** and adept at monitoring and logging using **Sentry**, **Datadog**, and **Grafana**. Familiar with **Kubernetes** for orchestration, **ClickHouse** and **Elasticsearch** for advanced data retrieval and analytics, and proficient in API standards like **OpenAPI**. Committed to delivering high-performing APIs and scalable services while utilizing tools like **Git** for version control and implementing effective caching strategies. Proven ability to drive impactful results at top-tier organizations, including VISA, Sii Poland, and Reply Polska.",
  "education": [
    {
      "degree": "Bachelor’s Degree in Computer Science",
      "category": "",
      "from_year": "2010",
      "to_year": "2015",
      "location": "Japan",
      "university": "Keio University"
    }
  ],
  "experience": [
    {
      "role": "Senior Backend Engineer",
      "company": "Leobit",
      "from_date": "Aug 2022",
      "to_date": "Present",
      "location": "Poland",
      "responsibilities": "Utilized **Python** and **Django** to engineer scalable backend services, emphasizing the optimization of document automation and user onboarding processes.\nImplemented **Celery** for asynchronous processing, alongside **Redis**, enhancing system efficiency for up to **1000** financial transaction requests daily.\nDeployed robust microservices on **Azure App Services** while using **Terraform** for managing infrastructure as code, contributing to a **50%** reduction in deployment time.\nCreated and maintained data pipelines leveraging **Apache Airflow** and **Azure Functions** to ensure compliance in regulatory data exchange with a processing frequency of every **hour**.\nConducted extensive security assessments and integrated **OAuth2** and **Azure AD B2C** for secure authentication, serving over **10,000** users safely.\nCollaborated with cross-functional teams to proactively address and resolve system integration challenges, ensuring compliance with industry standards and overseeing release strategies."
    },
    {
      "role": "Software Engineer",
      "company": "Innovature",
      "from_date": "Nov 2018",
      "to_date": "Jun 2022",
      "location": "Japan",
      "responsibilities": "• Developed backend systems using **Python** and **FastAPI** to automate document workflows, streamline user onboarding, and handle complex reporting processes.\n• Created event-driven microservices with **Celery** and **Redis**, enabling asynchronous processing of financial data and transaction requests.\n• Managed the deployment of microservices on **Azure App Services**, leveraging **Terraform** for infrastructure automation to maintain consistent and scalable environments across **3** critical applications.\n• Engineered data pipelines for secure exchange of regulatory data, utilizing **Apache Airflow** and **Azure Functions** to automate and streamline data flow, achieving process efficiency improvements by **25%**.\n• Conducted security audits to ensure compliance with industry standards, integrating **OAuth2** and **Azure AD B2C** for managing authentication and securing access controls for over **5000** users.\n• Collaborated with cross-functional teams to ensure smooth system integration, regulatory compliance, and successful release management, achieving a deployment success rate of **98%**."
    },
    {
      "role": "Software Developer",
      "company": "Wizcorp",
      "from_date": "Apr 2015",
      "to_date": "Nov 2018",
      "location": "Japan",
      "responsibilities": "Utilized **Python** and **Django REST** to develop backend services for trade execution, portfolio management, and account tracking, significantly enhancing trading operations.\nEngineered asynchronous processing with **Celery** for job queuing and scheduling, optimizing backend task execution with a processing increase of over **30%**.\nImplemented robust databases using **PostgreSQL** and **ClickHouse**, managing data for up to **10,000** active trading accounts while ensuring rapid data retrieval and integrity.\nCollaborated with frontend teams, delivering data through REST APIs and WebSocket channels, ensuring seamless user interactions and real-time data updates.\nEnsured compliance with regulatory requirements, including **MiFID II** and **GDPR**, while implementing data security protocols and best practices.\nDeveloped comprehensive test suites with **PyTest** and **tox**, increasing code coverage by **50%** and streamlining QA and CI processes for more efficient development cycles.\nIntegrated monitoring solutions using **Sentry**, **Datadog**, and **Grafana** to analyze system performance, leading to proactive issue resolution and enhancement of operational stability.\nEmployed **Kubernetes** for container orchestration, improving deployment speed by over **40%** and enhancing scalability during peak trading hours.\nUtilized caching strategies with **Redis**, improving data access times by **25%** and increasing overall system responsiveness."
    }
  ],
  "skills": "**Programming Languages**\n\tPython, SQL, Bash, JavaScript\n\n**Backend Frameworks**\n\tDjango, Django REST, FastAPI, Flask, Celery\n\n**Frontend Frameworks**\n\t\n\n**API Technologies**\n\tREST/gRPC APIs, OpenAPI\n\n**Serverless and Cloud Functions**\n\tAWS (EC2, S3, Lambda), Azure\n\n**Databases**\n\tPostgreSQL, MySQL, MongoDB, Redis, ClickHouse, Elasticsearch\n\n**DevOps**\n\tDocker, Kubernetes, GitHub Actions, Azure DevOps, CI/CD, Sentry, Datadog, Grafana\n\n**Cloud & Infrastructure**\n\t\n\n**Other**\n\tAI/ML Tools: Pandas, NumPy, scikit-learn, TensorFlow, Airflow, MLflow, Microservices, Kafka, Caching, Asynchronous Processing, Profiling Tools, PyTest, Git",
  "apply_company": "Search Atlas"
}