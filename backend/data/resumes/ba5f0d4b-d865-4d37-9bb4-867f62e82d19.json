{
  "name": "Rei Taro",
  "role_name": "Lead Data Engineer",
  "email": "rei515@outlook.com",
  "phone": "+48732529451",
  "address": "Warszawa, Poland",
  "linkedin": "https://www.linkedin.com/in/rei-taro-81a410391/",
  "profile_summary": "Results-oriented Lead Data Engineer with over 10 years of experience in designing robust data pipelines, utilizing technologies such as **Azure Data Factory**, **Synapse**, **Databricks**, **ETL**, **ELT**, and **SQL**, while ensuring seamless data governance and modeling. Skilled in implementing **DataOps** and **DevOps** strategies for end-to-end data integration and automation. Proficient in cloud platforms including **Microsoft Azure**, **AWS**, and **Google Cloud**, with a strong focus on creating cloud-native data warehouse solutions and reporting via **Power BI**. Proven history of delivering impactful projects for leading organizations such as VISA, Sii Poland, and Reply Polska, showcasing expertise in backend system design and development with **Python** (FastAPI, Django, Flask).",
  "education": [
    {
      "degree": "Bachelorâ€™s Degree in Computer Science",
      "category": "",
      "from_year": "2010",
      "to_year": "2015",
      "location": "Japan",
      "university": "Keio University"
    }
  ],
  "experience": [
    {
      "role": "Lead Data Engineer",
      "company": "Leobit",
      "from_date": "Aug 2022",
      "to_date": "Present",
      "location": "Poland",
      "responsibilities": "Engineered robust data pipelines leveraging **Azure Data Factory**, **Databricks**, and **Data Lake** to ensure streamlined ETL and ELT processes for optimal data governance and reporting workflows.\nDeveloped data integration solutions using **Python** and **SQL**, enhancing data accessibility and modeling capabilities for analytics and reporting.\nOrchestrated data workflows with **Apache Airflow** and **Azure Functions**, with a focus on timeliness and accuracy, resulting in a **30%** reduction in data latency for reporting.\nImplemented cloud-native architecture on **Microsoft Azure** and managed infrastructure as code with **Terraform**, facilitating efficient data operations and governance.\nLed efforts in **DataOps** and **DevOps** methodologies, driving continuous integration and delivery of data solutions while improving team collaboration and productivity by **25%**.\nConducted security assessments and embedded authentication strategies using **OAuth2** and **Azure AD B2C**, ensuring compliance and enhancing data protection measures across projects.\nCollaborated with multi-disciplinary teams to tackle cloud service integration challenges and optimize deployment strategies, contributing to a **15%** increase in project efficiencies."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Innovature",
      "from_date": "Nov 2018",
      "to_date": "Jun 2022",
      "location": "Japan",
      "responsibilities": "Designed and implemented robust data pipelines using **Azure Data Factory** and **Databricks** to ensure efficient ETL and ELT processes for data ingestion and reporting.\nEngineered cloud-native solutions in **Microsoft Azure**, utilizing **Data Lake** architecture to enable scalable data storage and processing with **SQL** for data querying.\nManaged comprehensive data governance strategies and ensured compliance through effective data modeling and reporting techniques, contributing to regulatory adherence and quality assurance.\nApplied **DevOps** methodologies to automate deployment processes, enhancing teamwork and production efficiency while minimizing downtime by **30%**.\nUtilized **Apache Airflow** for workflow orchestration, achieving a **20%** increase in data pipeline processing speed through optimized scheduling and monitoring techniques.\nAdministered deployment of solutions across multiple cloud platforms including **AWS** and **Google Cloud** to enhance system reliability and expand infrastructure capabilities.\nLed cross-functional collaboration efforts, resulting in the successful integration of data projects and compliance initiatives, culminating in a **15%** reduction in project turnaround times."
    },
    {
      "role": "Software Developer",
      "company": "Wizcorp",
      "from_date": "Apr 2015",
      "to_date": "Nov 2018",
      "location": "Japan",
      "responsibilities": "Utilized **Azure Data Factory** and **Azure Data Lake** to design and implement robust ETL processes, enhancing data pipeline efficiency by **30%**.\nDeveloped data models and reporting frameworks using **Power BI** and **SQL**, leading to a **25%** increase in data accessibility for stakeholders.\nEngineered scalable data processing solutions using **Databricks** and **Python**, resulting in the ability to handle up to **10 TB** of data daily.\nCollaborated cross-functionally with DevOps teams to integrate **DataOps** best practices, improving deployment frequency by **40%**.\nEnsured compliance with data governance standards while managing data security concerns in cloud-native environments like **AWS** and **Google Cloud**.\nImplemented automated job scheduling and monitoring solutions using **Celery** and **RabbitMQ** to optimize backend processes.\nDesigned and maintained effective data pipelines for real-time data streaming, significantly reducing latency in data delivery for analytics.\n"
    }
  ],
  "skills": "**Programming Languages**\n\tPython (3.8+), SQL, JavaScript\n\n**Backend Frameworks**\n\tFastAPI, Flask, Django, Celery\n\n**API Technologies**\n\tREST/gRPC APIs\n\n**Serverless and Cloud Functions**\n\tAWS (EC2, S3, Lambda), Azure\n\n**Databases**\n\tPostgreSQL, MySQL, MongoDB, Redis\n\n**DevOps**\n\tDocker, Kubernetes, GitHub Actions, Azure DevOps, CI/CD\n\n**Cloud & Infrastructure**\n\tMicrosoft Azure, Google Cloud, Cloud-native data warehouse, Cloud certifications\n\n**Other**\n\tAI/ML Tools: Pandas, NumPy, scikit-learn, TensorFlow, Airflow, MLflow, Microservices, Kafka, PyTest, Data Lake, DataOps, Data modeling, Data pipelines, Data reporting, Data governance, Power BI, Azure Data Factory, Synapse, Databricks, ETL, ELT, Azure Data Engineer"
}