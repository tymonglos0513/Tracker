{
  "name": "Rei Taro",
  "role_name": "Senior Data Engineer",
  "email": "rei515@outlook.com",
  "phone": "+48732529451",
  "address": "Warszawa, Poland",
  "linkedin": "https://www.linkedin.com/in/rei-taro-81a410391/",
  "profile_summary": "Results-driven Senior Data Engineer with over 10 years of experience in designing and optimizing data pipelines and backend systems for financial applications. Proficient in **AWS** services including **Redshift**, **S3**, **Glue**, and **Lambda**, and experienced in data modeling, ETL, and ELT processes to enhance data workflows. Strong command of **Python** for data manipulation and orchestration, as well as experience with NoSQL databases. Proven ability in collaborating within **Agile** teams, ensuring high data quality and adherence to data privacy standards. Adept at employing **Docker** and **Kubernetes** for containerization and orchestration, driving efficiency and scalability. Demonstrated success in delivering impactful solutions at leading organizations like VISA and Reply Polska, emphasizing strong communication and problem-solving skills.",
  "education": [
    {
      "degree": "Bachelorâ€™s Degree in Computer Science",
      "category": "",
      "from_year": "2010",
      "to_year": "2015",
      "location": "Japan",
      "university": "Keio University"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "Leobit",
      "from_date": "Aug 2022",
      "to_date": "Present",
      "location": "Poland",
      "responsibilities": "Utilized **Python** to engineer and optimize backend services, focusing on data automation and ETL processes for efficient data handling.\nDeveloped robust data pipelines using **AWS Glue**, **AWS Lambda**, and **Amazon Redshift** for seamless data integration and modeling, ensuring high data quality and compliance.\nImplemented containerization and orchestration with **Docker** and **Kubernetes** to streamline deployment and enhance scalability for data solutions.\nManaged and optimized NoSQL databases, incorporating strategies for data privacy and maintaining data integrity.\nEmployed Agile methodologies to collaborate with cross-functional teams, effectively communicating and addressing integration challenges.\nLed the application of MLOps practices to deploy and monitor machine learning models, ensuring they meet business requirements and performance standards.\nExecuted data quality assessments, implementing continuous improvement strategies to elevate data accuracy and reliability across projects.\nSpearheaded the automation of data-driven processes, utilizing **AWS S3** for storage solutions, thereby enhancing operational efficiency by **30%** over a **6-month** period."
    },
    {
      "role": "Software Engineer",
      "company": "Innovature",
      "from_date": "Nov 2018",
      "to_date": "Jun 2022",
      "location": "Japan",
      "responsibilities": "Utilized **Python** for backend development to create and optimize data pipelines, ensuring efficient ETL and ELT processes for handling large datasets from multiple sources.\nImplemented data modeling strategies and employed **AWS Glue** to automate data preparation tasks, enhancing data quality and accessibility for analytics.\nDeveloped and maintained scalable **AWS Lambda** functions for serverless computing, enabling real-time data processing and integration with other **AWS** services such as **S3** and **Redshift**.\nManaged deployment and orchestration using **Docker** and **Kubernetes**, ensuring efficient resource utilization and streamlined application delivery across environments.\nEngineered complex data solutions with a focus on **NoSQL** databases to facilitate flexible data storage and retrieval, resulting in a **35%** increase in query performance.\nCollaborated effectively with cross-functional teams to adhere to data privacy regulations and perform security audits, ensuring compliance with industry standards such as GDPR and CCPA.\nApplied **Agile** methodologies to successfully lead a team of 5 data engineers in delivering data solutions and improving project timelines by **15%** through effective communication and problem-solving skills."
    },
    {
      "role": "Software Developer",
      "company": "Wizcorp",
      "from_date": "Apr 2015",
      "to_date": "Nov 2018",
      "location": "Japan",
      "responsibilities": "Utilized **AWS** services such as **S3** and **Lambda** for scalable ETL processes, direct data pipelines, and storage solutions in support of data engineering projects.\nDeveloped and optimized data models using **SQL** and **Redshift** to enhance data retrieval and reporting efficiency, achieving a **30%** improvement in query response times.\nImplemented data quality frameworks to ensure compliance with data privacy regulations including GDPR, while effectively managing sensitive information.\nEngineered data integration workflows leveraging **Glue** to facilitate seamless data flow between systems, improving data accessibility by **25%**.\nCollaborated with cross-functional teams in an **Agile** environment to design and deliver robust data solutions, ensuring alignment with business objectives through effective communication and teamwork.\nStreamlined data processing and orchestration using **Docker** and **Kubernetes**, resulting in a **40%** reduction in deployment times and enhanced system reliability.\nApplied **Python** and **R** for data analysis and modeling, solving complex business problems and providing actionable insights to stakeholders.\nExecuted MLOps strategies by integrating machine learning models into production environments, increasing automated predictions by **15%**."
    }
  ],
  "skills": "**Programming Languages**\n\tPython (3.8+), SQL, R\n\n**Backend Frameworks**\n\tFastAPI, Flask, Django, Celery\n\n**API Technologies**\n\tREST/gRPC APIs, Microservices\n\n**Serverless and Cloud Functions**\n\tAWS (EC2, S3, Lambda), Glue, FSx\n\n**Databases**\n\tPostgreSQL, MySQL, MongoDB, Redis, Redshift, NoSQL\n\n**DevOps**\n\tDocker, Kubernetes, GitHub Actions, Azure DevOps, CI/CD\n\n**Cloud & Infrastructure**\n\tAWS, Azure\n\n**Other**\n\tAI/ML Tools: Pandas, NumPy, scikit-learn, TensorFlow, Airflow, MLflow, Data Modeling, ETL, ELT, MLOps, Data Quality, Data Privacy, Agile, Communication, Collaboration, Problem-solving",
  "apply_company": "Atorus"
}