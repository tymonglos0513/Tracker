{
  "name": "Tomasz Lee",
  "role_name": "Senior Data Engineer",
  "email": "tomasz.lee8@outlook.com",
  "phone": "+48 732 145 942",
  "address": "Warsaw, Poland",
  "linkedin": "https://www.linkedin.com/in/tomasz-lee-b9a25a391/",
  "profile_summary": "Accomplished Senior Data Engineer with 9+ years of experience in leveraging **Big Data** technologies, including **Spark**, **Databricks**, and **AWS**. Proficient in data analysis using **SQL**, **Python**, and **Scala**, specializing in the implementation of **CI/CD** pipelines and **Infrastructure-as-Code** practices to optimize data workflows. Demonstrated expertise in **monitoring** and **logging** for enhanced performance and reliability of data systems. With a strong foundation in **microservices architecture**, I excel in cross-team collaboration and leading projects to drive successful outcomes. Skilled in both UI/UX design and backend development, I am committed to delivering high-quality, scalable solutions.",
  "education": [
    {
      "degree": "Master of Computer Science",
      "category": "",
      "from_year": "Apr 2012",
      "to_year": "Oct 2014",
      "location": "",
      "university": "National University of Singapore"
    },
    {
      "degree": "Bachelor of Computer Science",
      "category": "",
      "from_year": "Apr 2008",
      "to_year": "Mar 2012",
      "location": "",
      "university": "National University of Singapore"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "CD Projekt RED",
      "from_date": "May 2022",
      "to_date": "Oct 2025",
      "location": "Warsaw, Poland",
      "responsibilities": "Utilized **AWS** services and **Databricks** for processing large datasets efficiently, enhancing data processing capabilities by 50%.\nDeveloped and maintained data pipelines using **Spark**, optimizing data workflows and ensuring high data quality across projects.\nImplemented CI/CD strategies with **Infrastructure-as-Code** using **Terraform** to streamline deployment processes, reducing time to production by 40%.\nDesigned logging and monitoring solutions to track data pipeline performance and data integrity, improving operational visibility by 30%.\nCollaborated with cross-functional teams to establish **DataContracts**, ensuring consistency and accuracy in data exchanges among systems.\nCreated interactive dashboards and reports using **SQL** and **Python**, leading to actionable insights and improved decision-making processes.\nEnhanced the user experience (UX) of data applications by working closely with designers to meet user expectations.\nConducted data analysis using **Scala** and **Python**, driving efficiency improvements within data-processing frameworks.\nImplemented advanced logging mechanisms to capture and analyze system behavior, facilitating proactive performance tuning and incident response.\nConducted workshops in **German** to train stakeholders on data tools and methodologies, enhancing team collaboration and project engagement."
    },
    {
      "role": "Software Engineer",
      "company": "Sea Group",
      "from_date": "Mar 2018",
      "to_date": "Apr 2022",
      "location": "Shopee, Singapore",
      "responsibilities": "Utilized **AWS** and **Databricks** to design and implement scalable data processing pipelines, improving data handling efficiency by **40%**.\nDeveloped ETL processes using **Spark** and **Python** to transform and analyze large datasets, achieving a **50%** reduction in processing time.\nImplemented **SQL** queries for data extraction and manipulation, optimizing performance which led to a **30%** decrease in run times.\nArchitected solutions using **Infrastructure-as-Code** principles, enabling seamless deployment and management of resources, reducing infrastructure setup time by **25%**.\nEstablished robust **CI/CD** pipelines utilizing tools such as **GitHub Actions**, which improved deployment frequencies and reduced rollback rates by **20%**.\nMonitored system performance and implemented logging strategies with **AWS CloudWatch**, enhancing system reliability and reducing downtime.\nCollaborated with cross-functional teams to define data contracts, ensuring data integrity and alignment with business objectives, which improved project delivery timelines by **15%**.\nCreated intuitive user experiences (UX) for data dashboards that increased user interactions and satisfaction ratings.\nLed data quality initiatives, empowering junior team members through code reviews and knowledge sharing sessions to foster a culture of continuous improvement."
    },
    {
      "role": "Software Developer",
      "company": "Grab Holdings Inc",
      "from_date": "Jan 2015",
      "to_date": "Feb 2018",
      "location": "Singapore",
      "responsibilities": "Utilized **BigData** analytics frameworks to manage extensive datasets effectively, ensuring data integrity and performance improvements across platforms.\nDeveloped ETL processes using **Spark** and **Databricks**, leading to a **35%** increase in data processing speed.\nDesigned and implemented data storage solutions in **AWS**, optimizing cloud resource usage and reducing operational costs by **15%**.\nApplied **Python** and **Scala** for data transformation and analysis, delivering actionable insights to the analytics team.\nImplemented **CI/CD** pipelines for data pipelines, which decreased deployment times by **40%**, enabling quicker iterations and feature releases.\nEmployed **Infrastructure-as-Code** strategies to manage infrastructure deployment, reducing configuration errors and increasing deployment speed.\nSet up comprehensive **monitoring** and **logging** mechanisms to track data pipeline performance and failures, enhancing overall system reliability.\nUsed **SQL** for efficient querying and data retrieval within large databases, improving response times by **25%**.\nCollaborated with UX designers to promote user-friendly data visualization tools, enhancing user engagement and data interpretation.\nProvided technical mentorship to junior engineers, fostering a culture of knowledge sharing and skill enhancement within the team."
    }
  ],
  "skills": "Programming Languages: Python, SQL, Scala\n\n\tBackend Frameworks: NodeJS, ExpressJS, NestJS, C#, .NET, Entity Framework, Microservices\n\n\tFrontend Frameworks: HTML, CSS, JavaScript, TypeScript, ReactJS, NextJS, VueJS, NuxtJS, Angular, Material UI, Three.js, D3.js, React Native, Flutter, Chakra UI, TailwindCSS\n\n\tAPI Technologies: RESTful API, GraphQL\n\n\tServerless and Cloud Functions: AWS, Azure\n\n\tDatabases: MSSQL Server, MySQL, PostgreSQL, MongoDB, DynamoDB, CosmosDB, BigData, Spark, Databricks\n\n\tDevOps: CI/CD, Infrastructure-as-Code, Monitoring, Logging\n\n\tCloud & Infrastructure: AWS, Azure\n\n\tOther: UX/UI Design, Git, GitHub, Redux, Blockchain: Solidity, Ether.js, Web3.js, Ethereum, German",
  "apply_company": "Finanzguru"
}