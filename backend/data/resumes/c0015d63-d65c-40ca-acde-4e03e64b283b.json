{
  "name": "Patryk Zaslawski",
  "role_name": "ML Engineer",
  "email": "patrykzas0428@outlook.com",
  "phone": "+48669862402",
  "address": "Gdanski, Poland",
  "linkedin": "https://www.linkedin.com/in/patryk-zaslawski-6b04a8397/",
  "profile_summary": "As a results-driven ML Engineer with 8+ years in software engineering, I am proficient in **Python**, **MLOps**, and **AWS**, specializing in designing and implementing efficient machine learning solutions. My expertise in frameworks such as **scikit-learn**, **TensorFlow**, and **PyTorch** allows me to build and optimize data ETL pipelines tailored for high-performance environments. I have a solid grasp of version control and software engineering best practices, ensuring robust code quality and enhancing team collaboration. Additionally, I leverage **Kubernetes** and **Lambda** for containerization and scalability, while employing **Redshift** for data warehousing solutions. My background also includes a thorough understanding of optimization techniques, testing strategies, and effective communication to align business needs with technical execution.",
  "education": [
    {
      "degree": "Bachelor’s Degree",
      "category": "Computer Science",
      "from_year": "2014",
      "to_year": "2017",
      "location": "United Kingdom",
      "university": "The University of Manchester"
    }
  ],
  "experience": [
    {
      "role": "ML Engineer",
      "company": "Binary Studio",
      "from_date": "Aug 2023",
      "to_date": "Present",
      "location": "United Kingdom (Remote)",
      "responsibilities": "- Developed and deployed machine learning models using **Python**, **scikit-learn**, **TensorFlow**, and **PyTorch**, enhancing the Healthcare Experience Platform's predictive analytics capabilities.\n- Designed and optimized **Data ETL pipelines** leveraging **Python** and cloud services such as **AWS** for scalable data ingestion and processing, achieving data transformation within **5 seconds** for real-time applications.\n- Implemented MLOps practices to streamline the deployment and monitoring of machine learning models, ensuring seamless integration with existing **Python microservices**.\n- Collaborated with cross-functional teams of 10+ engineers, promoting effective communication and collaboration while adhering to **software engineering best practices**.\n- Configured and maintained version control systems, ensuring smooth release management and traceability of model iterations in **Python** projects.\n- Developed comprehensive testing strategies, including unit tests and integration tests, utilizing **Python** tools like **PyTest** to ensure reliable and scalable model performance.\n- Utilized containerization strategies with **Kubernetes** to deploy machine learning models, enhancing scalability and operational efficiency of application workflows.\n- Established automated CI/CD pipelines for machine learning model deployment using **GitHub Actions** and **AWS Lambda**, reducing deployment times by **40%** and enhancing delivery cycles.\n- Integrated data storage solutions like **Redshift** to facilitate efficient storage and querying of model training datasets, significantly improving query times for large-scale data sets.\n- Spearheaded the automation of data labeling processes, using cloud functions to manage and optimize data workflows, improving the efficiency of the data preparation phase by **30%**.\n- Mentored junior engineers on machine learning best practices, fostering a culture of collaboration and knowledge sharing across engineering teams, while advocating for robust communication standards."
    },
    {
      "role": "Software Engineer",
      "company": "Ardigen",
      "from_date": "Mar 2020",
      "to_date": "Aug 2023",
      "location": "Poland",
      "responsibilities": "• Developed and deployed **Python**-based machine learning models utilizing **scikit-learn**, **TensorFlow**, and **PyTorch**, enhancing predictive analytics capabilities for financial transactions by over **30%**.\n• Designed and maintained **Data ETL pipelines** using **AWS Lambda**, achieving up to **50%** reduction in data processing time and increasing the efficiency of data flow.\n• Implemented best practices in **software engineering**, ensuring clean, maintainable **Python** code with a focus on automated unit testing using **PyTest** and integration testing through **Selenium**.\n• Collaborated with cross-functional teams to integrate machine learning solutions into existing **Python** microservices architecture, promoting cohesive development and deployment strategies.\n• Utilized **Kubernetes** for containerization of machine learning services, enabling seamless scaling and maintaining system reliability under varying loads.\n• Conducted thorough version control using **Git**, ensuring collaboration efficiency and consistent code quality across multiple projects.\n• Enhanced performance monitoring and data logging practices by implementing the **ELK stack** (**Elasticsearch, Logstash, Kibana**) within **Python** services, facilitating real-time insights and system optimization.\n• Communicated complex machine learning concepts effectively to stakeholders, fostering a data-driven culture and encouraging the adoption of machine learning strategies in project development.\n• Built predictive models that contributed to a **20%** increase in fraud detection rates, integrating these with **Python** services for real-time anomaly detection.\n• Developed secure and compliant financial data exchange protocols with external partners, ensuring robustness in machine learning model deployment for sensitive use cases."
    },
    {
      "role": "Software Engineer",
      "company": "Altum Software",
      "from_date": "Oct 2017",
      "to_date": "Feb 2020",
      "location": "United Kingdom",
      "responsibilities": "Utilized **Python** and **scikit-learn** to develop machine learning models, implementing software engineering best practices to enhance model accuracy by **20%**.\nDesigned and managed **Data ETL pipelines** to preprocess data effectively for machine learning tasks, ensuring data integrity and consistency across projects.\nBuilt and optimized model deployment processes using **AWS Lambda**, facilitating real-time machine learning inference with an average response time of **500ms**.\nImplemented containerization strategies using **Docker** and **Kubernetes** for scalable deployment of machine learning services, improving deployment efficiency by **30%**.\nConducted rigorous testing using **pytest** to ensure the robustness of machine learning applications, reducing bugs by **25%** before production release.\nCollaborated with cross-functional teams to integrate machine learning solutions within existing applications, enhancing user engagement metrics by **15%**.\nFacilitated code version control using **Git**, promoting collaborative development and maintaining a clean codebase.\nLeveraged **TensorFlow** and **PyTorch** for model training, achieving a model training time reduction of **40%** through efficient resource allocation.\nEnhanced big data processing and analytics using **AWS Redshift** for insight generation, resulting in faster reporting cycles by **50%**.\nParticipated in continuous performance optimization of machine learning models with tools like **Apache JMeter**, validating performance against real-world scenarios."
    }
  ],
  "skills": "**Programming Languages**\n\tPython\n\n**Backend Frameworks**\n\tFastAPI\n\tDjango\n\tFlask\n\tSpring Boot\n\n**Frontend Frameworks**\n\tAngular (1–16)\n\tReact (15–18)\n\tNext.js\n\tVue.js (2/3)\n\tBlazor\n\n**API Technologies**\n\tREST APIs\n\tgRPC APIs\n\n**Serverless and Cloud Functions**\n\tAWS Lambda\n\n**Databases**\n\tPostgreSQL\n\tMySQL\n\tMongoDB\n\tRedis\n\tRedshift\n\n**DevOps**\n\tDocker\n\tKubernetes\n\tGitHub Actions\n\tGitLab CI/CD\n\n**Cloud & Infrastructure**\n\tAWS (ECS, RDS, S3)\n\tAzure (App Services, Blob, SQL)\n\n**Other**\n\tSQL\n\tMLOps\n\tscikit-learn\n\tTensorFlow\n\tPyTorch\n\tData ETL pipelines\n\tSoftware engineering best practices\n\tVersion control\n\tTesting\n\tContainerization\n\tCollaboration\n\tCommunication"
}