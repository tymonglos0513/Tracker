{
  "name": "Tomasz Lee",
  "role_name": "Senior Solutions Architect",
  "email": "tomasz.lee8@outlook.com",
  "phone": "+48 732 145 942",
  "address": "Warsaw, Poland",
  "linkedin": "https://www.linkedin.com/in/tomasz-lee-b9a25a391/",
  "profile_summary": "Results-driven Senior Solutions Architect with 9+ years of reputable experience in High Performance Computing (HPC) and AI-driven solutions. Proficient in leveraging advanced technologies such as **C**, **C++**, **Python**, and frameworks including **PyTorch**, **Megatron-LM**, and **NeMo** to design innovative training pipelines. Demonstrated expertise in optimizing performance using **CUDA**, **NVIDIA platforms**, and the integration of **NCCL** and **MPI** for distributed computing. Experienced with **SLURM** for workload management and adept at utilizing **Nsight Systems** and **Nsight Compute** for performance analysis. Solid background in parallel filesystems and high-speed interconnects to enhance computational efficiency. Committed to developing scalable architectures and collaborating across multidisciplinary teams to successfully deliver complex projects.",
  "education": [
    {
      "degree": "Master of Computer Science",
      "category": "",
      "from_year": "Apr 2012",
      "to_year": "Oct 2014",
      "location": "",
      "university": "National University of Singapore"
    },
    {
      "degree": "Bachelor of Computer Science",
      "category": "",
      "from_year": "Apr 2008",
      "to_year": "Mar 2012",
      "location": "",
      "university": "National University of Singapore"
    }
  ],
  "experience": [
    {
      "role": "Senior Solutions Architect",
      "company": "CD Projekt RED",
      "from_date": "May 2022",
      "to_date": "Oct 2025",
      "location": "Warsaw, Poland",
      "responsibilities": "• Led the architecture and design of high-performance computing solutions leveraging **CUDA** and **NVIDIA platforms**, enhancing processing efficiency for AI workloads.\n• Developed robust training pipelines using **PyTorch** and **Megatron-LM**, improving training speed by **30%** and scalability of AI models.\n• Implemented efficient parallel computing strategies with **MPI** and optimized workloads on **SLURM**, achieving a reduction in training time by **25%**.\n• Utilized **Nsight Systems** and **Nsight Compute** for performance analysis and optimization, identifying bottlenecks and enhancing application throughput by **40%**.\n• Integrated **Dynamo** and **RedHat Inference Server** for seamless deployment of inference models, ensuring high availability and rapid response times.\n• Developed and managed parallel filesystems and high-speed interconnects, leading to improved data transfer rates of **50%** in cluster environments.\n• Created interactive data visualizations for AI model performance using **D3.js** and **Three.js**, enhancing data presentation for stakeholders.\n• Collaborated with cross-functional teams to implement advanced security protocols including JWT-based authentication in solution architectures.\n• Provided ongoing support and optimization recommendations, ensuring alignment with business objectives and technological advancements."
    },
    {
      "role": "Full Stack Developer",
      "company": "Sea Group",
      "from_date": "Mar 2018",
      "to_date": "Apr 2022",
      "location": "Shopee, Singapore",
      "responsibilities": "Designed and developed high-performance computing solutions utilizing **CUDA** and **NVIDIA platforms** to achieve optimized GPU resource utilization, resulting in a **30%** reduction in processing time.\nImplemented parallel computing strategies using **MPI** and **SLURM** to enhance throughput for intensive data processing tasks.\nIntegrated deep learning frameworks such as **PyTorch** and **Megatron-LM** into training pipelines, significantly improving AI model training efficiency by **40%**.\nDeveloped and optimized C and C++ algorithms tailored for GPU execution, leading to **25%** faster computation for complex tasks.\nLeveraged **TensorRT-LLM** for model inference acceleration, enhancing real-time predictions and performance metrics.\nCreated custom solutions using **Dynamo** for seamless data handling and management across various high-speed interconnects.\nCollaborated with cross-functional teams to define requirements for advanced GPU-based solutions, ensuring alignment with business goals.\nUtilized tools like **Nsight Systems** and **Nsight Compute** for performance tuning and monitoring, increasing application efficiency and reliability.\nFacilitated the integration of **RedHat Inference Server** to deploy AI applications, achieving scalability across microservices.\nProvided mentorship on best practices for development in **Python** for data processing, leading to a more agile and knowledgeable team."
    },
    {
      "role": "Software Developer",
      "company": "Grab Holdings Inc",
      "from_date": "Jan 2015",
      "to_date": "Feb 2018",
      "location": "Singapore",
      "responsibilities": "• Developed high-performance computing solutions leveraging **C++** and **Python**, resulting in processing speed improvements of up to **50%**.\n• Implemented AI training pipelines using **PyTorch** and **CUDA**, successfully reducing training times by **30%**.\n• Designed and optimized distributed computing frameworks utilizing **MPI** and **NVIDIA platforms**, achieving enhanced resource utilization.\n• Managed data parallelism for machine learning tasks employing **Nsight Systems** and **Nsight Compute**, improving debugging efficiency by **25%**.\n• Coordinated with cross-functional teams to integrate **Dynamo** and **TensorRT-LLM** for real-time inference, increasing operational throughput.\n• Developed and maintained scripts for job scheduling using **SLURM**, enhancing cluster resource allocation efficiency.\n• Led initiatives to optimize workflows on **RedHat Inference Server**, accelerating delivery of AI solutions.\n• Provided expert guidance on implementing high-speed interconnects and parallel filesystems for data processing, improving data transfer rates.\n• Created extensive documentation and user guides for complex systems, facilitating knowledge transfer within the teams.\n• Engaged in continuous performance tuning and optimization of AI frameworks like **Megatron-LM**, resulting in improved model performance."
    }
  ],
  "skills": " **Programming Languages** \n\t C, C++, Python, JavaScript, TypeScript\n\n **Backend Frameworks** \n\t NodeJS, ExpressJS, NestJS, C#, .NET, Entity Framework, Microservices\n\n **Frontend Frameworks** \n\t HTML, CSS, ReactJS, NextJS, VueJS, NuxtJS, Angular, Material UI, Three.js, D3.js, React Native, Flutter, Chakra UI, TailwindCSS\n\n **API Technologies** \n\t RESTful API, GraphQL\n\n **Serverless and Cloud Functions** \n\t AWS, Azure\n\n **Databases** \n\t MSSQL Server, MySQL, PostgreSQL, MongoDB, DynamoDB, CosmosDB\n\n **DevOps** \n\t CI/CD pipelines\n\n **Cloud & Infrastructure** \n\t GPU, High Performance Computing, NVIDIA platforms, CUDA, SLURM, parallel filesystems, high-speed interconnects, training pipelines, RedHat Inference Server\n\n **Other** \n\t Messaging & Caching: Apache Kafka, RabbitMQ, Redis, Testing Tools: NUnit, xUnit, Selenium, Moq, Postman, Cypress, JMeter, Jest, Blockchain: Solidity, Ether.js, Web3.js, Ethereum, UX/UI Design, Git, GitHub, PyTorch, Megatron-LM, NeMo, vLLM, TensorRT-LLM, NCCL, MPI, SGLang"
}