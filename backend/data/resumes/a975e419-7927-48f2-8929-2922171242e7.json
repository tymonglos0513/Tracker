{
  "name": "Tomasz Lee",
  "role_name": "Senior Data Engineer",
  "email": "tomasz.lee8@outlook.com",
  "phone": "+48 732 145 942",
  "address": "Warsaw, Poland",
  "linkedin": "https://www.linkedin.com/in/tomasz-lee-b9a25a391/",
  "profile_summary": "Results-driven Senior Data Engineer with 9+ years of experience in leveraging advanced data architecture frameworks such as **Data Vault 2.0**, **Modern Data Warehouse**, **Data Mesh**, and **Data Fabric**. Proficient in developing data pipelines and processing strategies using **Python**, **SQL**, and **NoSQL Databases** to ensure effective data governance and optimization. Skilled in leveraging **cloud-based data platforms** for data storage and processing, alongside expertise in streaming and batch data management. Experienced with orchestration and workflow tools to streamline data operations. Strong collaborator with effective communication skills in both German and English, dedicated to delivering high-quality data solutions that meet organizational goals.",
  "education": [
    {
      "degree": "Master of Computer Science",
      "category": "",
      "from_year": "Apr 2012",
      "to_year": "Oct 2014",
      "location": "",
      "university": "National University of Singapore"
    },
    {
      "degree": "Bachelor of Computer Science",
      "category": "",
      "from_year": "Apr 2008",
      "to_year": "Mar 2012",
      "location": "",
      "university": "National University of Singapore"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "CD Projekt RED",
      "from_date": "May 2022",
      "to_date": "Oct 2025",
      "location": "Warsaw, Poland",
      "responsibilities": "Utilized **Python** and **SQL** to design and implement data processing pipelines that improved data ingestion efficiency by **30%**.\nDeveloped modern data storage solutions leveraging **NoSQL Databases** for dynamic data retrieval and compatibility, optimizing storage management.\nEngineered a **Data Vault 2.0** compliant architecture to ensure robust data governance and scalability across the data warehouse.\nImplemented **Data Mesh** principles to enable decentralized data ownership, improving data accessibility across teams by **40%**.\nOrchestrated data workflows utilizing ** orchestration tools** to automate batch and streaming data processing, leading to a **50%** reduction in manual intervention.\nDesigned and managed cloud-based data platforms on **AWS** and **Azure**, resulting in optimized resource usage and reduced costs.\nEnhanced data pipelines using **Apache Kafka** for streaming data processing, enabling real-time insights and reporting.\nCreated comprehensive documentation and communication channels in both **German** and **English** to ensure cross-team collaboration and project clarity.\nIntegrated advanced **data governance** frameworks to maintain data quality and compliance across all data initiatives.\nCollaborated with cross-functional teams to align data strategy with business objectives, enhancing decision-making capabilities."
    },
    {
      "role": "Software Engineer",
      "company": "Sea Group",
      "from_date": "Mar 2018",
      "to_date": "Apr 2022",
      "location": "Shopee, Singapore",
      "responsibilities": "Implemented **Data Vault 2.0** strategies to enhance data governance and optimize ETL processes, contributing to a **20%** improvement in data accuracy.\nDeveloped and maintained **Modern Data Warehouse** solutions to facilitate seamless data processing and accessibility across teams, leading to a **30%** reduction in data retrieval times.\nArchitected a **Data Mesh** framework to promote decentralized data ownership and improved collaboration among data teams.\nDesigned data processing workflows utilizing **Python** to automate data quality checks and transformations, increasing operational efficiency by **25%**.\nCreated robust **Data Pipeline** solutions to ingest and process both streaming and batch data from various sources, ensuring timely data availability.\nLeveraged **Cloud-based Data Platforms** for scalable storage and processing, resulting in a **40%** cost savings on infrastructure.\nUtilized **NoSQL Databases** to handle diverse and unstructured data types effectively, enhancing system flexibility.\nEmployed **Orchestration Tools** to streamline data workflows, minimizing downtime during data operations.\nEngaged in effective communication with stakeholders in both **German** and **English** to define clear requirements and align project goals.\nConducted regular code reviews and developed mentorship programs for junior developers, fostering a culture of continuous learning and improved team performance."
    },
    {
      "role": "Software Developer",
      "company": "Grab Holdings Inc",
      "from_date": "Jan 2015",
      "to_date": "Feb 2018",
      "location": "Singapore",
      "responsibilities": "Leveraged **Python** and **SQL** to design and implement a **Data Pipeline** that processed and managed streaming and batch data effectively, enhancing data accessibility by **30%**.\nDeveloped a **Modern Data Warehouse** architecture using **NoSQL Databases**, improving data retrieval times and enabling efficient data governance practices.\nImplemented data processing strategies in line with **Data Vault 2.0** and **Data Mesh** methodologies, resulting in more scalable and organized datasets.\nUtilized **Orchestration Tools** to automate workflows, reducing manual intervention and improving data pipeline reliability.\nCollaborated with cross-functional teams to ensure alignment in data governance policies across departments, fostering seamless communication in both **German** and **English**.\nCreated technical documentation to outline data frameworks and integration processes, ensuring knowledge transfer within the team and promoting adherence to coding standards.\nParticipated in agile sprint planning and daily standups, enhancing project visibility and accountability.\nSuccessfully migrated existing data storage solutions to **Cloud-based Data Platforms**, increasing storage efficiency by **25%**.\nEngaged in continuous optimization of data processing workflows, employing various orchestration and workflow tools to enhance overall system performance."
    }
  ],
  "skills": " **Programming Languages**\n\tPython, JavaScript, TypeScript\n\n**Backend Frameworks**\n\tNodeJS, ExpressJS, NestJS, C#, .NET\n\n**Frontend Frameworks**\n\tHTML, CSS, ReactJS, NextJS, VueJS, NuxtJS, Angular, Material UI, Three.js, D3.js, React Native, Flutter, Chakra UI, TailwindCSS\n\n**API Technologies**\n\tRESTful API, GraphQL\n\n**Serverless and Cloud Functions**\n\tAWS, Azure\n\n**Databases**\n\tMSSQL Server, MySQL, PostgreSQL, MongoDB, DynamoDB, CosmosDB, NoSQL Databases\n\n**Data Technologies**\n\tData Vault 2.0, Modern Data Warehouse, Data Mesh, Data Fabric, Data Pipeline, Data Processing, Cloud-based Data Platforms, Data Governance, Streaming Data, Batch Data\n\n**DevOps**\n\tCI/CD pipelines, Orchestration Tools, Workflow Tools\n\n**Messaging & Caching**\n\tApache Kafka, RabbitMQ, Redis\n\n**Other**\n\tUX/UI Design, Git, GitHub, Redux, Communication, German, English, Testing Tools: NUnit, xUnit, Selenium, Moq, Postman, Cypress, JMeter, Jest, Blockchain: Solidity, Ether.js, Web3.js, Ethereum\n",
  "apply_company": "Hays"
}