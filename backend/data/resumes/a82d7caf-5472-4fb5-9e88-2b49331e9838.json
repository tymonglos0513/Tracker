{
  "name": "Marcin Karol Kotlinski",
  "role_name": "Senior Data Engineer",
  "email": "marcinkot55@outlook.com",
  "phone": "+48 732 779 243",
  "address": "Zgorzelec, Poland",
  "linkedin": "https://www.linkedin.com/in/marcin-k-a54a89395/",
  "profile_summary": "As a skilled Senior Data Engineer with 8 years of full-stack development experience, I excel in building high-performance solutions, leveraging **Python**, **SQL**, and cloud technologies such as **Azure**. My proficiency in data engineering includes expertise in **ETL** processes, real-time data handling, and customer data platforms. I have a solid foundation in Unix scripting and data management practices, ensuring robust data integrity and security.\nI have led engineering teams to implement enterprise-grade platforms in the healthcare and financial sectors while adhering to compliance standards like HIPAA and PCI DSS. My background also includes experience with **Azure DevOps** for CI/CD automation and cloud deployment strategies. Additionally, I am well-versed in integrating AI/ML capabilities into data analysis solutions, utilizing tools like **MLflow** and **Airflow** to optimize machine learning pipelines.",
  "education": [
    {
      "degree": "Master’s Degree in Computer Science",
      "category": "",
      "from_year": "2017",
      "to_year": "2018",
      "location": "UK",
      "university": "University of Oxford"
    },
    {
      "degree": "Bachelor’s Degree in Computer Science",
      "category": "",
      "from_year": "2015",
      "to_year": "2017",
      "location": "UK",
      "university": "University of Oxford"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "EVNE Developers",
      "from_date": "Oct 2023",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "- Developed and optimized ETL processes to efficiently handle large volumes of healthcare and financial data using **Python** and **SQL**, ensuring seamless data transformation and integration.\n- Collaborated on the implementation of a Real-Time Customer Data Platform, leveraging **Adobe Experience Platform** to enhance customer experiences and data accessibility.\n- Created and maintained data pipelines in **Azure DevOps**, implementing CI/CD practices for automated deployment and monitoring of data services across various environments.\n- Designed and supported data models adhering to **XDM** standards to enable unified data representation and analytics capabilities for banking and healthcare applications.\n- Developed Unix-scripting solutions for automation in data processing tasks, enhancing system performance and operational efficiency by **25%**.\n- Worked on cloud-based solutions for data storage and processing, utilizing **Azure** services to enhance availability and scalability of data systems.\n- Ensured compliance with regulatory requirements in banking and financial domains including data governance and security, maintaining adherence to standards such as PCI DSS.\n- Collaborated with cross-functional teams to integrate data-driven insights into business strategies, improving decision-making processes by providing real-time reporting.\n- Delivered comprehensive documentation and training sessions to team members regarding best practices in data engineering and analytics.\n- Engaged in continuous learning and professional development in cutting-edge technologies pertinent to data engineering, staying updated with industry trends and developments."
    },
    {
      "role": "Software Engineer",
      "company": "Air Force",
      "from_date": "Oct 2021",
      "to_date": "Sep 2023",
      "location": "Poland",
      "responsibilities": "Developed and maintained ETL pipelines to ensure seamless data processing and integration for the financial sector, utilizing **Python**, **Apache Airflow**, and **Azure Data Factory** for both batch and real-time ingestion of financial data from internal and third-party sources.\nEngineered real-time customer data platforms to enhance user experience and insights, incorporating **SQL** for data management and analysis in performance-critical environments.\nImplemented scalable data solutions and migration processes leveraging **Adobe Experience Platform**, ensuring optimal data utilization across all banking applications and systems.\nUtilized **XDM** for data modeling and governance, facilitating enhanced data interoperability and usability across various systems, while adhering to regulations and standards in the banking industry.\nOptimized existing banking applications by employing **Unix-Scripting** for automating data workflows and improving process efficiency, leading to reduced operational costs by **20%**.\nCollaborated with cross-functional teams using **Azure DevOps** to streamline deployment processes and improve the delivery of data-driven features by **30%**.\nEnhanced analytics capabilities of transaction systems through the application of machine learning algorithms, supporting fraud detection efforts and improving incident response times by **15%**.\nProvided technical documentation and support, ensuring knowledge transfer and upskilling of team members in banking technology stacks and cloud solutions."
    },
    {
      "role": "Software Engineer",
      "company": "DeepInspire",
      "from_date": "Sep 2018",
      "to_date": "Aug 2021",
      "location": "UK",
      "responsibilities": "Utilized **Python** for data transformation and ETL processes, optimizing workflows for the **Adobe Experience Platform**, ensuring efficient handling of real-time customer data.\nDeveloped and maintained robust **Unix-Scripting** solutions for data management and automation within cloud environments, enhancing productivity and operational efficiency.\nEngineered SQL queries and database structures for seamless integration with **Azure DevOps**, streamlining data pipelines and enabling continuous integration within data engineering projects.\nCollaborated across teams to establish a **Real-Time Customer Data Platform** utilizing XDM frameworks, enhancing customer insights with immediate data availability.\nDesigned automated data ingestion processes that merged banking data sources, resulting in a **30%** performance increase and reduced latency in reporting.\nLeveraged agile methodologies in a cloud-based infrastructure on **Azure**, facilitating **5** major data projects in the previous fiscal year with improved delivery timelines.\nContributed to documentation and data governance to ensure compliance with data management best practices and standards across the organization, enhancing adherence to GDPR regulations.\nCommunicated complex data findings in clear English to various stakeholders, ensuring alignment and understanding of project status and deliverables."
    }
  ],
  "skills": " **Programming Languages:**\n\tPython, SQL, Unix-Scripting\n\n**Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n**Frontend Frameworks:**\n\tJavaScript/TypeScript (React, Vue, Angular)\n\n**API Technologies:**\n\tN/A\n\n**Serverless and Cloud Functions:**\n\tAWS (ECS, Lambda), Azure (App Services)\n\n**Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare), MongoDB (Gaming), Redis\n\n**DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, Terraform, Ansible, Helm, Docker Compose, Azure DevOps\n\n**Cloud & Infrastructure:**\n\tAWS (RDS, S3), Azure (Blob, SQL)\n\n**Other:**\n\tAdobe Experience Platform, ETL, Real-Time Customer Data Platform, XDM, Banking, MLflow, Airflow, Kubeflow, Keycloak (OIDC, RBAC), JWT, OAuth2, Let’s Encrypt, Nginx, Certbot",
  "apply_company": "Logicalis Spain"
}