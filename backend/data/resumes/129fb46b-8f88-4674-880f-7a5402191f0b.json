{
  "name": "DANIEL HE",
  "role_name": "Senior Data Engineer",
  "email": "daniel.he8@outlook.com ",
  "phone": "+48 730 743 032",
  "address": "Rzesz√≥w, Poland",
  "linkedin": "https://www.linkedin.com/in/daniel-he-a5a536397/",
  "profile_summary": "Results-driven Senior Data Engineer with extensive expertise in **Python**, **pandas**, **SQL**, **Apache NiFi**, **Kafka**, and **PySpark**. Skilled in designing and implementing ETL and ELT processes, ensuring data quality through effective data modeling, and optimizing data lakes and warehouses. Proven track record in leveraging **Apache Hudi** and **Ozone** to enhance data storage and access. Complementary background in deployment and orchestration using **Docker** and **Kubernetes**. With a history of working in diverse sectors, including healthcare, eCommerce, and finance, I excel in delivering high-quality, scalable data solutions that drive strategic decision-making and improve operational efficiency.",
  "education": [
    {
      "degree": "Bachelor's degree in Computer Science",
      "category": "Computer Science",
      "from_year": "2012",
      "to_year": "2016",
      "location": "Beijing, China ",
      "university": "Tsinghua University "
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "Britenet",
      "from_date": "Feb 2023 ",
      "to_date": "Present",
      "location": "Warsaw, Poland",
      "responsibilities": "Utilized **Python** and **pandas** to conduct data quality assessments, enhancing data reliability by 30% and improving ETL processes for large datasets.\nImplemented **SQL** for data modeling and querying, resulting in a 40% reduction in data retrieval times across multiple project deliverables.\nDesigned and optimized data lakes and warehouses, leveraging **Apache Hudi** to ensure high performance and consistency across vast data sources.\nStreamlined data processing workflows using **Apache NiFi** and **Kafka**, managing data streams efficiently and achieving 99% data ingestion reliability.\nDeveloped data transformation processes with **PySpark**, improving processing speed by **3x** for large-scale datasets, while ensuring compliance with data governance policies.\nContainerized applications utilizing **Docker** for consistent development and deployment environments, facilitating seamless collaboration across teams.\nOrchestrated service deployment on **Kubernetes**, ensuring high availability and scalability for data applications with **99.9% uptime**.\nImplemented data pipeline monitoring strategies to maintain data integrity, leveraging ELT techniques for real-time data processing and quality checks."
    },
    {
      "role": "Software Engineer",
      "company": "Alibaba Group",
      "from_date": "Oct 2020 ",
      "to_date": "Dec 2022",
      "location": "Hangzhou, China",
      "responsibilities": "Utilized **Python** and **pandas** for data manipulation and analysis, enhancing data processing efficiency by 30%.\nImplemented **SQL** for data querying and management, optimizing database performance which led to a 15% reduction in query execution time.\nDesigned and developed ETL processes using **Apache NiFi** and **Kafka**, improving data ingestion rates by 40% in our pipelines.\nEnsured data quality and integrity by implementing comprehensive testing strategies in our **ETL/ELT** workflows, leading to a 99% accuracy in data deliveries.\nCreated and maintained data models for data lakes and warehouses using **data modeling** techniques, successfully supporting analytics for over 100+ users.\nLeveraged **Docker** and **Kubernetes** for containerization and orchestration, streamlining the deployment process and achieving a deployment frequency increase by 50%."
    },
    {
      "role": "Software Engineer ",
      "company": "Huawei Technologies Co., Ltd",
      "from_date": "May 2016 ",
      "to_date": "Sep 2020",
      "location": "Shenzhen, China ",
      "responsibilities": "Utilized **Python** with **pandas** for data manipulation and analysis, enhancing data processing efficiency by 25%.\nDesigned and implemented **ETL** processes using **Apache NiFi** and **Kafka**, improving data ingestion speed by 50%.\nManaged **SQL** databases to store, query, and maintain data integrity, achieving data retrieval times under 2 seconds.\nOptimized data workflows to ensure high **data quality** standards across multiple pipelines.\nDeveloped and maintained **data lakes** and **data warehouses** using **Apache Hudi** and **Ozone**, facilitating efficient data storage and retrieval for diverse analytical needs.\nLeveraged **Docker** and **Kubernetes** for deployment and scaling of applications, reducing deployment time by 40%."
    }
  ],
  "skills": "Programming Languages:\n\t**Python, SQL, Java, JavaScript, Go, Swift, Kotlin**\n\nBackend Frameworks:\n\t**Spring Boot, Spring Security, Hibernate, Node.js, Express.js, JPA, Kafka, RabbitMQ**\n\nFrontend Frameworks:\n\t**React, Vue.js, Angular, Pixi.js, Redux, Next.js, React Router, Material-UI, Ant Design, D3.js, Webpack, Babel, Jest**\n\nAPI Technologies:\n\t**RESTful API design**\n\nServerless and Cloud Functions:\n\t**AWS Lambda**\n\nDatabases:\n\t**MySQL, PostgreSQL, Redis, MongoDB, data modeling, data quality, data lakes, data warehouses**\n\nDevOps:\n\t**Docker, Kubernetes, Jenkins, GitHub Actions, Terraform, AWS CodePipeline**\n\nCloud & Infrastructure:\n\t**AWS (EKS, RDS, CloudFront, S3), API Gateway, Git, CloudWatch, ELK Stack**\n\nOther:\n\t**Microservices, CI/CD, Infrastructure as Code (IaC), Data structures and algorithms, Agile/Scrum methodologies, pandas, Apache NiFi, PySpark, ETL, ELT, Apache Hudi, Ozone**",
  "apply_company": "Zabel Global"
}