{
  "name": "Patryk Zaslawski",
  "role_name": "Senior Data Engineer",
  "email": "patrykzas0428@outlook.com",
  "phone": "+48669862402",
  "address": "Gdanski, Poland",
  "linkedin": "https://www.linkedin.com/in/patryk-z-9b9455391/",
  "profile_summary": "As a Senior Data Engineer with 8+ years of experience, I specialize in building and optimizing data pipelines utilizing **Azure Synapse Analytics**, **Azure Data Lake Storage Gen2**, **PySpark**, **T-SQL**, and ETL/ELT methodologies to drive data-driven decision making. My expertise in developing **RESTful APIs** and leveraging **Azure Functions**, **Logic Apps**, and **Databricks** enhances seamless data integration and processing capabilities. I am well-versed in implementing security best practices using **Azure RBAC**, **Managed Identities**, and **Key Vault** to ensure data integrity and compliance. Additionally, my proficiency in **Azure Monitor** and **Log Analytics** aids in monitoring and optimizing system performance. My strong foundation in **Python** and commitment to leveraging technology for effective solutions is complemented by my experience in the e-commerce and healthcare sectors, where I have successfully designed and delivered scalable and efficient applications aligned with business needs.",
  "education": [
    {
      "degree": "Bachelor’s Degree",
      "category": "Computer Science",
      "from_year": "2014",
      "to_year": "2017",
      "location": "United Kingdom",
      "university": "The University of Manchester"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "Binary Studio",
      "from_date": "Aug 2023",
      "to_date": "Present",
      "location": "United Kingdom (Remote)",
      "responsibilities": "- Developed and optimized ETL/ELT processes leveraging **Azure Synapse Analytics**, **Azure Data Lake Storage Gen2**, and **Databricks** to efficiently manage large-scale healthcare data sets.\n- Created RESTful APIs in **Python** to enable seamless data integration and automation through **Azure Functions** and **Logic Apps**, enhancing workflow efficiency.\n- Implemented security best practices using **Azure Key Vault** and **Managed Identities** to safeguard sensitive data and ensure compliance with regulations.\n- Monitored and managed resources using **Azure Monitor** and **Log Analytics**, ensuring high availability and performance for data engineering solutions.\n- Utilized **PySpark** for big data processing and transformation tasks, collaborating with teams to optimize resource utilization and processing times.\n- Designed automated data pipelines focused on real-time analytics, integrating with **Azure Data Lake Storage Gen2** and other Azure services for effective data management.\n- Optimized data querying and reporting using **T-SQL**, ensuring robust performance across healthcare analytics systems with adherence to norms.\n- Led the implementation of Azure RBAC for secure access controls, streamlining permissions across multiple data engineering environments.\n- Streamlined workflows by integrating various **ServiceNow APIs** into data operations, improving incident management efficiencies.\n- Successfully mentored junior data engineers in **Python**, **ETL**, and cloud technologies, fostering skills in agile and DevOps practices, while promoting a collaborative team culture.\n- Ensured high-quality delivery of data solutions through automated testing and CI/CD practices, enhancing reliability and reducing deployment times."
    },
    {
      "role": "Software Engineer",
      "company": "Ardigen",
      "from_date": "Mar 2020",
      "to_date": "Aug 2023",
      "location": "Poland",
      "responsibilities": "Utilized **Azure Synapse Analytics** and **Azure Data Lake Storage Gen2** to architect and manage data pipelines, enabling efficient **ETL** processes while enhancing data analysis capabilities by **40%**.\nDeveloped and maintained **Python** scripts leveraging **PySpark** for data transformation and processing, achieving a **25%** reduction in data processing time across large datasets.\nDesigned and implemented secure **RESTful APIs** to facilitate seamless integration with data sources, ensuring optimal communication between ingestion processes and analytical systems.\nManaged and optimized data storage solutions by implementing **T-SQL** queries and leveraging **Databricks**, significantly improving data retrieval speed.\nBuilt automated workflows utilizing **Azure Functions** and **Logic Apps** for real-time data processing, increasing operational efficiency by **30%**.\nEmployed **Azure Monitor** and **Log Analytics** to set up alerting and monitoring for data pipelines, achieving a **99.9%** uptime for services while streamlining incident response.\nImplemented **Azure RBAC** and **Managed Identities** for secure access management to sensitive data, ensuring compliance with governance policies.\nWorked on integration with **ServiceNow APIs** to automate ticketing processes for data engineering tasks, leading to quicker resolution of operational issues.\nDeveloped and executed unit tests to validate ETL workflows, ensuring data integrity and accuracy in analytics processes, reducing errors by **20%**.\nCollaborated in cross-functional teams to integrate various data processing systems into a cohesive architecture, successfully enhancing data flow and reducing bottlenecks.\nMaintained comprehensive documentation of data engineering processes to support knowledge sharing and onboarding, driving continuous improvement within the team.\nProficiently communicated complex technical concepts in **Fluent English**, facilitating effective collaboration with stakeholders across business and technical domains."
    },
    {
      "role": "Software Engineer",
      "company": "Altum Software",
      "from_date": "Oct 2017",
      "to_date": "Feb 2020",
      "location": "United Kingdom",
      "responsibilities": "Developed and optimized data pipelines in **Azure Synapse Analytics** and **Databricks** using **PySpark** and **T-SQL**, improving data processing speeds by **40%** and enhancing ETL/ELT workflows.\nDesigned and implemented RESTful APIs with **Python** to facilitate data access and transformation between various services, ensuring efficient data flows and real-time analytics for users.\nLeveraged **Azure Data Lake Storage Gen2** for effective data storage and retrieval, achieving a reduction in data retrieval time by **30%**.\nExecuted complex data manipulation and transformation tasks using **ETL** and **ELT** strategies with a focus on scalability and performance, processing **over 1 million** records daily.\nIntegrated **Azure Functions** and **Logic Apps** for automating data workflows, achieving significant improvements in operational efficiency and reducing manual intervention.\nImplemented security best practices by using **Azure RBAC**, **Managed Identities**, and **Key Vault** to safeguard sensitive data and ensure compliance with organizational policies.\nUtilized **Azure Monitor** and **Log Analytics** for system performance tracking and error detection, resulting in improved visibility and quicker resolution of system issues.\nCollaborated with cross-functional teams to develop comprehensive data solutions that streamlined business processes and enhanced data-driven decision-making.\nEnsured data quality and reliability by conducting thorough testing and validation, leading to a **20%** decrease in data anomalies.\nProvided technical guidance and support for the integration of **ServiceNow APIs** with existing systems to enhance service delivery and incident management.\nCommunicated effectively in **Fluent English** with stakeholders to gather requirements and present data solutions, ensuring alignment with business objectives."
    }
  ],
  "skills": "**Programming Languages:**\n\tPython, T-SQL, PySpark\n\n**Backend Frameworks:**\n\tFastAPI, Django, Flask, Spring Boot, Azure Functions\n\n**Frontend Frameworks:**\n\tAngular (1–16), React (15–18), Next.js, Vue.js (2/3), Blazor\n\n**API Technologies:**\n\tREST & gRPC APIs, RESTful API, ServiceNow APIs\n\n**Serverless and Cloud Functions:**\n\tAWS (ECS, Lambda, RDS, S3), Azure Functions, Logic Apps\n\n**Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare), MongoDB (Gaming), Redis, Azure Data Lake Storage Gen2\n\n**DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, Azure Monitor, Log Analytics\n\n**Cloud & Infrastructure:**\n\tAWS, Azure (App Services, Blob, SQL), Azure RBAC, Key Vault, Managed Identities\n\n**Other:**\n\tETL, ELT, Fluent English, Keycloak (OIDC, RBAC), JWT, OAuth2, Let’s Encrypt, Nginx, Certbot, SQLAlchemy, Pydantic, Celery, Databricks",
  "apply_company": "Top Client"
}