{
  "name": "Damian Franciszek Pospiech",
  "role_name": "Senior Data Engineer",
  "email": "damianpos127@outlook.com",
  "phone": "+48 732 143 608",
  "address": "Mikolow, Poland",
  "linkedin": "https://www.linkedin.com/in/damian-pospiech-261821397/",
  "profile_summary": "Senior Data Engineer with 13+ years of experience specializing in data visualization, ETL processes, and robust data storytelling. Proficient in SQL, **Airflow**, and **dbt**, with a strong analytical mindset to deliver insights through tools such as **Tableau**, **PowerBI**, and **Looker**. Adept at utilizing **Amplitude** to enhance data-driven decision-making and experienced in integrating data systems with platforms like **Salesforce** and **Marketo**.\n\nPossess hands-on experience as a Full Stack Developer with a versatile tech stack encompassing **JavaScript/TypeScript**, **Python**, **Flutter**, **React**, **Next.js**, **Vue**, **Node.js**, **FastAPI**, and **Django**. Proven track record in creating AI/ML-driven solutions that support automation and predictive analytics. Skilled in deploying cloud-native applications using **AWS** and **Azure**, alongside implementing microservices and CI/CD practices.\n\nCommitted to compliance-driven development, familiar with industry standards such as HIPAA, FHIR, PCI DSS, and SOC 2. Strong foundation in MLOps, including model training and orchestration using **MLflow**, **Airflow**, and **Kubeflow**.",
  "education": [
    {
      "degree": "Bachelor's degree in Computer Science",
      "category": "Computer Science",
      "from_year": "2007",
      "to_year": "2012",
      "location": "UK",
      "university": "University of Cambridge"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "Codebridge",
      "from_date": "Apr 2021",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "Utilized **SQL** to perform complex data extraction and transformation tasks as part of robust ETL processes, ensuring accurate and timely data delivery across different environments.\nDesigned and implemented data visualization solutions using **Power BI**, **Tableau**, and **Looker**, enabling clear data storytelling and real-time insights for stakeholders, leading to a **30%** increase in actionable business intelligence.\nDeveloped and orchestrated data workflows with **Airflow**, automating repetitive tasks and improving data pipeline efficiency by **40%**.\nCreated models and reports using **dbt** to support business analytics, optimizing data transformation processes to ensure high-quality data outputs.\nEnhanced data accessibility through integration with third-party tools like **Salesforce**, **Marketo**, and **Amplitude**, providing a holistic view of customer interactions and marketing effectiveness.\nConducted thorough data analysis and reporting, leveraging analytical skills to uncover patterns and trends, and effectively communicated the results to various teams, leading to informed decision-making.\nCollaborated across departments to establish a seamless communication flow, ensuring that insights from data analysis were understood and actionable for project advancement.\nExecuted advanced data storytelling techniques that improved stakeholder engagement with data-driven narratives, contributing to a **25%** increase in project buy-in.\nRegularly optimized and maintained existing data systems, focusing on reliability and performance, ensuring that data queries executed within **2 seconds** for standard reports.\nImplemented comprehensive testing strategies for data processing workflows ensuring accuracy and reliability of data delivery to end-users."
    },
    {
      "role": "Software Engineer",
      "company": "Grupa Azoty",
      "from_date": "Oct 2015",
      "to_date": "Mar 2021",
      "location": "Poland",
      "responsibilities": "Utilized **SQL** to optimize data queries and enhance the performance of data retrieval processes, resulting in a **30%** reduction in query execution time.\nDesigned and implemented **ETL** pipelines using **Python**, **Apache Airflow**, and **Azure Data Factory**, streamlining the ingestion of financial data from multiple internal and third-party sources and supporting both batch and real-time processing.\nCreated interactive dashboards using **Power BI** and **Looker**, enabling data visualization and storytelling through analytics, which improved stakeholder communication and decision-making speed by **25%**.\nDeveloped data transformation workflows using **dbt** to ensure data accuracy and consistency across different reporting layers, facilitating easy access to relevant metrics.\nLeveraged **Airflow** to orchestrate complex data workflows, improving operational efficiency by **40%** and ensuring timely delivery of data to analysts and stakeholders.\nCollaborated with cross-functional teams to effectively communicate data insights powered by **Tableau** and **Amplitude**, enhancing analytical skills and supporting innovative decision-making processes.\nIncorporated data visualization best practices into all dashboards and reports, ensuring clarity and effectiveness in data storytelling for both technical and non-technical audiences."
    },
    {
      "role": "Software Engineer",
      "company": "GoodCore",
      "from_date": "Jan 2012",
      "to_date": "Sep 2015",
      "location": "UK",
      "responsibilities": "Utilized **SQL** to design and optimize complex queries for analyzing large datasets, enhancing data retrieval efficiency and improving report generation times by **30%**.\nImplemented robust ETL processes utilizing **Airflow** to streamline data pipelines, ensuring data integrity and timely availability for business intelligence tools, reducing processing time by **25%**.\nLeveraged **dbt** for transforming raw data into clean, analyzable formats, resulting in simplified data models and improved collaboration across teams.\nCreated interactive and visually compelling dashboards using **PowerBI**, **Tableau**, and **Looker**, elevating data storytelling capabilities and enabling stakeholders to make data-driven decisions with increased clarity.\nIntegrated data from **Salesforce** and **Marketo** into central data repositories, optimizing customer insights and marketing effectiveness through advanced analytics.\nAnalyzed user engagement and behavior data through **Amplitude**, resulting in actionable insights that increased user retention by **15%** through targeted marketing strategies.\nPresented complex analytical results and visualizations to non-technical stakeholders, improving communication and fostering a data-driven culture across departments.\nCollaborated on cross-functional teams to enhance the data visualization process, defining key performance indicators (KPIs) and metrics that aligned with business goals.\nExecuted data governance practices to ensure compliance with GDPR, enhancing the security and privacy of corporate data assets across the organization."
    }
  ],
  "skills": " **Programming Languages:**\n\tPython: FastAPI, Flask, Django\n\tJavaScript/TypeScript: React, Vue, Angular\n\n **Backend Frameworks:**\n\n **Frontend Frameworks:**\n\n **API Technologies:**\n\n **Serverless and Cloud Functions:**\n\tAWS: ECS, Lambda, RDS, S3\n\tAzure: App Services, Blob Storage, SQL Database\n\n **Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare)\n\tMongoDB (Gaming), Redis\n\tSQL\n\n **DevOps:**\n\tDocker, Kubernetes\n\tGitHub Actions, GitLab CI/CD\n\tTerraform, Ansible, Helm, Docker Compose\n\n **Cloud & Infrastructure:**\n\n **Other:**\n\tMLflow, Airflow, Kubeflow\n\tPowerBI\n\tETL\n\tdbt\n\tSalesforce\n\tMarketo\n\tAmplitude\n\tLooker\n\tTableau\n\tdata visualization\n\tdata storytelling\n\tcommunication\n\tanalytical skills\n\tKeycloak (OIDC, RBAC), OAuth2, JWT\n\tNginx, Letâ€™s Encrypt, Certbot",
  "apply_company": "Autodesk"
}