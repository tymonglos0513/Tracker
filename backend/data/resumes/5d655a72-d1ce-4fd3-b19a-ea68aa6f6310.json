{
  "name": "Tomasz Lee",
  "role_name": "Senior Data Engineer",
  "email": "tomasz.lee8@outlook.com",
  "phone": "+48 732 145 942",
  "address": "Warsaw, Poland",
  "linkedin": "https://www.linkedin.com/in/tomasz-lee-b9a25a391/",
  "profile_summary": "Results-driven Senior Data Engineer with 9+ years of extensive experience in SQL, **PostgreSQL**, **ClickHouse**, and **Snowflake**. Proficient in ETL and ELT processes, leveraging **Apache Airflow** for orchestration and using **dbt** and **Airbyte** for data transformation and integration. Demonstrated expertise in building efficient data pipelines, developing data lakehouse solutions, and performing data modeling and schema design. Strong problem-solving skills complemented by a meticulous attention to detail. Additionally, experienced in **.NET Full Stack Development**, microservices architecture, and utilizing tools such as **Apache Kafka**, **RabbitMQ**, and **Redis**. Proven ability to lead cross-functional teams and deliver high-quality data solutions that enhance decision-making processes.",
  "education": [
    {
      "degree": "Master of Computer Science",
      "category": "",
      "from_year": "Apr 2012",
      "to_year": "Oct 2014",
      "location": "",
      "university": "National University of Singapore"
    },
    {
      "degree": "Bachelor of Computer Science",
      "category": "",
      "from_year": "Apr 2008",
      "to_year": "Mar 2012",
      "location": "",
      "university": "National University of Singapore"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "CD Projekt RED",
      "from_date": "May 2022",
      "to_date": "Oct 2025",
      "location": "Warsaw, Poland",
      "responsibilities": "Designed and optimized data models using **PostgreSQL** and **ClickHouse** to enhance data accessibility and performance for reporting.\nSpearheaded the development of ETL and ELT processes leveraging **Apache Airflow** and **dbt**, improving data ingestion efficiency by **50%**.\nDeveloped and maintained data pipelines, ensuring data integrity and quality across **data lakehouse** architecture, resulting in data retrieval times reducing by **30%**.\nImplemented data visualization solutions utilizing **Power BI** and **Looker**, contributing to a **40%** increase in data-driven decision-making across the organization.\nLed schema design initiatives, ensuring alignment with business requirements, achieving an **85%** reduction in data redundancy.\nCollaborated with cross-functional teams to implement comprehensive data governance policies, enhancing data security and compliance.\nOptimized data processing workflows, demonstrating strong problem-solving capabilities while maintaining high attention to detail in analytics.\nWorked on integrating **Airbyte** for streamlined data extraction from various sources, allowing real-time data updates while reducing loading times by **25%**.\n"
    },
    {
      "role": "Software Engineer",
      "company": "Sea Group",
      "from_date": "Mar 2018",
      "to_date": "Apr 2022",
      "location": "Shopee, Singapore",
      "responsibilities": "Utilized **PostgreSQL** and **SQL** to design and optimize data storage solutions, improving query performance by **30%**.\nImplemented **ETL** processes with **Apache Airflow** to facilitate data movement and transformation, ensuring a reliable data pipeline.\nDeveloped data models and schema designs for a robust data lakehouse architecture, allowing for seamless data integration and analysis.\nEmployed **dbt** to perform data transformation and manage version control in data workflow, enhancing data accuracy.\nBuilt interactive dashboards using **Power BI** and **Looker** for data visualization, increasing stakeholder insights by **40%**.\nLed migration efforts to **ClickHouse** and **Snowflake** for high-performance data analytics, achieving a **20%** reduction in query time.\nDrove projects focusing on problem-solving, attention to detail while mentoring junior data engineers to elevate team capabilities.\nCollaborated with cross-functional teams to gather requirements and create effective data solutions, ensuring alignment with business objectives.\nConducted thorough documentation of data processes and architecture for future reference and knowledge transfer."
    },
    {
      "role": "Software Developer",
      "company": "Grab Holdings Inc",
      "from_date": "Jan 2015",
      "to_date": "Feb 2018",
      "location": "Singapore",
      "responsibilities": "Designed and implemented robust **ETL** and **ELT** processes to efficiently manage and transform data from various sources including **PostgreSQL**, **ClickHouse**, and **Snowflake**.\nDeveloped data pipelines using **Apache Airflow** to automate workflows, enhancing data availability and reliability.\nExecuted data modeling and schema design strategies to optimize data structures and improve query performance, leading to a **30%** reduction in data retrieval times.\nImplemented **dbt** for data transformation, ensuring consistent and reliable outputs across analysis tools such as **Power BI** and **Looker**.\nCollaborated with cross-functional teams to design a data lakehouse architecture, consolidating data sources for improved analytics capabilities.\nConducted thorough testing and validation of data flows, applying strong problem-solving skills to identify and rectify issues efficiently.\nIntegrated **Airbyte** for seamless data ingestion from third-party systems to streamline the data pipeline process.\nMaintained attention to detail through rigorous documentation practices and technical guides to facilitate knowledge transfer among data teams.\nParticipated in agile project ceremonies, including daily stand-ups, to ensure alignment with team goals and enhancements to the development process.\nAnalyzed performance metrics of existing data processes, making iterative improvements that resulted in enhanced efficiency across data operations."
    }
  ],
  "skills": " **Programming Languages**\n\tPython, JavaScript, TypeScript, C#, Solidity\n\n**Backend Frameworks**\n\tNodeJS, ExpressJS, NestJS, .NET, Entity Framework, Microservices\n\n**Frontend Frameworks**\n\tReactJS, NextJS, VueJS, NuxtJS, Angular, Material UI, Three.js, D3.js, React Native, Flutter, Chakra UI, TailwindCSS\n\n**API Technologies**\n\tRESTful API, GraphQL\n\n**Serverless and Cloud Functions**\n\tAWS, Azure\n\n**Databases**\n\tMSSQL Server, MySQL, PostgreSQL, MongoDB, DynamoDB, CosmosDB, SQL, ClickHouse, Snowflake\n\n**DevOps**\n\tCI/CD pipelines\n\n**Cloud & Infrastructure**\n\tApache Airflow, ETL, ELT, dbt, Airbyte\n\n**Other**\n\tUX/UI Design, Git, GitHub, Blockchain, problem-solving, attention to detail, data pipeline, data lakehouse, data modeling, schema design, Power BI, Looker",
  "apply_company": "Corsearch"
}