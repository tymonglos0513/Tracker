{
  "name": "Patryk Zaslawski",
  "role_name": "Freelancer MLOps Engineer",
  "email": "patrykzas0428@outlook.com",
  "phone": "+48669862402",
  "address": "Gdanski, Poland",
  "linkedin": "https://www.linkedin.com/in/patryk-zaslawski-6b04a8397/",
  "profile_summary": "As a results-driven Freelancer MLOps Engineer with 8+ years of experience, I specialize in Python development and impactful Machine Learning solutions. Proficient in **Python**, I leverage frameworks like **FastAPI** and **Flask** to build scalable applications. Skilled in **Docker** and **Kubernetes**, I ensure smooth deployment and management of containerized applications in cloud environments including **AWS**, **GCP**, and **Azure**. My expertise includes implementing CI/CD pipelines using **Git**, and I have hands-on experience with data orchestration tools such as **Prefect** and **Airflow**. Furthermore, I possess a solid understanding of **Distributed Computing** principles. My background encompasses creating high-performance applications tailored for diverse sectors such as e-commerce and healthcare, along with a commitment to optimizing workflows and enhancing system performance.",
  "education": [
    {
      "degree": "Bachelor’s Degree",
      "category": "Computer Science",
      "from_year": "2014",
      "to_year": "2017",
      "location": "United Kingdom",
      "university": "The University of Manchester"
    }
  ],
  "experience": [
    {
      "role": "Freelancer MLOps Engineer",
      "company": "Binary Studio",
      "from_date": "Aug 2023",
      "to_date": "Present",
      "location": "United Kingdom (Remote)",
      "responsibilities": "Utilized **Python** to develop and deploy machine learning models, streamlining data processing and analysis for healthcare applications.\nImplemented CI/CD pipelines using **Docker** and **Kubernetes** for efficient deployment of ML models and microservices, ensuring 99% uptime.\nAutomated data workflows with **Airflow** to support batch and real-time processing, enabling data ingestion from various healthcare sources with an efficiency gain of 30%.\nEngineered a cloud-native architecture on **AWS** and **Azure** to enhance scalability and performance of ML workloads, achieving a 25% reduction in latency for data retrieval.\nCollaborated with cross-functional teams to integrate ML models into existing applications using **Distributed Computing** strategies, enhancing overall system responsiveness.\nConfigured **Git** for version control to facilitate collaboration across teams, maintaining a clean repository and streamlining the development process for multiple projects.\nAdopted **Prefect** to monitor and manage data workflows efficiently, improving task reliability and reducing the time spent on maintenance by 40%.\nGuided implementation of **Machine Learning** frameworks like **PyTorch** for advanced analytical capabilities, leading to the successful launch of predictive models that improved patient engagement.\nConducted training sessions for junior engineers on using **Kubernetes**, **Docker**, and cloud services, promoting best practices in deployment and MLOps automation.\nDeveloped comprehensive documentation for ML processes and systems, aiding in knowledge transfer and facilitating smoother project handovers."
    },
    {
      "role": "Software Engineer",
      "company": "Ardigen",
      "from_date": "Mar 2020",
      "to_date": "Aug 2023",
      "location": "Poland",
      "responsibilities": "Developed and maintained scalable **Python** microservices for MLOps implementation, enhancing deployment efficiency and performance of machine learning models on **AWS**, **GCP**, and **Azure**.\nUtilized **Docker** and **Kubernetes** to orchestrate containerized applications, achieving a **95%** reduction in deployment times and improved scalability across the infrastructure.\nIntegrated machine learning workflows with tools like **Prefect** and **Airflow**, optimizing data pipelines while ensuring reliability and monitoring for model performance.\nImplemented CI/CD pipelines using **Git** and various platforms such as **Azure DevOps** and **GitHub Actions**, leading to a **30%** increase in deployment frequency and faster time to market.\nDesigned and deployed AWS Lambda functions for serverless processing of real-time data inputs, which improved resource efficiency by **20%** compared to traditional methods.\nCollaborated with data scientists to incorporate **PyTorch** models into production environments, ensuring seamless integration through robust API development.\nArchitected a distributed computing framework leveraging cloud services, facilitating large-scale data processing and model training, resulting in a **40%** reduction in operational costs.\nEstablished best practices in version control and collaboration with **Git**, enhancing code quality and team synergy for ongoing projects.\nMonitored and optimized deployed models utilizing cloud monitoring tools, ensuring high availability and reliability in production environments.\nProvided training and documentation for teams on cloud-based MLOps practices and tools, increasing overall efficiency and knowledge sharing within the organization."
    },
    {
      "role": "Software Engineer",
      "company": "Altum Software",
      "from_date": "Oct 2017",
      "to_date": "Feb 2020",
      "location": "United Kingdom",
      "responsibilities": "Leveraged **Python** to design and implement machine learning models for robust decision-making in operational processes, enhancing efficiency by **15%**.\nUtilized **Docker** and **Kubernetes** for container orchestration, streamlining the deployment of scalable machine learning applications across various environments, achieving a deployment time reduction of **30%**.\nEngineered CI/CD pipelines using **Git**, **Azure**, and **AWS** to automate testing and deployment workflows, ensuring seamless integration of new features and reducing integration issues by **40%**.\nEmployed distributed computing frameworks with **Apache Airflow** and **Prefect** to manage workflows and data pipelines, improving data processing efficiency by **25%**.\nDeveloped and trained machine learning models using **PyTorch**, optimizing performance with efficient hyperparameter tuning techniques, leading to a model accuracy improvement by **20%**.\nImplemented monitoring and observability practices in machine learning workflows to track model performance and operational metrics, enhancing system reliability and responsiveness.\nCollaborated with cross-functional teams to define MLOps best practices and standards, ensuring alignment with business goals while driving innovation through technology.\nConducted thorough performance testing and optimization of machine learning services, addressing bottlenecks and achieving significant reductions in latency.\nManaged and maintained production machine learning systems on **GCP** and **AWS**, ensuring high availability and performance for end-users.\nCreated comprehensive documentation and guidelines for machine learning deployments, facilitating knowledge transfer and team collaboration."
    }
  ],
  "skills": " **Programming Languages:**\n\tPython, \n\n**Backend Frameworks:**\n\tFastAPI, Django, Flask, Spring Boot, \n\n**Frontend Frameworks:**\n\tAngular (1–16), React (15–18), Next.js, Vue.js (2/3), Blazor, \n\n**API Technologies:**\n\tREST & gRPC APIs, \n\n**Serverless and Cloud Functions:**\n\tAWS Lambda, \n\n**Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare), MongoDB (Gaming), Redis, \n\n**DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, \n\n**Cloud & Infrastructure:**\n\tAWS (ECS, RDS, S3), Azure (App Services, Blob, SQL), GCP, \n\n**Other:**\n\tMachine Learning, PyTorch, Distributed Computing, CI/CD, Git, Prefect, Airflow, Keycloak (OIDC, RBAC), JWT, OAuth2, Let’s Encrypt, Nginx, Certbot"
}