{
  "name": "Tomasz Lee",
  "role_name": "Senior Data Engineer",
  "email": "tomasz.lee8@outlook.com",
  "phone": "+48 732 145 942",
  "address": "Warsaw, Poland",
  "linkedin": "https://www.linkedin.com/in/tomasz-lee-b9a25a391/",
  "profile_summary": "Results-driven Senior Data Engineer with 9+ years of experience in designing and implementing data-driven solutions. Proficient in using **Apache Spark**, **Python**, **Java**, **Scala**, **SQL**, and cloud platforms like **Azure**, **AWS**, and **GCP**. Demonstrated expertise in data processing with **Databricks**, **MLOps**, and real-time data streaming using **Kafka** and **Spark Streaming**. Strong background in NoSQL databases and agile methodologies to deliver high-quality, scalable solutions. Proven track record of leading cross-functional teams and optimizing workflows to enhance performance and efficiency.",
  "education": [
    {
      "degree": "Master of Computer Science",
      "category": "",
      "from_year": "Apr 2012",
      "to_year": "Oct 2014",
      "location": "",
      "university": "National University of Singapore"
    },
    {
      "degree": "Bachelor of Computer Science",
      "category": "",
      "from_year": "Apr 2008",
      "to_year": "Mar 2012",
      "location": "",
      "university": "National University of Singapore"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "CD Projekt RED",
      "from_date": "May 2022",
      "to_date": "Oct 2025",
      "location": "Warsaw, Poland",
      "responsibilities": "Utilized **Apache Kafka** for real-time data streaming, enhancing data processing efficiency within the architecture. \nManaged **SQL** and **NoSQL** databases to support diverse data needs and ensure optimized access, improving data handling capabilities. \nDesigned and implemented data pipelines using **Apache Spark** and **Python**, facilitating the transformation and processing of large datasets. \nCollaborated on CI/CD pipelines using **Azure**, resulting in a **40%** reduction in deployment time and promoting agility in development. \nDeveloped scalable data processing solutions leveraging **AWS** and **GCP** cloud services to ensure business continuity and resource optimization. \nEmployed **MLOps** strategies to streamline machine learning model deployment, enhancing application performance and reliability. \nKeenly applied **Agile** methodologies to ensure effective project management and timely delivery of data solutions. \nIntegrated **Spark Streaming** and **Flume** for real-time data ingestion and processing, doubling the throughput of the data pipeline. \nFacilitated data visualization projects using modern libraries such as **D3.js** for interactive reporting and insights generation."
    },
    {
      "role": "Software Engineer",
      "company": "Sea Group",
      "from_date": "Mar 2018",
      "to_date": "Apr 2022",
      "location": "Shopee, Singapore",
      "responsibilities": "Utilized **Apache Spark** and **Python** to design and implement data processing pipelines, enhancing data transformation speed by **30%**.\nEngineered solutions using **Scala** and **Kafka** for real-time data streaming, improving data ingestion efficiency by **25%**.\nManaged and optimized **SQL** and **NoSQL** databases, including customizing queries for improved performance and reduced latency by **15%**.\nImplemented **MLOps** practices to streamline model deployment and monitor performance, contributing to a **20%** increase in machine learning model reliability.\nDeveloped data solutions on cloud platforms including **Azure** and **AWS**, ensuring scalability and security across projects.\nCollaborated with cross-functional teams in an **Agile** environment, ensuring clear communication of project requirements and timelines for timely delivery.\nLed initiatives to migrate legacy systems to **GCP**, performing data mapping and validating integration with new cloud services.\nDesigned batch and streaming data applications employing **Spark Streaming** and **Flume**, achieving processing efficiency across **100,000** data records daily.\nMentored junior engineers in data engineering best practices, boosting team capability and development speed by **20%**.\nConducted thorough code reviews, improving code quality and adherence to industry standards."
    },
    {
      "role": "Software Developer",
      "company": "Grab Holdings Inc",
      "from_date": "Jan 2015",
      "to_date": "Feb 2018",
      "location": "Singapore",
      "responsibilities": "Developed and implemented data processing pipelines using **Apache Spark** and **Kafka**, enhancing data ingestion speed by **35%**.\nUtilized **Python** and **Scala** for data transformation and analysis, streamlining workflows and reducing code duplication by **40%**.\nDesigned and executed complex queries in **SQL** for data retrieval and reporting, leading to a **25%** improvement in data access speeds.\nLeveraged **Azure** services for deploying scalable data solutions, improving system reliability and uptime by **99%**.\nManaged cloud resources across **AWS** and **GCP** to ensure efficient data storage and processing capabilities for diverse datasets.\nCollaborated on MLOps strategies for machine learning model deployment, enhancing model performance monitoring and reducing drift by **15%**.\nImplemented real-time data processing with **Spark Streaming**, allowing for instantaneous insights and reporting.\nParticipated in Agile methodologies, contributing to sprint planning and retrospectives to improve team productivity.\nProduced detailed technical documentation and data flow diagrams for knowledge transfer and onboarding new team members, which decreased onboarding time by **30%**."
    }
  ],
  "skills": "**Programming Languages**\n\tPython, Java, Scala, JavaScript, TypeScript\n\n**Backend Frameworks**\n\tNodeJS, ExpressJS, NestJS, C#, .NET, Entity Framework, Microservices\n\n**Frontend Frameworks**\n\tHTML, CSS, ReactJS, NextJS, VueJS, NuxtJS, Angular, Material UI, Three.js, D3.js, React Native, Flutter, Chakra UI, TailwindCSS\n\n**API Technologies**\n\tRESTful API, GraphQL\n\n**Serverless and Cloud Functions**\n\tAWS, Azure, GCP\n\n**Databases**\n\tMSSQL Server, MySQL, PostgreSQL, MongoDB, DynamoDB, CosmosDB, NoSQL, SQL\n\n**DevOps**\n\tCI/CD pipelines, MLOps\n\n**Cloud & Infrastructure**\n\tApache Kafka, RabbitMQ, Redis, Apache Spark, Databricks, Spark Streaming, Flume\n\n**Other**\n\tUX/UI Design, Git, GitHub, Testing Tools: NUnit, xUnit, Selenium, Moq, Postman, Cypress, JMeter, Jest, Blockchain: Solidity, Ether.js, Web3.js, Ethereum, Agile",
  "apply_company": "EPAM Systems"
}