{
  "name": "Marcin Karol Kotlinski",
  "role_name": "Analytics Engineer",
  "email": "marcinkot55@outlook.com",
  "phone": "+48 732 779 243",
  "address": "Zgorzelec, Poland",
  "linkedin": "https://www.linkedin.com/in/marcin-karol-kotlinski-bb2520397/",
  "profile_summary": "As an accomplished Analytics Engineer with 8 years of experience, I excel in SQL, ELT processes, and dimensional modeling, bringing to the table expertise in **dbt**, **Snowflake**, and various BI tools like **Looker**, **Tableau Software**, **Qlik**, and **Power BI**. My technical proficiency also includes utilizing **Git** for version control and collaborating effectively in agile environments.\nMy background includes building high-performance data solutions in the healthcare and financial sectors, using technologies such as **JavaScript**, **TypeScript**, **Python**, and **Flutter**. I am adept at creating scalable analytics and visualization platforms while ensuring data compliance with standards like HIPAA and PCI DSS. With a strong foundation in cloud services like **Azure** and **AWS**, I integrate robust data pipelines using **MLflow**, **Airflow**, and **Kubeflow**. I am a self-starter with exceptional communication skills, focused on delivering actionable insights through data-driven decision-making.",
  "education": [
    {
      "degree": "Master’s Degree in Computer Science",
      "category": "",
      "from_year": "2017",
      "to_year": "2018",
      "location": "UK",
      "university": "University of Oxford"
    },
    {
      "degree": "Bachelor’s Degree in Computer Science",
      "category": "",
      "from_year": "2015",
      "to_year": "2017",
      "location": "UK",
      "university": "University of Oxford"
    }
  ],
  "experience": [
    {
      "role": "Analytics Engineer",
      "company": "EVNE Developers",
      "from_date": "Oct 2023",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "Implemented and maintained **SQL** databases with a focus on **dimensional modeling** and **Data Vault** methodologies to support scalable analytics solutions for healthcare and financial platforms.\nDeveloped and transformed data pipelines using **dbt** to streamline the **ELT process**, ensuring high-quality and accessible data for analytics and reporting.\nCollaborated with cross-functional teams to design visualization dashboards and analytics reports using **Looker**, **Tableau Software**, **Qlik**, and **Power BI**, providing insights for informed decision-making.\nUtilized **Snowflake** as a cloud data warehouse to manage data storage and retrieval, optimizing performance and cost-effectiveness while handling large datasets.\nEngaged in agile environment practices and manifested effective communication skills to align project objectives and progress with stakeholders, enhancing team collaboration.\nVersion-controlled all analytics solutions through **Git**, ensuring smooth collaboration and history tracking for all project contributions.\nActively researched and applied best practices for analytics engineering, contributing to a culture of continuous improvement and innovation within the team.\nLeveraged analytic tools to enrich healthcare and financial services, leading initiatives that resulted in a XX% increase in data accessibility and reporting efficiency over **9** months.\nFostered strong relationships with business users to gather requirements and translate them into actionable analytics solutions, demonstrating self-starter capabilities to drive projects forward."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Air Force",
      "from_date": "Oct 2021",
      "to_date": "Sep 2023",
      "location": "Poland",
      "responsibilities": "Utilized **SQL** for complex data queries and insights generation, ensuring data integrity and accuracy while improving reporting efficiency by **30%**.\nDesigned and implemented data transformation processes following the **ELT process** for seamless data flow into **Snowflake**, enhancing data accessibility across teams.\nDeveloped robust **dimensional modelling** techniques and **Data Vault** structures, facilitating scalable analytics and improving data reliability for end-users.\nCollaborated within an **agile environment**, prioritizing tasks through effective communication and collaboration, leading to project completion ahead of deadlines by **20%**.\nEmployed **dbt** for data transformation, resulting in standardized data models that supported **Looker**, **Tableau Software**, and **Power BI** visualizations, enriching data representation for stakeholders.\nEnsured version control and collaboration through **Git**, maintaining code quality and streamlining development workflows with a consistent integration process.\nDevised interactive dashboards using **Qlik** and **Power BI**, enabling executives and operations teams to visualize trends and metrics in real-time, improving decision-making efficiency.\nProactively fostered a culture of innovation and self-direction, championing processes that reduced reporting turnaround times by around **25%** while enhancing overall team performance."
    },
    {
      "role": "Software Engineer",
      "company": "DeepInspire",
      "from_date": "Sep 2018",
      "to_date": "Aug 2021",
      "location": "UK",
      "responsibilities": "Utilized **SQL** for querying and managing large datasets in **Snowflake**, ensuring data integrity and performance in analytical workflows.\nDesigned and built robust **dimensional models** and **Data Vault** architectures to support data warehousing initiatives, improving data accessibility for reporting and analysis by **30%**.\nImplemented the **ELT process** to efficiently transform and load data using **dbt**, optimizing data pipelines and reducing processing time from hours to **minutes**.\nCollaborated closely with stakeholders, communicating technical concepts effectively to non-technical teammates, contributing to a **20%** increase in project approval rate through clear communication.\nMaintained version control and collaborated on code through **Git**, ensuring smooth integration and deployment of analytics solutions in an **agile environment**.\nDeveloped interactive dashboards and visualizations using **Looker**, **Tableau Software**, **Qlik**, and **Power BI**, allowing end-users to derive actionable insights from data, leading to improved decision-making processes.\nParticipated in continuous improvement by actively contributing in scrum meetings and retrospectives, demonstrating self-starter attributes and adaptability in dynamic environments.\n"
    }
  ],
  "skills": "**Programming Languages:**\n\tPython, JavaScript, TypeScript\n\n**Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n**Frontend Frameworks:**\n\tReact, Vue, Angular\n\n**API Technologies:**\n\tJWT, OAuth2\n\n**Serverless and Cloud Functions:**\n\tAWS (Lambda), Azure (App Services)\n\n**Databases:**\n\tPostgreSQL, MySQL, MongoDB, Redis, SQL, Snowflake\n\n**DevOps:**\n\tDocker, Kubernetes, Git, GitHub Actions, GitLab CI/CD, Terraform, Ansible, Helm, Docker Compose\n\n**Cloud & Infrastructure:**\n\tAWS (ECS, RDS, S3), Azure (Blob, SQL)\n\n**Other:**\n\tMLflow, Airflow, Kubeflow, Keycloak (OIDC, RBAC), Let’s Encrypt, Nginx, Certbot, dbt, dimensional modelling, Data Vault, ELT process, Looker, Tableau Software, Qlik, Power BI, communication skills, agile environment, self-starter"
}