{
  "name": "Rei Taro",
  "role_name": "Senior Data Engineer",
  "email": "rei515@outlook.com",
  "phone": "+48732529451",
  "address": "Warszawa, Poland",
  "linkedin": "https://www.linkedin.com/in/rei-taro-81a410391/",
  "profile_summary": "Results-driven Senior Data Engineer with over 10 years of experience in data analytics, data visualization, and ETL processes. Proficient in leveraging SQL and tools such as **Tableau**, **Looker**, and **PowerBI** for effective data presentation. Skilled in managing data workflows using **Airflow** and enhancing data transformation with **DBT**. Well-versed in integrating various marketing tools like **Salesforce**, **Marketo**, and **Amplitude** to increase business insights. Experienced in developing high-quality backend systems for financial platforms and AI/ML pipelines, utilizing programming languages like **Python** (FastAPI, Django, Flask) and deploying on **AWS** and **Azure**. Proven history of impactful contributions to leading organizations, including VISA and Reply Polska.",
  "education": [
    {
      "degree": "Bachelorâ€™s Degree in Computer Science",
      "category": "",
      "from_year": "2010",
      "to_year": "2015",
      "location": "Japan",
      "university": "Keio University"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "Leobit",
      "from_date": "Aug 2022",
      "to_date": "Present",
      "location": "Poland",
      "responsibilities": "Utilized **SQL** and **ETL** processes to engineer backend data services, supporting data ingestion and reporting workflows for analytics.\nLeveraged **Airflow** to create and maintain data pipelines, enhancing the efficiency and accuracy of data flow for regulatory compliance.\nDeveloped data visualization solutions using **PowerBI**, **Looker**, and **Tableau** to present actionable insights and facilitate data-driven decision-making, successfully reducing report generation time by **35%**.\nImplemented version control best practices through **GitHub**, ensuring collaboration and consistent deployment processes.\nApplied **DBT** for data transformation tasks, enriching the data for analysis and improving overall data integrity.\nCollaborated with cross-functional teams to integrate systems like **Salesforce** and **Marketo**, tackling integration challenges and enhancing data connectivity.\nAnalyzed product performance metrics using tools like **Amplitude**, contributing to key product analytics strategies that increased user engagement by **20%**.\nLed efforts to enhance analytic capabilities while ensuring compliance with organizational standards and best practices."
    },
    {
      "role": "Software Engineer",
      "company": "Innovature",
      "from_date": "Nov 2018",
      "to_date": "Jun 2022",
      "location": "Japan",
      "responsibilities": "- Executed data analytics and ETL processes using **SQL** to optimize and manage data ingestion and transformation, improving reporting efficiency by **30%**.\n- Developed and maintained data visualization dashboards with **PowerBI**, **Looker**, and **Tableau**, enhancing insights generation from complex datasets.\n- Implemented robust data pipelines using **Apache Airflow** for workflow orchestration, automating data processes and reducing manual hours by **25%**.\n- Leveraged **GitHub** for version control, ensuring collaboration across teams with a seamless code review process.\n- Integrated third-party tools such as **Salesforce** and **Marketo** into analytics workflows, streamlining customer data analysis across platforms.\n- Created custom data models and visualizations using **DBT**, leading to a significant increase in clarity and accessibility of analytics by **40%**.\n- Collaborated with product teams to analyze user behavior using **Amplitude**, driving product enhancements based on data-driven insights.\n- Enhanced reporting capabilities with integrated data from various sources, ensuring comprehensive analytics for business intelligence and strategic decisions."
    },
    {
      "role": "Software Developer",
      "company": "Wizcorp",
      "from_date": "Apr 2015",
      "to_date": "Nov 2018",
      "location": "Japan",
      "responsibilities": "Utilized **SQL** to extract and manipulate data for analysis, enhancing insights through effective data management solutions.\nDeveloped ETL processes leveraging **Airflow** and **DBT** to ensure seamless integration of data across various platforms, streamlining data workflows.\nCreated dynamic visualizations and dashboards using **PowerBI**, **Looker**, and **Tableau** for reporting to provide stakeholders with clear insights into data trends.\nApplied advanced data analytics techniques to support product analytics, driving strategic decision-making by analyzing user behavior and engagement.\nCollaborated with cross-functional teams to implement data visualization solutions that align with business objectives, ensuring consistent communication and understanding of data-driven insights.\nLed version **2.0** of the data pipeline enhancements, increasing data retrieval speed by **35%**, significantly improving operational efficiency.\nEmployed GitHub for version control and collaboration, facilitating continuous integration and deployment in the development cycle.\nEngaged in data quality assurance processes, implementing rigorous checks within ETL workflows to maintain **99.9%** data accuracy for analytical outputs."
    }
  ],
  "skills": "Programming Languages:\n\t**Python (3.8+), SQL, JavaScript, Bash**\n\nBackend Frameworks:\n\t**FastAPI, Flask, Django, Celery**\n\nFrontend Frameworks:\n\t**PowerBI, Looker, Tableau, data visualization**\n\nAPI Technologies:\n\t**REST/gRPC APIs**\n\nServerless and Cloud Functions:\n\t**AWS (EC2, S3, Lambda), Azure**\n\nDatabases:\n\t**PostgreSQL, MySQL, MongoDB, Redis**\n\nDevOps:\n\t**Docker, Kubernetes, GitHub Actions, Azure DevOps, CI/CD, Git**\n\nCloud & Infrastructure:\n\t**AWS, Azure**\n\nOther:\n\t**AI/ML Tools: Pandas, NumPy, scikit-learn, TensorFlow, Airflow, MLflow, ETL, DBT, Salesforce, Marketo, Amplitude, data analytics, product analytics, Microservices, Kafka, PyTest**",
  "apply_company": "Autodesk"
}