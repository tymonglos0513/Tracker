{
  "name": "Tomasz Lee",
  "role_name": "Senior Data Engineer",
  "email": "tomasz.lee8@outlook.com",
  "phone": "+48 732 145 942",
  "address": "Warsaw, Poland",
  "linkedin": "https://www.linkedin.com/in/tomasz-lee-477994390/",
  "profile_summary": "Senior Data Engineer with 9+ years of experience in leveraging **Python**, **SQL**, and **Spark** to design and implement innovative data solutions. Proficient in **Databricks**, **cloud-based data platforms** such as **Azure**, **AWS**, and **GCP**, and skilled in data modeling, building **data lakes**, and **data warehouses**. Demonstrated ability in performance tuning, CI/CD, and monitoring to ensure optimal data processing. Originally a .NET Full Stack Developer, I bring a strong foundation in software development with expertise in **Apache Kafka**, **RabbitMQ**, **Redis**, **ReactJS**, **NextJS**, and the **.NET** technology stack, allowing for effective collaboration with cross-functional teams and driving projects to successful completion.",
  "education": [
    {
      "degree": "Master of Computer Science",
      "category": "",
      "from_year": "Apr 2012",
      "to_year": "Oct 2014",
      "location": "",
      "university": "National University of Singapore"
    },
    {
      "degree": "Bachelor of Computer Science",
      "category": "",
      "from_year": "Apr 2008",
      "to_year": "Mar 2012",
      "location": "",
      "university": "National University of Singapore"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "CD Projekt RED",
      "from_date": "May 2022",
      "to_date": "Apr 2025",
      "location": "Warsaw, Poland",
      "responsibilities": "Utilized **Python** for data manipulation and transformation, leveraging its capabilities to streamline data processes and implement efficient data pipelines.\nDesigned and optimized **SQL** queries for accessing and analyzing large datasets, enhancing data retrieval speed by **20%**.\nEngineered data models and structures in **Databricks** and **Azure**, facilitating data lakes and warehouses integration for improved data accessibility and storage.\nEmployed **Apache Spark** for big data processing, managing workloads that increased processing efficiency by **30%**.\nDeveloped and maintained CI/CD pipelines on **Azure DevOps**, achieving a **40%** reduction in deployment time.\nImplemented comprehensive monitoring solutions on cloud-based data platforms (**AWS**, **GCP**, **Azure**) to ensure system reliability and performance.\nConducted performance tuning of data workflows, reducing processing times by **25%** through effective optimization strategies.\nCollaborated with cross-functional teams to design and implement effective data models, directly contributing to optimal data flow and integration.\nEngaged in the setup and management of cloud-based data platforms, ensuring data security and compliance across all systems."
    },
    {
      "role": "Full Stack Developer",
      "company": "Sea Group",
      "from_date": "Mar 2018",
      "to_date": "Apr 2022",
      "location": "Shopee, Singapore",
      "responsibilities": "Utilized **Python** to design and implement data pipelines, enhancing data processing efficiency by **20%**.\nDeveloped optimized **SQL** queries for data retrieval and processing within **Azure** and **AWS** cloud environments, improving execution time by **30%**.\nLeveraged **Spark** on **Databricks** for big data processing tasks, leading to a **15%** increase in data processing speed.\nImplemented data modeling techniques for building robust **data lakes** and **data warehouses**, ensuring data integrity and accessibility.\nConducted performance tuning of analytical queries, achieving optimized resource allocation, which reduced costs by **25%** in cloud services.\nEngineered monitoring solutions for pipeline health using **cloud-based data platforms**, enabling real-time alerting and issue resolution.\nEstablished CI/CD practices for smooth deployment of data engineering workflows, decreasing deployment times by **40%**.\nCollaborated with cross-functional teams to gather requirements and develop scalable data solutions, resulting in a **100%** on-time project delivery rate.\nMentored junior data engineers on best practices in data architecture and engineering, fostering professional growth within the team."
    },
    {
      "role": "Software Developer",
      "company": "Grab Holdings Inc",
      "from_date": "Jan 2015",
      "to_date": "Feb 2018",
      "location": "Singapore",
      "responsibilities": "Utilized **Python** and **SQL** to perform data modeling and ensure seamless integration of data processes into cloud-based data platforms, achieving a 30% increase in data accessibility.\nImplemented **Azure** services for CI/CD pipelines, enhancing deployment efficiency by 40%.\nDeveloped optimized data lakes and data warehouses leveraging **Databricks** and **Spark**, which facilitated data retrieval times under 5 seconds.\nConducted performance tuning of SQL queries, leading to a 25% improvement in processing speeds for large datasets.\nCollaborated with cross-functional teams to establish monitoring frameworks for cloud infrastructures using **AWS** and **GCP** solutions.\nEngaged in daily standups and design reviews to maintain alignment with data engineering objectives and best practices.\nCreated comprehensive documentation on data architecture and workflows to enhance team knowledge and onboarding processes.\nAssisted in migrating legacy data solutions to cloud services, improving configuration and scalability to handle up to 10 TB of data.\nProactively integrated advanced data APIs to enable versatile data analytics capabilities across multiple systems."
    }
  ],
  "skills": "**Programming Languages**\n\tPython\n\n**Backend Frameworks**\n\tNodeJS, ExpressJS, NestJS, C#, .NET, Entity Framework, Microservices\n\n**Frontend Frameworks**\n\tHTML, CSS, JavaScript, TypeScript, ReactJS, NextJS, VueJS, NuxtJS, Angular, Material UI, Three.js, D3.js, React Native, Flutter, Chakra UI, TailwindCSS\n\n**API Technologies**\n\tRESTful API, GraphQL\n\n**Serverless and Cloud Functions**\n\tAWS, Azure, GCP\n\n**Databases**\n\tMSSQL Server, MySQL, PostgreSQL, MongoDB, DynamoDB, CosmosDB, SQL\n\n**DevOps**\n\tCI/CD pipelines, monitoring\n\n**Cloud & Infrastructure**\n\tcloud-based data platforms, data modeling, data lakes, data warehouses, performance tuning\n\n**Other**\n\tUX/UI Design, Git, GitHub, Redux, Blockchain: Solidity, Ether.js, Web3.js, Ethereum, Messaging & Caching: Apache Kafka, RabbitMQ, Redis, Testing Tools: NUnit, xUnit, Selenium, Moq, Postman, Cypress, JMeter, Jest"
}