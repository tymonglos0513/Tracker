{
  "name": "Rei Taro",
  "role_name": "Backend Engineer",
  "email": "rei515@outlook.com",
  "phone": "+48732529451",
  "address": "Warszawa, Poland",
  "linkedin": "https://www.linkedin.com/in/rei-taro-81a410391/",
  "profile_summary": "Results-driven Backend Engineer with over 10 years of extensive experience in API integration and developing robust ETL pipelines. Proficient in **JavaScript**, **Node.js**, and **PostgreSQL**, with a strong focus on handling unstructured data and integrating AI APIs such as **OpenAI API**, **Gemini API**, and **Anthropic API**. Skilled in crafting high-performing backend systems and automation tools, while utilizing **Python** for scripting and chatbot development. Notable expertise in building conversational interfaces and document parsing solutions. Proven ability to deliver impactful projects for global clients, including VISA and Reply Polska, leveraging a solid foundation in cloud-native architectures.",
  "education": [
    {
      "degree": "Bachelorâ€™s Degree in Computer Science",
      "category": "",
      "from_year": "2010",
      "to_year": "2015",
      "location": "Japan",
      "university": "Keio University"
    }
  ],
  "experience": [
    {
      "role": "Backend Engineer",
      "company": "Leobit",
      "from_date": "Aug 2022",
      "to_date": "Present",
      "location": "Poland",
      "responsibilities": "Developed and integrated backend services leveraging **Python**, with a focus on **API integration** and **document parsing** to enhance user experience and improve workflow efficiency.\nEngineered ETL pipelines using **Apache Airflow** and **PostgreSQL** to manage and process data efficiently, ensuring accuracy with over **95%** data integrity across **3** key projects.\nUtilized **Node.js** for asynchronous processing, building scalable systems capable of handling **100,000** transactions per day through event-driven architecture.\nImplemented robust solutions for unstructured data handling, employing technologies such as **OpenAI API** and **GPT-3** for intelligent data extraction and analysis.\nCreated and maintained chatbots and conversational interfaces using **Gemini API** and **Anthropic API**, facilitating user interaction and operational support for **24/7** service availability.\nLed initiatives to integrate security measures, including **OAuth2**, to protect sensitive user data and maintain compliance with industry standards.\nCollaborated with software engineers and product managers to troubleshoot and resolve integration issues, resulting in a **30%** reduction in system downtime while overseeing multiple releases."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Innovature",
      "from_date": "Nov 2018",
      "to_date": "Jun 2022",
      "location": "Japan",
      "responsibilities": "Designed and implemented ETL pipelines using **Python**, ensuring efficient management of unstructured data and real-time data integration with **PostgreSQL**.\nDeveloped and maintained APIs for seamless integration of **OpenAI API**, **Gemini API**, and **Anthropic API**, enabling advanced AI functionalities in applications.\nEngineered backend service functionalities in **Node.js** to support chatbot development and conversational interfaces, enhancing user engagement and operational efficiency.\nIntegrated robust document parsing mechanisms to optimize data processing workflows, improving accuracy and efficiency by up to **30%**.\nCollaborated with cross-functional teams to align on system requirements, ensuring smooth API integration and deployment strategies while adhering to industry standards.\nImplemented security measures in the application stack, focusing on secure API integration and user data protection solutions, ensuring compliance with **OAuth2** protocols.\nConducted performance evaluations and optimizations across **3** backend services resulting in a **20%** increase in throughput and responsiveness."
    },
    {
      "role": "Software Developer",
      "company": "Wizcorp",
      "from_date": "Apr 2015",
      "to_date": "Nov 2018",
      "location": "Japan",
      "responsibilities": "- Developed and integrated **APIs** using **Python** and **Flask** for seamless communication between backend and frontend systems, enhancing user experience in the **Backend Engineer** role.\n- Implemented robust **PostgreSQL** databases to handle unstructured data efficiently, supporting data storage and retrieval for trading operations.\n- Engineered ETL pipelines to process and analyze large datasets, ensuring accurate trade execution and portfolio management from **AI APIs integrations** like **OpenAI API** and **Gemini API**.\n- Utilized **Node.js** for backend services, improving task execution speed by **30%** through advanced concurrency mechanisms.\n- Collaborated on the development of conversational interfaces and chatbots that integrated with various **AI APIs**, enhancing customer interaction and support capabilities.\n- Parsed documents effectively to extract valuable information, utilizing **Python scripting** and aiding regulatory compliance with **MiFID II** and **GDPR** standards.\n- Developed comprehensive testing frameworks using **PyTest** and **mock servers**, reducing bugs in production by **25%** during CI/CD processes.\n- Optimized process management by introducing scheduling solutions with **Celery** and **RabbitMQ**, facilitating a **40%** increase in backend task efficiency."
    }
  ],
  "skills": "**Programming Languages**\n\tPython (3.8+), SQL, Bash, JavaScript\n\n**Backend Frameworks**\n\tFastAPI, Flask, Django, Celery, Node.js\n\n**Frontend Frameworks**\n\t\n\n**API Technologies**\n\tREST/gRPC APIs, API integration, AI APIs integration, OpenAI API, Gemini API, Anthropic API, chatbot development, conversational interfaces, prompt engineering\n\n**Serverless and Cloud Functions**\n\tAWS (EC2, S3, Lambda), Azure\n\n**Databases**\n\tPostgreSQL, MySQL, MongoDB, Redis\n\n**DevOps**\n\tDocker, Kubernetes, GitHub Actions, Azure DevOps, CI/CD\n\n**Cloud & Infrastructure**\n\t\n\n**Other**\n\tAI/ML Tools: Pandas, NumPy, scikit-learn, TensorFlow, Airflow, MLflow, unstructured data handling, ETL pipelines, document parsing, Python scripting"
}