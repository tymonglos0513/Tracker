{
  "name": "Patryk Zaslawski",
  "role_name": "Senior Machine Learning Engineer",
  "email": "patrykzas0428@outlook.com",
  "phone": "+48669862402",
  "address": "Gdanski, Poland",
  "linkedin": "https://www.linkedin.com/in/patryk-zaslawski-6b04a8397/",
  "profile_summary": "As a Senior Machine Learning Engineer with 8+ years of software engineering experience, I excel in **Machine Learning**, developing **Data Pipelines**, and deploying models with **MLOps** methodologies. Proficient in **Python** and adept with frameworks and libraries such as **TensorFlow**, **PyTorch**, **NumPy**, **pandas**, **Keras**, **Scikit-learn**, **XGBoost**, and **LightGBM**, I focus on **Model Evaluation**, **Hyperparameter Optimization**, and **Model Tuning** to deliver high-quality machine learning solutions. I have hands-on experience using cloud platforms like **AWS**, **Azure**, and **GCP**, including services such as **AWS SageMaker**, **GCP AI Platform**, and **Azure Machine Learning**. My technical background is complemented by a deep understanding of **SQL** and **NoSQL** databases, ensuring optimized data retrieval and storage for analytical tasks. In addition, I bring strong analytical thinking, problem-solving capabilities, and effective communication skills to collaborate efficiently within team-oriented environments, enabling the creation of innovative solutions across different sectors.",
  "education": [
    {
      "degree": "Bachelor’s Degree",
      "category": "Computer Science",
      "from_year": "2014",
      "to_year": "2017",
      "location": "United Kingdom",
      "university": "The University of Manchester"
    }
  ],
  "experience": [
    {
      "role": "Senior Machine Learning Engineer",
      "company": "Binary Studio",
      "from_date": "Aug 2023",
      "to_date": "Present",
      "location": "United Kingdom (Remote)",
      "responsibilities": "Developed and optimized **machine learning** models using **Python** and libraries such as **TensorFlow**, **PyTorch**, **NumPy**, **pandas**, and **scikit-learn**, contributing to a 25% improvement in prediction accuracy.\nDesigned, implemented, and maintained robust **data pipelines** using **Apache Airflow** and **Azure Data Factory** for efficient model training and real-time data ingestion, enabling processing of **over 1 million** records daily.\nDeployed machine learning models utilizing **AWS SageMaker** and **Azure Machine Learning** to streamline workflows and facilitate continual learning, leading to a **15% reduction** in operational costs.\nApplied **hyperparameter optimization** techniques to improve the performance of **LightGBM**, **XGBoost**, and other models, achieving a **10% increase** in performance metrics.\nImplemented MLOps practices with **Kubernetes** and **Docker** for reliable deployment and scaling of models, improving deployment efficiency by **30%**.\nCollaborated with cross-functional teams to translate business requirements into data-driven insights, enhancing communication strategies and technical documentation for improved project alignment.\nConducted extensive **model evaluation** processes ensuring adherence to compliance standards and best practices in algorithms, resulting in high-quality deliverables and satisfied stakeholders.\nMentored junior engineers on advanced **machine learning** techniques and best practices, fostering a team-oriented culture and boosting overall team proficiency.\nUtilized **SQL** and **NoSQL** databases for data storage and retrieval, ensuring efficient data management for large datasets supporting analysis and model training.\nDemonstrated strong **analytical thinking** and **problem-solving** skills through systematic troubleshooting of model performance, which led to swift resolutions of issues impacting model outputs.\nDesigned and executed **CI/CD** pipelines for machine learning models using **GitHub Actions** and **Azure DevOps**, ensuring consistent delivery and high-quality code integration across platforms.\nContinuously improved processes and knowledge sharing within the team to promote a strong learning environment focused on **AI and ML** innovations."
    },
    {
      "role": "Software Engineer",
      "company": "Ardigen",
      "from_date": "Mar 2020",
      "to_date": "Aug 2023",
      "location": "Poland",
      "responsibilities": "Implemented data pipelines in **Python** to support machine learning workflows, ensuring seamless integration with **AWS SageMaker** and **Azure Machine Learning** for model deployment and MLOps.\nDeveloped and optimized machine learning models using **TensorFlow**, **PyTorch**, **Keras**, and **Scikit-learn**, achieving a model accuracy improvement of **20%** over previous benchmarks.\nConducted comprehensive model evaluations and hyperparameter optimization with **NumPy** and **pandas**, reducing training time by **30%** and enhancing model performance.\nDesigned, built, and maintained Kubernetes clusters for orchestrating and deploying machine learning services, enabling seamless scaling and high availability in a cloud environment using **AWS** and **GCP**.\nLed the integration of large language models in project workflows, using version **1.5** of the **Hugging Face Transformers** library to enhance natural language processing functionalities.\nCollaborated with cross-functional teams to communicate complex machine learning concepts effectively, promoting an analytical thinking approach towards problem-solving.\nUtilized **Docker** to containerize machine learning applications, improving deployment efficiency and standardizing environments across development and production.\nManaged data storage solutions using **SQL** and **NoSQL** databases to ensure reliable access and retrieval of model training datasets, with a focus on managing datasets of over **1 TB**.\nEmployed model tuning techniques to enhance the performance of algorithms like **XGBoost** and **LightGBM**, achieving significant improvements in predictive accuracy for real-time analytics.\nContributed to the development of CI/CD pipelines for continuous integration and delivery of machine learning models, leveraging **Azure DevOps** and **GitHub Actions** to automate workflows and ensure code quality through best practices."
    },
    {
      "role": "Software Engineer",
      "company": "Altum Software",
      "from_date": "Oct 2017",
      "to_date": "Feb 2020",
      "location": "United Kingdom",
      "responsibilities": "Developed and deployed machine learning models using **TensorFlow**, **PyTorch**, and **Keras** to enhance data-driven decision-making for e-commerce operations, improving overall efficiency by **30%**.\nImplemented end-to-end data pipelines utilizing **AWS SageMaker** and **GCP AI Platform** for seamless model training and deployment, reducing deployment time by **40%**.\nOptimized models through hyperparameter tuning with **Scikit-learn** and **XGBoost**, achieving accuracy improvements of up to **20%** in prediction tasks.\nUtilized **Python** and libraries such as **NumPy** and **pandas** to preprocess data and derive valuable insights, enhancing model input quality and performance.\nManaged model lifecycle and versioning, ensuring robust MLOps practices by employing **Docker** for containerization and **Kubernetes** for orchestration in scalable deployments.\nDesigned and conducted A/B testing of models to evaluate performance against key metrics, translating results into actionable insights for stakeholders.\nLeveraged cloud services (**AWS**, **Azure**) for hosting machine learning solutions, ensuring compliance and governance in the deployment strategy.\nApplied analytical thinking and problem-solving skills to troubleshoot issues with data integrity and model performance, leading cross-functional collaboration to enhance solutions.\nCommunicated findings and presented model evaluations clearly to non-technical stakeholders, facilitating informed decisions based on data analysis.\nWorked effectively in a team-oriented environment, contributing insights and mentoring junior engineers, fostering a culture of continuous learning and improvement."
    }
  ],
  "skills": "**Programming Languages:**\n\tPython, SQL\n\n**Backend Frameworks:**\n\tFastAPI, Django, Flask, Spring Boot\n\n**Frontend Frameworks:**\n\tAngular (1–16), React (15–18), Next.js, Vue.js (2/3), Blazor\n\n**API Technologies:**\n\tREST & gRPC APIs\n\n**Serverless and Cloud Functions:**\n\tAWS (Lambda), Azure, GCP\n\n**Databases:**\n\tPostgreSQL, MySQL, MongoDB, Redis, NoSQL\n\n**DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD\n\n**Cloud & Infrastructure:**\n\tAWS (ECS, RDS, S3), Azure (App Services, Blob, SQL), GCP\n\n**Other:**\n\tMachine Learning, Data Pipelines, Model Deployment, MLOps, TensorFlow, PyTorch, Large Language Models, NumPy, pandas, Keras, Scikit-learn, XGBoost, LightGBM, Model Evaluation, Hyperparameter Optimization, Model Tuning, Analytical Thinking, Problem-solving, Communication Skills, Team-oriented, Authentication & Security (Keycloak, JWT, OAuth2, Let’s Encrypt, Nginx, Certbot)"
}