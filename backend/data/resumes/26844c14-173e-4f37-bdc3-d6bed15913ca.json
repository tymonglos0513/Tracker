{
  "name": "Marcin Karol Kotlinski",
  "role_name": "Lead Data Engineer",
  "email": "marcinkot55@outlook.com",
  "phone": "+48 732 779 243",
  "address": "Zgorzelec, Poland",
  "linkedin": "https://www.linkedin.com/in/marcin-karol-kotlinski-bb2520397/",
  "profile_summary": "Results-oriented Lead Data Engineer with 8 years of experience in data engineering, specializing in **Azure Data Factory**, **Synapse**, **Databricks**, and **Data Lake** technologies. Proven track record in designing and implementing robust ETL/ELT processes, utilizing **SQL** and **Python** to deliver high-performance solutions. Proficient in modern **DataOps** and **DevOps** practices that enhance productivity and streamline workflows in cloud-native environments including **Azure**, **AWS**, and **Google Cloud**.\n\nExperienced in building data governance frameworks and ensuring compliance with industry standards. Strong communication skills enable effective collaboration with cross-functional teams to drive data initiatives forward. Additionally, I possess extensive knowledge in developing enterprise-grade platforms with machine learning capabilities, leveraging technologies like **React**, **Next.js**, **Node.js**, and **FastAPI**. My background in microservices architecture and CI/CD automation supports the creation of secure, scalable applications that meet diverse business needs.",
  "education": [
    {
      "degree": "Master’s Degree in Computer Science",
      "category": "",
      "from_year": "2017",
      "to_year": "2018",
      "location": "UK",
      "university": "University of Oxford"
    },
    {
      "degree": "Bachelor’s Degree in Computer Science",
      "category": "",
      "from_year": "2015",
      "to_year": "2017",
      "location": "UK",
      "university": "University of Oxford"
    }
  ],
  "experience": [
    {
      "role": "Lead Data Engineer",
      "company": "EVNE Developers",
      "from_date": "Oct 2023",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "Designed and implemented **ETL** and **ELT** processes to ensure efficient data ingestion and transformation utilizing **Azure Data Factory**, **Databricks**, and **SQL** for high-quality data processing.\nArchitected cloud-native data architectures utilizing **Data Lake** solutions for large-scale data storage and optimized querying in **Azure**, **AWS**, and **Google Cloud** environments.\nDeveloped and managed automated DevOps pipelines using **Azure DevOps** and **GitHub Actions** to enhance code deployment and monitoring for data engineering applications.\nImplemented **DataOps** methodologies to streamline data workflows, ensuring rapid iterations and aligning data teams with business requirements.\nCollaborated cross-functionally to create real-time dashboards and reporting tools utilizing **Power BI**, delivering actionable insights for stakeholders.\nOversaw data governance strategies to ensure compliance and integrity of healthcare and financial data in accordance with industry regulations.\nConducted data quality assessments and validations to maintain accuracy across various data environments and platforms.\nFostered effective communication skills among stakeholders to translate complex technical concepts into understandable insights, supporting decision-making processes.\nLed training sessions and mentor junior data engineers, fostering a culture of continuous learning and skill development within the team.\nExecuted projects leveraging **Python** for scripting and automating data-related tasks, enhancing productivity and operational efficiency."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Air Force",
      "from_date": "Oct 2021",
      "to_date": "Sep 2023",
      "location": "Poland",
      "responsibilities": "Led the design and implementation of cloud-native data warehousing solutions by leveraging **Azure Data Factory**, **Synapse**, and **Databricks**, enhancing data governance and data accessibility across teams.\nDeveloped and maintained ETL and ELT pipelines utilizing **Python**, ensuring efficient data ingestion into a **Data Lake** and enabling real-time analytics processes.\nCollaborated with cross-functional teams to deliver data-driven insights using **Power BI**, transitioning legacy reporting to interactive dashboards that improved decision-making speed by **30%**.\nUtilized **SQL** for complex data querying and transformation, establishing robust data models that supported product features and analytics needs, resulting in improved data reliability by **25%**.\nImplemented DataOps and DevOps practices to streamline and automate data workflows, achieving a **40%** reduction in deployment times and enhancing the overall development lifecycle efficiency.\nEngaged in ongoing cloud-related projects on **Azure**, **AWS**, and **Google Cloud**, maintaining compliance with industry standards and ensuring robust security protocols on all data-related initiatives.\nWorked on integrating machine learning models with data pipelines using technologies such as **MLflow** and **Airflow**, resulting in predictive analytics capabilities that improved user engagement metrics by **20%**.\nFostered strong communication skills across teams to ensure clarity in project requirements and deliverables, contributing to a **15%** increase in project satisfaction ratings according to stakeholder feedback."
    },
    {
      "role": "Software Engineer",
      "company": "DeepInspire",
      "from_date": "Sep 2018",
      "to_date": "Aug 2021",
      "location": "UK",
      "responsibilities": "Led the design and optimization of backend ETL processes using **Python** and **Azure Data Factory**, ensuring efficient data processing for cloud-native data warehousing.\nEngineered scalable data pipelines with **Databricks** and **Azure Synapse**, managing over **10TB** of data efficiently and ensuring data accuracy and integrity.\nCollaborated with cross-functional teams to implement DataOps strategies, streamlining workflows and enhancing deployment processes leveraging **Azure**, **AWS**, and **Google Cloud** technologies.\nDeveloped and maintained data structures in **SQL** and **Data Lake** environments, improving data retrieval times by **30%** and enhancing query performance.\nImplemented robust data governance practices, ensuring compliance with industry standards and developing protocols for secure data access through role-based access control (RBAC).\nDesigned and executed data transformation workflows using **ETL** and **ELT** methodologies, driving insights and analytics for business intelligence initiatives with tools like **Power BI**.\nSpearheaded cloud migration projects, improving data accessibility and performance, successfully migrating **5+** legacy systems to Azure cloud services while ensuring zero downtime.\nFostered effective communication across teams, delivering training and workshops on data engineering best practices and cloud services to enhance internal capabilities and collaboration.\nObtained cloud certifications leading to improved team skills and project delivery timeframes, ensuring high-quality data solutions are implemented efficiently.\nLeveraged experience in data engineering to mentor junior engineers, fostering a culture of continuous learning and knowledge sharing within the team."
    }
  ],
  "skills": " **Programming Languages:**\n\tPython, JavaScript/TypeScript\n\n**Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n**Frontend Frameworks:**\n\tReact, Vue, Angular\n\n**API Technologies:**\n\tJWT, OAuth2\n\n**Serverless and Cloud Functions:**\n\tAWS (Lambda), Azure (App Services)\n\n**Databases:**\n\tPostgreSQL, MySQL, MongoDB, Redis, SQL\n\n**DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, Terraform, Ansible, Helm, Docker Compose\n\n**Cloud & Infrastructure:**\n\tAWS (ECS, RDS, S3), Azure (Blob), Google Cloud\n\n**Other:**\n\tMLflow, Airflow, Kubeflow, Keycloak (OIDC, RBAC), Let’s Encrypt, Nginx, Certbot, Azure Data Factory, Synapse, Databricks, Data Lake, DataOps, ETL, ELT, Power BI, Cloud-native data warehouse, Data governance, Communication skills, Cloud certifications, Data engineering experience"
}