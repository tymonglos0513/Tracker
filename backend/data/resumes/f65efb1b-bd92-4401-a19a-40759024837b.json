{
  "name": "Marcin Karol Kotlinski",
  "role_name": "Senior Software Engineer",
  "email": "marcinkot55@outlook.com",
  "phone": "+48 732 779 243",
  "address": "Zgorzelec, Poland",
  "linkedin": "https://www.linkedin.com/in/marcin-k-a54a89395/",
  "profile_summary": "As a skilled Senior Software Engineer with 8 years of experience, I excel in Python and have a strong command of SQL and Data Warehousing principles. My proficiency in ETL processes, Data Modeling, and API development ensures the creation of efficient, high-performance data solutions. I am well-versed in modern methodologies like Agile and Lean, significantly enhancing communication, teamwork, problem-solving abilities, and critical thinking skills within cross-functional teams.\nMy technical expertise encompasses a diverse stack including **Python**, **DBT**, **Airflow**, and robust experience in building enterprise applications that align with compliance standards. I possess hands-on experience in implementing CI/CD automation for seamless deployment and have led initiatives to adopt MLOps workflows using tools like MLflow and Kubeflow. I bring a foundational understanding of microservices architecture, ensuring robust security and scalability in the applications I develop.",
  "education": [
    {
      "degree": "Master’s Degree in Computer Science",
      "category": "",
      "from_year": "2017",
      "to_year": "2018",
      "location": "UK",
      "university": "University of Oxford"
    },
    {
      "degree": "Bachelor’s Degree in Computer Science",
      "category": "",
      "from_year": "2015",
      "to_year": "2017",
      "location": "UK",
      "university": "University of Oxford"
    }
  ],
  "experience": [
    {
      "role": "Senior Software Engineer",
      "company": "EVNE Developers",
      "from_date": "Oct 2023",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "Developed and optimized **ETL** processes using **Python**, enhancing the data pipeline’s efficiency by **30%**, ensuring seamless data transfer and transformation for analytical purposes.\nUtilized **SQL** for robust data modeling and querying, maintaining a well-structured data warehouse that improved report generation times by **25%** across various business units.\nImplemented **Airflow** for orchestrating complex workflows, managing dependencies in data pipelines to support real-time analytics in a fast-paced environment.\nCollaborated with cross-functional teams in an **Agile** setting, enhancing communication and teamwork to deliver high-quality features on schedule, resulting in a **15%** increase in project delivery speed.\nConducted critical problem-solving sessions to address data integrity issues, employing **Lean** principles to streamline processes and eliminate waste, contributing to a more efficient operational workflow.\nMonitored and fine-tuned **APIs** to ensure high availability and performance, enabling seamless integration between front-end applications and back-end databases.\nDesigned, developed, and maintained scalable data models that support business intelligence initiatives, aiding in decision-making by providing accurate insights.\nFacilitated knowledge sharing within the team to foster a culture of autonomy and critical thinking, encouraging the independent troubleshooting of data issues.\nCreated documentation and training materials to enhance team collaboration and onboarding processes, demonstrating empathy towards new team members transitioning into their roles.\nParticipated in weekly sprint planning meetings to assess sprint progress and adjust priorities based on project needs, ensuring transparency and alignment within the team."
    },
    {
      "role": "Software Engineer",
      "company": "Air Force",
      "from_date": "Oct 2021",
      "to_date": "Sep 2023",
      "location": "Poland",
      "responsibilities": "• Developed and modernized data pipelines leveraging **Python** and **Apache Airflow**, ensuring robust ETL processes for effective data integration and transformation across diverse financial systems.\n• Created scalable and efficient **SQL** data models, enhancing **data warehousing** solutions to support high-volume analytics and reporting accurately.\n• Implemented APIs to streamline data access and improve system integration, facilitating seamless communication between various components of the financial platforms.\n• Utilized **DBT** for data transformation, enabling a well-structured environment for analytical queries and enhancing **data modeling** practices.\n• Fostered a culture of **Agile** and **Lean** methodologies within the team, promoting efficient workflows and high-quality deliverables through effective **communication** and **teamwork**.\n• Leveraged critical thinking and **problem-solving** skills to tackle complex challenges and optimize existing processes, resulting in a **30%** increase in operational efficiency.\n• Conducted regular data quality assessments, ensuring the integrity and accuracy of financial data utilized in decision-making, leading to a **20%** reduction in discrepancies.\n• Collaborated with cross-functional teams to design and iterate on effective data solutions, enhancing user engagement and satisfaction with financial systems.\n• Demonstrated autonomy in executing tasks while effectively mentoring junior team members, promoting a cooperative environment focused on mutual success."
    },
    {
      "role": "Software Engineer",
      "company": "DeepInspire",
      "from_date": "Sep 2018",
      "to_date": "Aug 2021",
      "location": "UK",
      "responsibilities": "Utilized **Python** to develop scalable backend services for data processing tasks, ensuring efficient data workflows and integrity for a global e-commerce platform.\nImplemented **SQL** for robust data modeling, capable of handling complex queries essential for data warehousing solutions, optimizing performance by **30%**, and ensuring data accuracy in ETL processes.\nEmployed **DBT** and **Airflow** for streamlined ETL and data transformation tasks, achieving automated data pipelines that contribute to real-time analytics, enhancing decision-making efficiency by **25%**.\nDesigned and developed **APIs** that support data accessibility and integration across various services, facilitating seamless communication between frontend and backend systems.\nDemonstrated strong communication and teamwork skills in agile environments, collaborating with cross-functional teams to adhere to lean methodologies, which improved project delivery timelines by **15%**.\nExercised critical thinking and problem-solving skills to troubleshoot and resolve technical challenges, delivering solutions with a focus on reducing downtime and enhancing system reliability.\nFostered autonomy in project development while modeling data structures that aligned with business needs, showcasing an empathetic approach to team collaboration and user-centered design.\nEngaged in continuous improvement practices, adapting to changing user requirements and technical updates, ensuring the platform remains innovative and competitive."
    }
  ],
  "skills": " **Programming Languages:**\n\tPython, JavaScript/TypeScript\n\n **Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n **Frontend Frameworks:**\n\tReact, Vue, Angular\n\n **API Technologies:**\n\tAPIs, JWT, OAuth2\n\n **Serverless and Cloud Functions:**\n\tAWS (ECS, Lambda, RDS, S3), Azure (App Services, Blob, SQL)\n\n **Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare), MongoDB (Gaming), Redis, SQL\n\n **DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, Terraform, Ansible, Helm, Docker Compose\n\n **Cloud & Infrastructure:**\n\tAWS (ECS, Lambda, RDS, S3), Azure (App Services, Blob, SQL)\n\n **Other:**\n\tMLflow, Airflow, Kubeflow, Data Modeling, Data Warehousing, ETL, Lean, Agile, Communication, Teamwork, Problem Solving, Autonomy, Critical Thinking, Empathy",
  "apply_company": "Clarity AI"
}