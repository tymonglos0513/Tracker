{
  "name": "Damian Franciszek Pospiech",
  "role_name": "Senior Analytics Engineer",
  "email": "damianpos127@outlook.com",
  "phone": "+48 732 143 608",
  "address": "Mikolow, Poland",
  "linkedin": "https://www.linkedin.com/in/damian-pospiech-261821397/",
  "profile_summary": "Senior Analytics Engineer with 13+ years of experience specializing in **data modeling**, **data architecture**, and **data pipeline** development for high-performance applications in the healthcare and financial sectors. Proficient in **Python** and skilled in **SQL**, leveraging expertise in **dbt** for data transformation and documentation. Experienced in statistical methods and **predictive modeling** to support data analysis and drive strategic business decisions.\n\nDemonstrated capability in **CI/CD** methodologies for efficient deployment and version control, ensuring high-quality deliverables while adhering to compliance standards. Strong background in MLOps practices, focusing on model training and orchestration using **MLflow** and **Airflow**. Adept at communication and team management, fostering collaboration to deliver robust analytics solutions.",
  "education": [
    {
      "degree": "Bachelor's degree in Computer Science",
      "category": "Computer Science",
      "from_year": "2007",
      "to_year": "2012",
      "location": "UK",
      "university": "University of Cambridge"
    }
  ],
  "experience": [
    {
      "role": "Senior Analytics Engineer",
      "company": "Codebridge",
      "from_date": "Apr 2021",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "Utilized **SQL** and **dbt** to design and implement data models that enhance data architecture and ensure data integrity across analytics platforms in healthcare and financial services.\n\nDeveloped and optimized **Python**-based data pipelines to enable scalable data processing and real-time analytics, supporting decision-making processes for various stakeholders.\n\nCreated comprehensive data documentation that captures data lineage, transformation processes, and system integrations to facilitate robust data analysis and team communication.\n\nEstablished CI/CD processes for data workflows, promoting automation and quality assurance by integrating version control with tools such as Git and **GitHub Actions**.\n\nLed the development of predictive modeling frameworks employing statistical methods and analytics tools, resulting in enhanced forecasting accuracy for financial and health outcomes.\n\nImplemented effective team management strategies, fostering a collaborative environment for data scientists and engineers to achieve shared project goals.\n\nEvaluated and applied data best practices to model complex datasets, ensuring clear and actionable insights through **data documentation** and visual analytics support.\n\nManaged the deployment of advanced analytics features leveraging the latest **data analysis** techniques and tools, enhancing the overall functionality of analytics systems.\n\nSpearheaded the integration of data quality and governance measures, ensuring adherence to industry standards and regulatory compliance for data handling processes.\n\nPresented analytics findings and strategic recommendations effectively to stakeholders through data storytelling, demonstrating strong communication skills."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Grupa Azoty",
      "from_date": "Oct 2015",
      "to_date": "Mar 2021",
      "location": "Poland",
      "responsibilities": "Leveraged **SQL** and **Python** for data modeling and building data pipelines, enhancing data architecture for improved analytics operations.\nUtilized **dbt** for efficient data transformation and documentation, ensuring high-quality data output for analytics tasks.\nImplemented CI/CD practices to streamline the deployment of data solutions, achieving a **30% increase** in delivery efficiency.\nConducted comprehensive data analysis using statistical methods, enabling teams to derive actionable insights and support data-driven decision-making.\nDesigned and maintained detailed data documentation, fostering clear communication across teams and facilitating knowledge transfer of data workflows.\nChampioned predictive modeling techniques to enhance forecasting accuracy, incorporating statistical methods for robust results.\nManaged cross-functional teams, promoting collaboration and effective communication to ensure project milestones were met on time, achieving a **95% project completion rate**.\nProduced reliable data documentation, allowing for transparency and ease of understanding for stakeholders, aiding in long-term data strategy formulation.\nImplemented version control practices, ensuring the integrity and traceability of data models and analytics workflows."
    },
    {
      "role": "Software Engineer",
      "company": "GoodCore",
      "from_date": "Jan 2012",
      "to_date": "Sep 2015",
      "location": "UK",
      "responsibilities": "Utilized **SQL** and **dbt** to perform data modeling and architecture, enhancing data pipeline efficiency and ensuring accurate data documentation for analytics projects.\nEngineered complex **data pipelines** to support dynamic reporting and predictive modeling capabilities, delivering insights that informed business decisions and improved operational strategies.\nCollaborated with cross-functional teams to refine **data documentation**, ensuring clarity and accessibility for stakeholders, while promoting effective communication across departments.\nEmployed **version control** systems to maintain code integrity and manage changes in data processing scripts, resulting in streamlined collaboration among team members.\nImplemented CI/CD practices to automate data integration and deployment processes, significantly reducing turnaround times for analytics updates and refinements.\nLed efforts in applying **statistical methods** and **data analysis** techniques to extract actionable insights, facilitating data-driven decision-making throughout the organization.\nTrained and mentored team members on **data architecture** best practices, fostering a culture of learning and continuous improvement in data management practices.\nDesigned scalable analytics solutions that contributed to a **30% reduction** in processing time for large datasets, enhancing overall system performance.\nDeveloped predictive models using advanced **statistical methods**, achieving an accuracy rate of **85%** in forecasting key business metrics, thus driving revenue growth.\nFostered a collaborative team environment through effective communication, enabling the successful execution of multiple analytics projects simultaneously."
    }
  ],
  "skills": "**Programming Languages:**\n\tPython, SQL\n\n**Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n**Frontend Frameworks:**\n\tJavaScript/TypeScript: React, Vue, Angular\n\n**API Technologies:**\n\tOAuth2, JWT, Keycloak (OIDC, RBAC)\n\n**Serverless and Cloud Functions:**\n\tAWS: Lambda, ECS\n\n**Databases:**\n\tPostgreSQL, MySQL, MongoDB, Redis\n\n**Data Management:**\n\tdatamodeling, dataarchitecture, datapipeline, datadocumentation\n\n**DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD\n\n**Cloud & Infrastructure:**\n\tAWS: RDS, S3, Azure: App Services, Blob Storage, SQL Database\n\n**Other:**\n\tMLflow, Airflow, Kubeflow, Terraform, Ansible, Helm, Docker Compose, version control, predictive modeling, statistical methods, data analysis, communication, team management",
  "apply_company": "OpenClassrooms"
}