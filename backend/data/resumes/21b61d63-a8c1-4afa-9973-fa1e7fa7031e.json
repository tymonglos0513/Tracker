{
  "name": "Damian Franciszek Pospiech",
  "role_name": "Lead Data Engineer",
  "email": "damianpos127@outlook.com",
  "phone": "+48 732 143 608",
  "address": "Mikolow, Poland",
  "linkedin": "https://www.linkedin.com/in/damian-pospiech-187801395/",
  "profile_summary": "Lead Data Engineer with 13+ years of experience specializing in **Azure Data Factory**, **Synapse**, and **Databricks**, along with a solid foundation in **ETL** and **ELT** processes. Proficient in **SQL** and experienced in transforming large datasets in **Data Lakes** for analytics and reporting, including using **Power BI** for data visualization. Comprehensive understanding of **DataOps** and **DevOps** methodologies, driving efficient workflows and collaboration among teams.\nSkilled in **Python** for data processing and analytics, with hands-on experience in deploying robust applications in multiple **cloud platforms** including **AWS** and **Microsoft Azure**. Demonstrated ability to lead projects that require strong problem-solving and communication skills, ensuring compliance with industry standards. Proven expertise in developing high-performance applications leveraging **JavaScript**, **TypeScript**, and **Flutter**, and delivering **cloud-native data warehouses** that meet enterprise needs.",
  "education": [
    {
      "degree": "Bachelor's degree in Computer Science",
      "category": "Computer Science",
      "from_year": "2007",
      "to_year": "2012",
      "location": "UK",
      "university": "University of Cambridge"
    }
  ],
  "experience": [
    {
      "role": "Lead Data Engineer",
      "company": "Codebridge",
      "from_date": "Apr 2021",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "Utilized **Azure Data Factory**, **Databricks**, and **SQL** to design and implement ETL and ELT processes for large-scale data ingestion and transformation, ensuring efficient data flow into **Data Lakes** and **cloud-native data warehouses**.\nDeveloped and maintained data architectures on **Microsoft Azure**, enabling real-time analytics and reporting with **Power BI**, leading to a **30%** improvement in data accessibility for business intelligence.\nCollaborated with cross-functional teams to define data modeling strategies, enhancing data quality and usability across multiple projects, and promoting effective **DataOps** practices.\nImplemented **DevOps** best practices in data pipelines, utilizing **GitHub Actions** and **Azure DevOps** for automated deployment and monitoring, increasing deployment frequency by **50%**.\nLeveraged **Python** for data processing and analysis, creating complex data scripts that optimized **Data Lake** usage and reduced processing times by **20%**.\nDesigned and developed robust data solutions that integrated Google Cloud and AWS for cloud data management, demonstrating strong collaboration and problem-solving skills within multi-cloud environments.\nExecuted advanced data transformations with **Azure Synapse** for batch and stream processing, resulting in scalable and cost-effective data analytics solutions.\nProduced comprehensive documentation and maintained effective communication strategies throughout projects, ensuring stakeholder alignment and project visibility.\nConducted training sessions and workshops to enhance the team’s understanding of **DataOps** approaches, fostering a culture of continuous improvement and innovation in data engineering practices.\nCreated and optimized data visualization dashboards in **Power BI**, facilitating the monitoring of key performance indicators (KPIs) and enhancing decision-making processes across departments."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Grupa Azoty",
      "from_date": "Oct 2015",
      "to_date": "Mar 2021",
      "location": "Poland",
      "responsibilities": "Utilized **Azure Data Factory** and **Databricks** to modernize core financial data processes, implementing **ETL** and **ELT** strategies to support seamless data integration from internal and third-party sources.\nDesigned and optimized cloud-native data solutions on **Microsoft Azure**, enhancing data modeling capabilities and supporting both batch and real-time processing for high-volume financial transactions.\nLed development of data pipelines for automation using **Python**, achieving a **95%** reduction in data processing time and improving data availability across teams.\nCollaborated with cross-functional teams to deliver actionable business insights via **Power BI** dashboards, facilitating data-driven decision making with a goal of improving reporting efficiency by **30%**.\nEnsured adherence to **DataOps** and **DevOps** practices, increasing deployment frequency by **40%** while maintaining operational excellence and data quality.\nDeveloped machine learning models for real-time fraud detection using **Python** and **scikit-learn**, achieving an over **85%** detection rate for suspicious activities, leading to a decrease in fraud losses.\nImplemented robust data lake solutions to enhance data accessibility and analytics capabilities across the organization, leveraging **Cloud platforms** such as **AWS** and **Google Cloud** for deployment and scalability.\nConducted team workshops to enhance **communication skills**, **collaboration**, and **problem-solving** capabilities, resulting in improved project delivery timelines and team performance."
    },
    {
      "role": "Software Engineer",
      "company": "GoodCore",
      "from_date": "Jan 2012",
      "to_date": "Sep 2015",
      "location": "UK",
      "responsibilities": "Designed and optimized ETL processes for cloud-native data warehouses utilizing **Azure Data Factory**, ensuring seamless data integration and transformation across various data sources with **SQL**.\nEngineered data pipelines using **Databricks** and **Synapse** to streamline data processing for analytics, improving query performance by over **40%** while managing large volumes of data in **Data Lakes**.\nCollaborated cross-functionally with teams, implementing **DataOps** and **DevOps** methodologies, resulting in enhanced operational efficiency and reduced deployment times by **30%**.\nDeveloped scalable data modeling solutions in **Python**, producing accurate and reliable data sets that support real-time decision-making and analytics.\nLed the migration of legacy data systems to **Microsoft Azure**, reducing costs by **25%** and increasing data accessibility across organizations.\nEnhanced data visualization capabilities by integrating **Power BI** dashboards for business stakeholders, directly improving data-driven decision-making across departments.\nFacilitated clear and effective communication with both technical and non-technical teams, fostering a collaborative work environment that drives project success and innovation.\nImplemented and maintained robust data governance frameworks to ensure compliance with data protection regulations, resulting in **zero** data breaches throughout the project lifecycle.\nUtilized cloud platforms such as **AWS** and **Google Cloud** to build and deploy sophisticated data solutions that enhance the overall functionality of analytics tools across the organization.\nApplied advanced problem-solving techniques to identify bottlenecks in data flow, implementing solutions that improved data processing efficiency by **20%**."
    }
  ],
  "skills": " **Programming Languages:**\n\tPython, SQL\n\n **Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n **Frontend Frameworks:**\n\tReact, Vue, Angular\n\n **API Technologies:**\n\tOAuth2, JWT\n\n **Serverless and Cloud Functions:**\n\tAWS Lambda, Azure Functions\n\n **Databases:**\n\tPostgreSQL, MySQL, MongoDB, Redis\n\n **DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, Terraform, Ansible, Helm, Docker Compose\n\n **Cloud & Infrastructure:**\n\tAWS ECS, AWS RDS, AWS S3, Microsoft Azure, Azure App Services, Azure Blob Storage, Azure SQL Database, Azure Data Factory, Synapse, Databricks, Data Lake, Cloud platforms, Google Cloud\n\n **Other:**\n\tMLflow, Airflow, Kubeflow, DataOps, Data modeling, Cloud-native data warehouse, Power BI, Communication skills, Collaboration, Problem-solving, Keycloak (OIDC, RBAC), Nginx, Let’s Encrypt, Certbot"
}