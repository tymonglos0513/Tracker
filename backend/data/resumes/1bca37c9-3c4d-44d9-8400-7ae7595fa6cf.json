{
  "name": "Tomasz Lee",
  "role_name": "Senior Data Engineer",
  "email": "tomasz.lee8@outlook.com",
  "phone": "+48 732 145 942",
  "address": "Warsaw, Poland",
  "linkedin": "https://www.linkedin.com/in/tomasz-lee-b9a25a391/",
  "profile_summary": "Dynamic Senior Data Engineer with 9+ years of experience in data architecture and engineering. Proficient in **AWS**, **GCP**, **Azure**, and **Docker** to ensure scalable cloud solutions. Expertise in data processing and orchestration tools such as **Apache Airflow**, **DBT**, **Hadoop**, and **Spark** for transforming and managing large datasets. Solid experience with **SQL**, **Snowflake**, **BigQuery**, and **Redshift** for efficient data warehousing and analysis. Proven track record of optimizing workflows and improving data system performance while collaborating across cross-functional teams. Additionally skilled in **microservices architecture**, with a strong background in **.NET**, **C#**, **ReactJS**, and **NextJS**, making contributions toward backend and frontend development.",
  "education": [
    {
      "degree": "Master of Computer Science",
      "category": "",
      "from_year": "Apr 2012",
      "to_year": "Oct 2014",
      "location": "",
      "university": "National University of Singapore"
    },
    {
      "degree": "Bachelor of Computer Science",
      "category": "",
      "from_year": "Apr 2008",
      "to_year": "Mar 2012",
      "location": "",
      "university": "National University of Singapore"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "CD Projekt RED",
      "from_date": "May 2022",
      "to_date": "Oct 2025",
      "location": "Warsaw, Poland",
      "responsibilities": "Leveraged **AWS**, **GCP**, and **Azure** to design and implement data pipelines, enhancing data processing efficiency by 30%.\nUtilized **Snowflake** and **Redshift** for data warehousing solutions, optimizing storage costs by 25%.\nImplemented data workflow orchestration using **Airflow**, resulting in a 40% improvement in task scheduling and monitoring.\nDeveloped ETL processes using **DBT** and **SQL**, facilitating data transformation and integration from various sources.\nContainerized applications with **Docker** and orchestrated them with **Kubernetes**, improving deployment consistency and reducing setup time by 50%.\nPerformed data analysis using **Spark**, achieving data processing speeds of up to **100GB/hour**.\nArchitected data lakes on **S3** and integration with **BigQuery** for large-scale data analytics, reducing query execution time by 35%.\nImplemented and optimized **REST-API** services for seamless access to data across applications.\nCollaborated with cross-functional teams to enhance data availability and quality, contributing to improved decision-making processes.\nDesigned and maintained complex SQL queries for downstream analytics, improving reporting accuracy by 20%."
    },
    {
      "role": "Software Engineer",
      "company": "Sea Group",
      "from_date": "Mar 2018",
      "to_date": "Apr 2022",
      "location": "Shopee, Singapore",
      "responsibilities": "Implemented and optimized data pipelines using **AWS** and **GCP** to ensure data quality and integrity, improving processing speed by **40%**.\nDeveloped and maintained ETL processes with **Airflow** to automate data workflows across various sources, facilitating a more efficient data integration system.\nUtilized **Snowflake** and **Redshift** for data warehousing solutions, resulting in a **30%** reduction in query processing time compared to previous systems.\nDesigned and built efficient data models using **DBT** and **SQL**, optimizing data retrieval and reporting.\nLeveraged **Docker** and **Kubernetes** for container orchestration in data application deployment, enhancing scalability.\nExecuted real-time data processing tasks using **Apache Spark** and **Hive**, achieving a **25%** improvement in data analytics turnaround time.\nCollaborated with cross-functional teams to gather requirements and align on project objectives, ensuring a seamless development process.\nMonitored and maintained data pipelines, ensuring uptime metrics exceeded **99.5%** availability.\nProvided training and mentorship to junior data engineers, fostering a culture of learning and innovation within the team."
    },
    {
      "role": "Software Developer",
      "company": "Grab Holdings Inc",
      "from_date": "Jan 2015",
      "to_date": "Feb 2018",
      "location": "Singapore",
      "responsibilities": "Utilized **AWS** and **Azure** to develop and maintain data pipelines, ensuring efficient data flow and processing across the organization.\nLeveraged **Snowflake** and **BigQuery** for data warehousing solutions, enhancing data accessibility and analysis capabilities while reducing costs by **30%**.\nImplemented ETL processes using **Python** and **Airflow**, automating data ingestion from various sources and improving data processing times by **50%**.\nDesigned and maintained **DBT** models for transformation scripts, promoting cleaner and more efficient data practices.\nCollaborated with engineering teams to containerize applications using **Docker** and orchestrated deployments with **Kubernetes**, ensuring consistency across development and production environments.\nWorked extensively with **SQL** for database querying and optimization, increasing query performance by **40%** through efficient indexing strategies.\nIntegrated **REST-API** for seamless data exchange with external platforms, enhancing functionality and interoperability.\nEngaged in code reviews and peer programming to foster best practices in data engineering and team collaboration, contributing to a culture of continuous improvement.\nPrepared comprehensive documentation and held training sessions for data engineering processes, improving onboarding for new team members.\n"
    }
  ],
  "skills": "**Programming Languages**\n\tPython, JavaScript, TypeScript\n\n**Backend Frameworks**\n\tNodeJS, ExpressJS, NestJS, C#, .NET\n\n**Frontend Frameworks**\n\tReactJS, NextJS, VueJS, NuxtJS, Angular, React Native, Flutter, Material UI, Three.js, D3.js, Chakra UI, TailwindCSS\n\n**API Technologies**\n\tRESTful API, GraphQL\n\n**Serverless and Cloud Functions**\n\tAWS, Azure, GCP\n\n**Databases**\n\tMSSQL Server, MySQL, PostgreSQL, MongoDB, DynamoDB, CosmosDB, Snowflake, SQL, Bigquery, Redshift, Vertica, Teradata, SAP HANA\n\n**DevOps**\n\tCI/CD pipelines, Docker, Kubernetes\n\n**Cloud & Infrastructure**\n\tS3, DataBricks, Hadoop, Hive, Spark\n\n**Other**\n\tUX/UI Design, Git, GitHub, Microservices, Messaging & Caching: Apache Kafka, RabbitMQ, Redis, Blockchain: Solidity, Ether.js, Web3.js, Ethereum, Testing Tools: NUnit, xUnit, Selenium, Moq, Postman, Cypress, JMeter, Jest",
  "apply_company": "Rush Street Interactive"
}