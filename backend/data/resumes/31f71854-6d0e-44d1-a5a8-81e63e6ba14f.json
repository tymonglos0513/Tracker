{
  "name": "Tomasz Lee",
  "role_name": "Senior Data Engineer",
  "email": "tomasz.lee8@outlook.com",
  "phone": "+48 732 145 942",
  "address": "Warsaw, Poland",
  "linkedin": "https://www.linkedin.com/in/tomasz-lee-b9a25a391/",
  "profile_summary": "Results-driven Senior Data Engineer with 9+ years of extensive experience in data modeling, performance optimization, and debugging. Proficient in leveraging **Azure Data Factory**, **Snowflake**, **DBT**, and **SQL** to design and implement robust data pipelines. Highly skilled in **Python** for data processing and analytics, ensuring efficient data flow and integrity. Experienced in utilizing **Git** for version control and implementing **CI/CD** best practices to streamline deployment processes. Proven track record of effective communication and collaboration across teams to deliver high-quality solutions. Additionally, I bring a strong foundation as a .NET Full Stack Developer, with expertise in **microservices architecture** and technologies including **Apache Kafka**, **RabbitMQ**, **Redis**, **ReactJS**, **NextJS**, and **.NET**, ensuring a comprehensive approach to complex application development.",
  "education": [
    {
      "degree": "Master of Computer Science",
      "category": "",
      "from_year": "Apr 2012",
      "to_year": "Oct 2014",
      "location": "",
      "university": "National University of Singapore"
    },
    {
      "degree": "Bachelor of Computer Science",
      "category": "",
      "from_year": "Apr 2008",
      "to_year": "Mar 2012",
      "location": "",
      "university": "National University of Singapore"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "CD Projekt RED",
      "from_date": "May 2022",
      "to_date": "Oct 2025",
      "location": "Warsaw, Poland",
      "responsibilities": "Utilized **Azure Data Factory** for efficient data integration and ETL processes, ensuring seamless data flow and transformation.\nDeveloped and maintained data models leveraging **Snowflake** and **DBT**, optimizing data storage and accessibility for analytics purposes.\nEmployed **SQL** for querying and managing databases, focusing on performance optimization and efficient data retrieval.\nImplemented **Python** scripts for data processing and automation, enhancing data manipulation efficiency by 30%.\nMonitored and debugged data pipelines, ensuring high-quality data outputs and minimizing downtime by **20%**.\nRefined and optimized existing processes, resulting in a **25%** reduction in data processing times through effective performance tuning.\nDeveloped comprehensive documentation for data models and workflows, improving team communication and facilitating knowledge transfer.\nEngaged with cross-functional teams to drive collaboration, ensuring alignment with business objectives and data strategies.\nIntegrated version control using **Git**, maintaining a reliable codebase and streamlining collaboration within the team.\nDesigned and implemented CI/CD pipelines to automate deployments, significantly reducing the time required for production updates by **40%**."
    },
    {
      "role": "Full Stack Developer",
      "company": "Sea Group",
      "from_date": "Mar 2018",
      "to_date": "Apr 2022",
      "location": "Shopee, Singapore",
      "responsibilities": "Utilized **Azure Data Factory** to orchestrate data workflows, improving data pipeline efficiency by **20%**.\nEmployed **Snowflake** for data warehousing, optimizing storage and query performance, leading to a **30%** decrease in runtime for data retrieval.\nDeveloped **DBT** models to ensure accurate data transformations, streamlining the ETL process and enhancing data quality.\nImplemented robust **SQL** queries for performance optimization, achieving a **40%** enhancement in data processing times.\nUsed **Python** for data manipulation and analysis, providing actionable insights to stakeholders and improving data-driven decision-making.\nConducted thorough data modeling to enhance database design, reducing redundancy by **15%** and simplifying access pathways.\nInstituted monitoring and debugging processes for data workflows, leading to a **50%** reduction in error rates.\nLed CI/CD initiatives using **Git** to ensure reliable data deployment cycles, minimizing downtime and increasing reliability.\nCommunicated effectively with cross-functional teams to define project requirements, ensuring alignment with business goals and maximizing team productivity.\nMentored junior engineers on best practices for data engineering, fostering skill development and collaboration within the team."
    },
    {
      "role": "Software Developer",
      "company": "Grab Holdings Inc",
      "from_date": "Jan 2015",
      "to_date": "Feb 2018",
      "location": "Singapore",
      "responsibilities": "Utilized **Azure Data Factory** to orchestrate and automate data workflows, achieving a **30%** reduction in data processing time.\nDeveloped data models leveraging **Snowflake** for efficient data storage and retrieval, resulting in a **25%** improvement in query performance.\nImplemented **DBT** for version control and transformation of data, improving data quality across multiple pipelines.\nWrote complex SQL queries to manipulate and analyze data, facilitating decision-making processes and business intelligence.\nDesigned and executed performance optimization strategies that enhanced data load times by **40%**, ensuring smooth performance of the data environment.\nEngaged in monitoring and debugging data pipelines to troubleshoot issues promptly and maintain data integrity.\nCollaborated with cross-functional teams to ensure clear communication and alignment of data initiatives with broader business objectives.\nManaged source control and CI/CD processes using **Git**, streamlining deployment workflows for data solutions.\nParticipated in code reviews and knowledge sharing sessions to foster continuous improvement within the team.\nDelivered comprehensive documentation on data engineering processes and systems, improving onboarding for new team members."
    }
  ],
  "skills": " **Programming Languages**\n\t Python, JavaScript, TypeScript\n\n **Backend Frameworks**\n\t NodeJS, ExpressJS, NestJS, C#, .NET\n\n **Frontend Frameworks**\n\t HTML, CSS, ReactJS, NextJS, VueJS, NuxtJS, Angular, Material UI, Three.js, D3.js, React Native, Flutter, Chakra UI, TailwindCSS\n\n **API Technologies**\n\t RESTful API, GraphQL\n\n **Serverless and Cloud Functions**\n\t Azure Data Factory\n\n **Databases**\n\t MSSQL Server, MySQL, PostgreSQL, MongoDB, DynamoDB, CosmosDB, SQL\n\n **DevOps**\n\t AWS, Azure, CI/CD, Git, GitHub\n\n **Cloud & Infrastructure**\n\t Performance optimization, Monitoring, Debugging\n\n **Other**\n\t UX/UI Design, Redux, Blockchain, Solidity, Ether.js, Web3.js, Ethereum, Messaging & Caching, Apache Kafka, RabbitMQ, Redis, Testing Tools, NUnit, xUnit, Selenium, Moq, Postman, Cypress, JMeter, Jest, Microservices, Data modeling, Communication"
}