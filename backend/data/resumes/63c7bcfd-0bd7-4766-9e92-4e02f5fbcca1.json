{
  "name": "Damian Franciszek Pospiech",
  "role_name": "Senior Data Engineer",
  "email": "damianpos127@outlook.com",
  "phone": "+48 732 143 608",
  "address": "Mikolow, Poland",
  "linkedin": "https://www.linkedin.com/in/damian-pospiech-261821397/",
  "profile_summary": "Senior Data Engineer with 13+ years of experience in building high-performance data solutions and data warehousing using **ETL**, **ELT**, **Snowflake**, and **Azure**. Proven expertise in implementing **AWS** cloud technologies, ensuring data quality, and managing relational databases effectively. Skilled in data modeling and designing data warehouses that support agile methodologies such as **Scrum** and **Kanban**.\nDemonstrated ability to collaborate with stakeholders to align data projects with business objectives and drive performance management across platforms. Strong problem-solving skills complemented by a solid background in compliance-driven development practices. Proficient in **DevOps** methodologies, implementing CI/CD pipelines for data-driven applications, and leveraging frameworks such as **Python** and **JavaScript** alongside **FastAPI** and **Django** for comprehensive end-to-end solutions.",
  "education": [
    {
      "degree": "Bachelor's degree in Computer Science",
      "category": "Computer Science",
      "from_year": "2007",
      "to_year": "2012",
      "location": "UK",
      "university": "University of Cambridge"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "Codebridge",
      "from_date": "Apr 2021",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "- Developed and maintained ETL/ELT processes for data integration using **AWS** and **Azure**, optimizing data workflows to enhance efficiency and reliability in a **Data Warehouse** environment.\n- Designed and implemented scalable data models with **Snowflake** and relational databases, ensuring high performance and compliance with **Data Quality** standards.\n- Collaborated within an **Agile** development framework, practicing **Scrum** and **Kanban** methodologies to streamline project management and enhance team productivity.\n- Conducted performance management and monitoring of data processes, achieving a **30%** reduction in execution time through targeted optimizations and best practices in **Data Warehousing**.\n- Employed effective **Communication** and **Stakeholder Management** techniques to gather requirements and deliver tailored solutions for data-driven decision-making.\n- Led initiatives in **Metadata Management**, ensuring data lineage and transparency across all data pipelines to facilitate regulatory compliance.\n- Utilized cutting-edge **DevOps** practices by implementing CI/CD approaches, ensuring reliable and frequent releases in data-centric projects.\n- Addressed complex data problems with strong **Problem-solving** skills, driving innovative solutions that improved overall data integrity and accessibility.\n- Fostered cross-functional teamwork, enhancing collaboration between data teams and other business units to align on data strategy and objectives.\n- Played a vital role in defining and monitoring data quality metrics, resulting in improved data governance and user trust across systems."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Grupa Azoty",
      "from_date": "Oct 2015",
      "to_date": "Mar 2021",
      "location": "Poland",
      "responsibilities": "• Developed and optimized **ETL** processes for integrating financial data into a **Snowflake** data warehouse, ensuring high data quality and performance management, resulting in a **30%** reduction in data processing time.\n• Designed scalable data models to facilitate efficient data retrieval and analytics for core financial platforms, aligning with **Agile** methodologies to enhance team collaboration and stakeholder management.\n• Led the implementation of cloud-based solutions on **Azure** and **AWS**, contributing to enhanced data warehousing strategies and a **25%** increase in the efficiency of data workflows.\n• Managed **metadata management** strategies to ensure clear documentation and understanding of data lineage for better compliance and governance.\n• Collaborated with cross-functional teams in a **Scrum** environment, effectively communicating technical concepts to stakeholders to drive project alignment and success.\n• Engaged in continuous performance management and optimization of data pipelines, implementing **DevOps** practices that reduced deployment times by **40%**.\n• Addressed data quality issues through effective problem-solving techniques, resulting in improved analytics accuracy and user trust in the financial data provided.\n• Conducted stakeholder meetings to gather requirements and feedback, ensuring that solutions met business needs and enhanced operational efficiency."
    },
    {
      "role": "Software Engineer",
      "company": "GoodCore",
      "from_date": "Jan 2012",
      "to_date": "Sep 2015",
      "location": "UK",
      "responsibilities": "• Implemented ETL and ELT processes to ensure data quality and seamless data flow into the data warehouse, leveraging **Snowflake** for robust data storage and processing.\n• Designed and managed relational databases, applying advanced data modeling techniques to optimize query performance and enhance data accessibility across **Azure** and **AWS** environments.\n• Delivered strategic insights through data analysis, ensuring stakeholder management by communicating effectively with teams and project stakeholders during Agile, Scrum, and Kanban methodologies.\n• Collaborated cross-functionally to develop solutions that improved performance management and data quality across all operational fronts.\n• Led initiatives in metadata management to maintain data integrity and provide clear documentation for data structures, supporting ongoing data warehouse optimization.\n• Employed strong problem-solving skills to identify and alleviate data discrepancies, ensuring superior data reliability and consistency for decision-making processes.\n• Participated in iterative development cycles, ensuring rapid delivery of functional improvements through effective communication and collaboration with project teams."
    }
  ],
  "skills": " **Programming Languages:**\n\tPython: FastAPI, Flask, Django\n\tJavaScript/TypeScript: React, Vue, Angular\n\n **Backend Frameworks:**\n\t\n\n **Frontend Frameworks:**\n\t\n\n **API Technologies:**\n\t\n\n **Serverless and Cloud Functions:**\n\tAWS: ECS, Lambda, RDS, S3\n\tAzure: App Services, Blob Storage, SQL Database\n\n **Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare)\n\tMongoDB (Gaming), Redis\n\tRelational Databases\n\n **DevOps:**\n\tDocker, Kubernetes\n\tGitHub Actions, GitLab CI/CD\n\tTerraform, Ansible, Helm, Docker Compose\n\n **Cloud & Infrastructure:**\n\tAWS\n\tAzure\n\n **Other:**\n\tETL\n\tELT\n\tData Warehouse\n\tSnowflake\n\tData Modelling\n\tAgile\n\tScrum\n\tKanban\n\tData Quality\n\tMetadata Management\n\tPerformance Management\n\tProblem-solving\n\tCommunication\n\tStakeholder Management",
  "apply_company": "Zurich Insurance"
}