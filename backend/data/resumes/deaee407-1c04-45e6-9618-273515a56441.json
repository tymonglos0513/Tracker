{
  "name": "Tomasz Lee",
  "role_name": "Senior Data Engineer",
  "email": "tomasz.lee8@outlook.com",
  "phone": "+48 732 145 942",
  "address": "Warsaw, Poland",
  "linkedin": "https://www.linkedin.com/in/tomasz-lee-b9a25a391/",
  "profile_summary": "Accomplished Senior Data Engineer with 9+ years of experience in building and optimizing data pipelines and data warehouses. Proficient in **SQL**, **Databricks**, **Google BigQuery**, **Airflow**, **dbt**, **Docker**, **Kubernetes**, and data governance principles. Expertise in schema design, indexing, query optimization, and data modeling, ensuring efficient data retrieval and management. Strong project management skills, with a proven ability to lead cross-functional teams to enhance collaboration and communication. Known for delivering high-quality, scalable data solutions while fostering a culture of innovation and continuous improvement.",
  "education": [
    {
      "degree": "Master of Computer Science",
      "category": "",
      "from_year": "Apr 2012",
      "to_year": "Oct 2014",
      "location": "",
      "university": "National University of Singapore"
    },
    {
      "degree": "Bachelor of Computer Science",
      "category": "",
      "from_year": "Apr 2008",
      "to_year": "Mar 2012",
      "location": "",
      "university": "National University of Singapore"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "CD Projekt RED",
      "from_date": "May 2022",
      "to_date": "Oct 2025",
      "location": "Warsaw, Poland",
      "responsibilities": "Designed and developed data pipelines leveraging **Docker** and **Kubernetes** for container orchestration, ensuring scalable data processing workflows.\nImplemented **SQL** and optimized **MSSQL** database queries, achieving a **20%** reduction in query execution times and enhancing data retrieval efficiency.\nDeveloped and maintained data models for effective **Data Warehousing** and **Metadata Management**, improving the overall data architecture strategy.\nManaged data governance practices to ensure compliance and data integrity across all stages of data life cycle, increasing data reliability by **30%**.\nUtilized **Databricks** and **Google BigQuery** for advanced data processing and analytics, facilitating seamless data exploration and analysis.\nCollaborated with cross-functional teams to design and implement **Airflow** workflows for automated ETL processes, decreasing manual intervention by **50%**.\nApplied **dbt** for SQL-based data transformation, enhancing the transparency and maintainability of data models.\nOptimized data schema design, contributing to effective data pipeline operations and reducing load times by **15%**.\nEnhanced project delivery through strategic **Project Management**, ensuring that timelines and objectives were consistently met.\nFostered collaboration and communication between data stakeholders to align data initiatives with business objectives, driving a data-driven culture within the organization."
    },
    {
      "role": "Software Engineer",
      "company": "Sea Group",
      "from_date": "Mar 2018",
      "to_date": "Apr 2022",
      "location": "Shopee, Singapore",
      "responsibilities": "Utilized **SQL** and **Databricks** to design and optimize data pipelines, resulting in a **30%** reduction in data processing time.\nImplemented data warehousing solutions with **Google BigQuery** to enhance data accessibility for stakeholders, leading to improved decision-making.\nDeveloped and orchestrated ETL workflows using **Airflow** and **dbt**, achieving a high level of automation and reducing manual data handling by **40%**.\nEmployed **Docker** and **Kubernetes** for containerization and orchestration of data applications, ensuring seamless deployments and scaling, with **uptime exceeding 99%**.\nApplied data governance strategies to maintain compliance and improve data quality across all data assets.\nDesigned and maintained metadata management frameworks to streamline data lineage and documentation, supporting improved data discovery.\nExecuted schema design and indexing strategies to optimize query performance, reducing average query run time by **20%**.\nCollaborated effectively with cross-functional teams to align project management goals, ensuring timely project delivery and consistent communication.\nFacilitated regular meetings and development sessions to foster teamwork and enhance collaboration within the data engineering team.\nMentored junior engineers, promoting best practices in data modeling and architecture, significantly boosting overall productivity."
    },
    {
      "role": "Software Developer",
      "company": "Grab Holdings Inc",
      "from_date": "Jan 2015",
      "to_date": "Feb 2018",
      "location": "Singapore",
      "responsibilities": "Utilized **SQL** for efficient query optimization and indexing of customer data, improving retrieval speeds by **30%**.\nDesigned and implemented data pipelines using **Airflow** to automate workflows, reducing manual intervention by **50%**.\nDeveloped scalable data warehousing solutions leveraging **Databricks** to support large-scale data processing and analytics, enhancing system capacity by **40%**.\nManaged metadata effectively using best practices for **Data Governance**, ensuring compliance and data integrity across systems.\nCollaborated with cross-functional teams to establish data models and schema designs, improving data accessibility and alignment with project goals.\nImplemented containerization with **Docker** and orchestration using **Kubernetes** to streamline deployment processes for data applications.\nEngaged in project management activities to ensure timely delivery of data solutions while maintaining communication with stakeholders.\nParticipated in regular code reviews and standup meetings to foster collaboration and innovation within the engineering team.\nProvided comprehensive documentation for data governance policies and procedures, enhancing knowledge transfer and operational efficiency.\nLeveraged **Google BigQuery** for advanced analytics and reporting, enabling real-time insights for business decision-making."
    }
  ],
  "skills": "  **Frontend Frameworks**\n\tHTML, CSS, JavaScript, TypeScript, ReactJS, NextJS, VueJS, NuxtJS, Angular, Material UI, Three.js, D3.js, React Native, Flutter, Chakra UI, TailwindCSS\n\n  **Backend Frameworks**\n\tNodeJS, ExpressJS, NestJS, C#, .NET, Entity Framework, Microservices\n\n  **Databases**\n\tMSSQL Server, MySQL, PostgreSQL, MongoDB, DynamoDB, CosmosDB, SQL\n\n  **DevOps**\n\tAWS, Azure, CI/CD pipelines, Docker, Kubernetes\n\n  **API Technologies**\n\tRESTful API, GraphQL\n\n  **Other**\n\tUX/UI Design, Git, GitHub, Python, Redux, Blockchain, Solidity, Ether.js, Web3.js, Ethereum, Data Governance, Data Warehousing, Metadata Management, Data Pipeline, Schema Design, Indexing, Query Optimization, Data Modeling, Project Management, Collaboration, Communication, Apache Kafka, RabbitMQ, Redis, Testing Tools: NUnit, xUnit, Selenium, Moq, Postman, Cypress, JMeter, Jest",
  "apply_company": "team.blue"
}