{
  "name": "Rei Taro",
  "role_name": "Senior Data Engineer",
  "email": "rei515@outlook.com",
  "phone": "+48732529451",
  "address": "Warszawa, Poland",
  "linkedin": "https://www.linkedin.com/in/rei-taro-81a410391/",
  "profile_summary": "Results-driven Senior Data Engineer with over 10 years of experience in backend development and data engineering, proficient in **Python** (FastAPI, Django, Flask), **SQL**, **ETL**, and implementing **REST APIs**. Extensive knowledge of data workflows with **Airflow** and cloud-native solutions using **AWS** and **Kubernetes**. Skilled in web scraping and leveraging machine learning techniques to enhance data-driven decision making, especially within the **sports betting** domain. Demonstrated success in delivering scalable and high-performing data solutions at prominent organizations, while fostering a collaborative environment through strong problem-solving skills and a team-oriented approach.",
  "education": [
    {
      "degree": "Bachelor’s Degree in Computer Science",
      "category": "",
      "from_year": "2010",
      "to_year": "2015",
      "location": "Japan",
      "university": "Keio University"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "Leobit",
      "from_date": "Aug 2022",
      "to_date": "Present",
      "location": "Poland",
      "responsibilities": "Utilized **Python** and **SQL** to build robust ETL processes that streamline data extraction and transformation for analytics in the sports betting domain.\nEngineered scalable data workflows with **Apache Airflow** to ensure efficient scheduling and monitoring of data pipelines; managed over **50** data tasks weekly.\nImplemented REST APIs for seamless integration of data sources, improving data accessibility by **40%** across departments.\nLeveraged **Kubernetes** for container orchestration, enabling automated deployment and scaling of microservices, achieving a **30%** reduction in deployment times.\nEmployed **git** for version control and collaborative project management, facilitating team-oriented development practices.\nConducted web scraping and machine learning techniques to derive actionable insights from sports data, enhancing prediction accuracy by **25%**.\nProactively solved data-related problems and collaborated with cross-functional teams to ensure timely delivery and adherence to compliance standards, consistently meeting project timelines."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Innovature",
      "from_date": "Nov 2018",
      "to_date": "Jun 2022",
      "location": "Japan",
      "responsibilities": "• Developed backend systems in **Python** and **FastAPI** to automate document workflows, streamline user onboarding, and handle complex reporting processes, resulting in a **30%** reduction in manual processing time.\n• Created event-driven microservices using **Celery** and **Redis**, enabling asynchronous processing of financial data and transaction requests, improving data handling efficiency by **40%**.\n• Managed the deployment of microservices on **Azure App Services** leveraging **Terraform** for infrastructure automation to maintain consistent and scalable environments with over **99.9%** uptime.\n• Engineered data pipelines for the secure exchange of regulatory data, using **Apache Airflow** and **Azure Functions** to automate and streamline the data flow, reducing operational bottlenecks by **25%**.\n• Performed security audits, ensuring compliance with industry standards, and integrated **OAuth2** and **Azure AD B2C** to manage authentication and secure access controls, significantly enhancing system security.\n• Collaborated with cross-functional teams to ensure smooth system integration, regulatory compliance, and successful release management, participating in **weekly sprints** to track progress and resolve issues rapidly."
    },
    {
      "role": "Software Developer",
      "company": "Wizcorp",
      "from_date": "Apr 2015",
      "to_date": "Nov 2018",
      "location": "Japan",
      "responsibilities": "Utilized **Python** and **SQL** to develop backend services for trade execution, portfolio management, and account tracking, enhancing trading operations by processing over **10,000** transactions per minute.\nImplemented **ETL** processes using **Airflow**, ensuring seamless data integration and transformation, contributing to a **25%** improvement in data retrieval efficiency.\nEngineered real-time price feed processors with **asyncio**, **WebSockets**, and **Redis**, delivering up-to-the-minute trading data for high-frequency transactions with less than **1 second** latency.\nCollaborated closely with frontend teams to deliver data via **REST APIs** and **WebSocket channels**, ensuring smooth user interaction with the platform and supporting **500+** simultaneous users.\nEnsured compliance with regulatory requirements including MiFID II and GDPR while adhering to internal data security protocols, minimizing potential risks.\nImplemented comprehensive test suites using **PyTest**, **tox**, and mock servers, streamlining QA and CI processes for efficient development cycles contributing to a **30%** reduction in bugs.\nIntroduced job queuing and scheduling solutions using **Celery** and **RabbitMQ**, optimizing backend task execution and process management, resulting in faster processing times by **40%**."
    }
  ],
  "skills": "**Programming Languages**\n\tPython, SQL\n\n**Backend Frameworks**\n\tFastAPI, Flask, Django, Celery\n\n**Frontend Frameworks**\n\tJavaScript\n\n**API Technologies**\n\tREST APIs, REST/gRPC APIs\n\n**Serverless and Cloud Functions**\n\tAWS (EC2, S3, Lambda)\n\n**Databases**\n\tPostgreSQL, MySQL, MongoDB, Redis\n\n**DevOps**\n\tDocker, Kubernetes, GitHub Actions, Azure DevOps, git, CI/CD\n\n**Cloud & Infrastructure**\n\tAzure\n\n**Other**\n\tAirflow, MLflow, Pandas, NumPy, scikit-learn, TensorFlow, Microservices, Kafka, web scraping, machine learning, data science, sports betting, team-oriented, problem-solving, PyTest",
  "apply_company": "Swish Analytics"
}