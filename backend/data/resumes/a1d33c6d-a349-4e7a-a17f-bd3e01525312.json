{
  "name": "Mariusz Jan Skobel",
  "role_name": "Senior Apache Spark Developer",
  "email": "mariuszskobel15@outlook.com",
  "phone": "+48 735 343 548",
  "address": "Katowice, Poland",
  "linkedin": "https://www.linkedin.com/in/mariusz-skobel-789557397/",
  "profile_summary": "Senior Apache Spark Developer with 10+ years of comprehensive experience in delivering high-performance software solutions within the healthcare and finance sectors. Proficient in **Apache Spark**, **Kafka**, and **Hive**, with significant expertise in **Scala**, **Java**, and **Python**. Adept at building scalable architectures and optimizing performance in distributed computing environments. Demonstrated ability in streaming analytics using **Spark Structured Streaming** and **Spark SQL**, employing RDDs and DataFrames for efficient data processing and system integration.\n\nExperienced in the deployment of cloud-native applications on **Azure** and **AWS**, while leading the development of enterprise platforms that leverage AI/ML for real-time analytics and automation. Strong background in microservices architecture and CI/CD automation, ensuring compliance with standards such as HIPAA, FHIR, PCI DSS, and SOC 2. Possesses hands-on knowledge of MLOps to develop ML pipelines and manage production workflows utilizing tools like **MLflow**, **Airflow**, and **Kubeflow**. Committed to creating technically robust systems that drive sustainable real-world impact.",
  "education": [
    {
      "degree": "Bachelor’s Degree",
      "category": "Computer Science",
      "from_year": "2012",
      "to_year": "2015",
      "location": "UK",
      "university": "University of Bristol"
    }
  ],
  "experience": [
    {
      "role": "Senior Apache Spark Developer",
      "company": "EitBiz",
      "from_date": "Oct 2022",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "• Developed and optimized **Apache Spark** applications for processing large-scale datasets in financial and healthcare domains, leveraging **Spark SQL**, **RDDs**, and **DataFrames** for efficient data manipulation and analysis.\n• Implemented **performance optimization** strategies to enhance the processing speed and resource utilization of scalable architecture, achieving a **30%** improvement in job efficiency.\n• Collaborated effectively in a team environment, utilizing **Java** and **Python** to build data pipelines integrating with **Kafka** for real-time data streaming and operational processing.\n• Designed architectures employing **Hive** and **Iceberg** for data storage and access, providing seamless integration with existing data ecosystems.\n• Conducted in-depth analysis and interpretation of streaming analytics, utilizing **Spark Structured Streaming** to deliver actionable insights in near real-time, improving decision-making capabilities by **25%**.\n• Ensured successful deployment of distributed computing solutions, focusing on **system integration** and maintaining high data quality standards across applications.\n• Engaged in continuous learning and knowledge sharing about new features and best practices in **Apache Spark**, contributing to a more knowledgeable and skilled development team."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Tvn S.A.",
      "from_date": "Oct 2019",
      "to_date": "Sep 2022",
      "location": "Poland",
      "responsibilities": "Implemented **Apache Spark** solutions for performance optimization and scalable architecture in financial applications, enhancing processing throughput by **30%** over legacy systems.\nDeveloped data ingestion and transformation strategies using **Kafka** and **Apache Spark Structured Streaming**, enabling real-time analytics capabilities and improving operational efficiency by **25%**.\nDesigned and built interactive dashboards using **Python**, **D3.js**, and **Power BI**, facilitating data visualization and actionable insights for financial transaction monitoring.\nCollaborated with cross-functional teams to integrate **Hive** and **Iceberg** for managing large datasets, ensuring efficient querying and data retrieval operations, reducing response times by **40%**.\nLeveraged **Scala** and **Java** to optimize existing data pipelines and workflows for distributed computing, resulting in improved resource utilization across the architecture.\nEnhanced system integration and deployment processes utilizing **Apache Spark SQL**, ensuring seamless data flow between various system components while adhering to compliance and regulatory standards.\nDeveloped user-friendly front-end applications with **React** and **TypeScript**, maintaining performance standards that resulted in a **20%** increase in user engagement across financial dashboards.\nConducted performance tuning and optimization of Spark jobs and data processing functions, significantly boosting application responsiveness and efficiency."
    },
    {
      "role": "Software Engineer",
      "company": "Timspark",
      "from_date": "Sep 2015",
      "to_date": "Aug 2019",
      "location": "UK",
      "responsibilities": "Engineered scalable architecture and optimized performance for big data applications using **Apache Spark**, **Scala**, and **Java**, ensuring high throughput and low latency for processing large datasets.\nDeveloped real-time streaming analytics solutions leveraging **Spark Structured Streaming** and **Kafka**, facilitating dynamic data processing and enabling near real-time analytics for business insights.\nDesigned and implemented distributed computing frameworks utilizing **RDDs** and **DataFrames**, which improved data processing efficiency by up to **30%**.\nIntegrated data storage solutions with **Hive** and **Iceberg**, ensuring effective schema management and optimized query performance across diverse datasets.\nApplied performance optimization techniques for complex calculations and data transformations, achieving a reduction of processing time by more than **40%** on key workflows.\nExecuted deployment strategies that enhanced system integration, utilizing methodologies such as continuous integration and deployment, which have led to a **50%** decrease in deployment time.\nCollaborated in cross-functional teams to improve system efficiencies and promote best practices in coding, testing, and documentation, enhancing team productivity and collaboration.\nProvided technical leadership and mentorship in **Python** development practices for backend systems, ensuring code quality and adherence to best practices throughout the development lifecycle.\nCommunicated effectively in English with stakeholders to gather requirements and align project goals, facilitating a smoother project execution and delivery process."
    }
  ],
  "skills": "Programming Languages:\n\tJava, Python, Scala\n\n**Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n**Frontend Frameworks:**\n\tJavaScript/TypeScript (React, Vue, Angular)\n\n**API Technologies:**\n\tJWT, OAuth2\n\n**Serverless and Cloud Functions:**\n\tAWS (ECS, Lambda, RDS, S3), Azure (App Services, Blob, SQL)\n\n**Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare), MongoDB (Gaming), Redis\n\n**DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, Terraform, Ansible, Helm, Docker Compose\n\n**Cloud & Infrastructure:**\n\tNginx, Certbot\n\n**Other:**\n\tArtificial Intelligence & Machine Learning: MLflow, Airflow, Kubeflow; Apache Spark, Kafka, Hive, Iceberg, distributed computing, performance optimization, scalable architecture, streaming analytics, Spark Structured Streaming, Spark SQL, RDDs, DataFrames, system integration, deployment, English"
}