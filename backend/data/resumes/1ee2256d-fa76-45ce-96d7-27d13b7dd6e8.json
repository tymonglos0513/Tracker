{
  "name": "Marcin Karol Kotlinski",
  "role_name": "Analytics Engineer",
  "email": "marcinkot55@outlook.com",
  "phone": "+48 732 779 243",
  "address": "Zgorzelec, Poland",
  "linkedin": "https://www.linkedin.com/in/marcin-karol-kotlinski-bb2520397/",
  "profile_summary": "As an Analytics Engineer with 8 years of experience, I am proficient in key data engineering and analytics skills including **SQL**, **dbt**, **Data Vault**, **dimensional modelling**, **ELT**, and **Snowflake**. I have a proven track record of designing and implementing high-performance data solutions across the healthcare and financial sectors, utilizing data visualization tools like **Looker**, **Tableau Software**, **Qlik**, and **Power BI** to enhance data-driven decision-making.\nIn addition to my technical expertise, I possess strong communication skills and fluency in both French and English, allowing me to effectively collaborate in diverse and agile environments. I am a self-starter with a solid foundation in best practices for data management and analytics, focusing on delivering value through action-oriented insights and analytics. My background includes full-stack development with **React**, **Node.js**, and comprehensive cloud experience with **Azure** and **AWS**, enhancing my capability to engage in data-focused projects that integrate modern technologies.",
  "education": [
    {
      "degree": "Master’s Degree in Computer Science",
      "category": "",
      "from_year": "2017",
      "to_year": "2018",
      "location": "UK",
      "university": "University of Oxford"
    },
    {
      "degree": "Bachelor’s Degree in Computer Science",
      "category": "",
      "from_year": "2015",
      "to_year": "2017",
      "location": "UK",
      "university": "University of Oxford"
    }
  ],
  "experience": [
    {
      "role": "Analytics Engineer",
      "company": "EVNE Developers",
      "from_date": "Oct 2023",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "Utilized **SQL** and **dbt** to design robust data models and data pipelines, ensuring reliable data ingestion, transformation, and analytics for large-scale health and finance datasets.\nImplemented **dimensional modelling** techniques and **Data Vault** strategies to maintain historical accuracy and streamline analytics processes, enhancing reporting efficiencies by **30%**.\nCollaborated with cross-functional teams in an **agile environment** to develop analytics solutions that meet stakeholder needs, leveraging strong **communication skills** to articulate complex data insights in both **French** and **English**.\nEstablished and maintained data visualization dashboards using **Looker**, **Tableau**, and **Power BI**, providing actionable insights on KPIs and business trends for the executive team.\nPartnered with data analysts to conduct thorough data analysis and modeling projects, ensuring a seamless integration of analytics tools into existing workflows using technologies like **Snowflake** and **Qlik**.\nImplemented an ELT strategy utilizing **Snowflake** for efficient data processing, resulting in a reduction of data loading times by **25%**.\nConducted training sessions on analytical tools and data interpretation, fostering a culture of data-driven decision-making across the organization.\nUtilized **Git** for version control, ensuring collaboration and traceability in analytics projects, while acting as a **self-starter** to initiate and drive continuous improvement initiatives."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Air Force",
      "from_date": "Oct 2021",
      "to_date": "Sep 2023",
      "location": "Poland",
      "responsibilities": "Utilized **SQL** to enhance data querying and analysis, supporting decision-making for financial platforms and improving data accessibility.\nEmployed **dbt** to create robust data models and automate transformations, ensuring consistency and reliability in data workflows.\nDesigned and implemented **Data Vault** architecture, facilitating historical data tracking and scalability of financial data analytics.\nExecuted **dimensional modelling** techniques to optimize reporting and analysis, improving end-user interactions with data.\nManaged **ELT** processes to streamline data ingestion and transformation, resulting in a more efficient analytics pipeline.\nVersion-controlled projects using **Git** to collaborate effectively within an **agile environment**, assuring continuous integration and delivery of features.\nDeveloped interactive dashboards and reports with **Looker**, **Power BI**, and **Tableau Software**, enhancing data visualization and business insights across financial metrics.\nLeveraged **Snowflake** for data warehousing, significantly reducing data retrieval times by up to **50%** and supporting high-volume queries.\nUtilized **Power BI** and **Qlik** for creating comprehensive analytical reports, enabling stakeholders to derive actionable insights from complex datasets.\nCommunicated effectively in both **French and English**, ensuring clarity and collaboration with diverse teams and stakeholders.\nDemonstrated strong **communication skills** while presenting data findings and recommendations to both technical and non-technical audiences.\nActed as a **self-starter**, leading initiatives in project's analytical strategies and processes, contributing to team success and project outcomes."
    },
    {
      "role": "Software Engineer",
      "company": "DeepInspire",
      "from_date": "Sep 2018",
      "to_date": "Aug 2021",
      "location": "UK",
      "responsibilities": "Utilized **SQL** to craft and optimize complex queries for data extraction and reporting, ensuring accurate and timely insights across analytics platforms.\nDesigned and implemented data pipelines using **dbt** with **Snowflake**, facilitating seamless ELT processes and enabling dimensional modeling for improved data utilization.\nDeveloped and maintained interactive dashboards and reports with **Tableau Software**, **Looker**, and **Power BI**, empowering stakeholders with actionable insights through visual data storytelling.\nCollaborated in an agile environment to refine data processes and workflows, ensuring continuous improvement and adoption of best practices in analytics.\nCommunicated effectively in both **French** and **English**, fostering collaboration across diverse teams and enhancing project success through clear delivery of complex data concepts.\nWorked on enhancing data accessibility and reporting across multiple tools, including **Qlik**, to support data-driven decision-making processes.\nDemonstrated expertise as a self-starter by independently managing projects from conception to implementation, ensuring alignment with business objectives and delivering results within deadlines.\nLeveraged **Git** for version control and collaborative development, ensuring code quality and streamlined teamwork throughout the project lifecycle."
    }
  ],
  "skills": " **Backend Frameworks:**\n\tPython(FastAPI, Flask, Django)\n\n**Frontend Frameworks:**\n\tJavaScript/TypeScript (React, Vue, Angular)\n\n**Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare), MongoDB (Gaming), Redis, SQL, Snowflake\n\n**DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD\n\n**Cloud & Infrastructure:**\n\tAWS (ECS, Lambda, RDS, S3), Azure (App Services, Blob, SQL), Terraform, Ansible, Helm, Docker Compose\n\n**API Technologies:**\n\tKeycloak (OIDC, RBAC), JWT, OAuth2, Let’s Encrypt, Nginx, Certbot\n\n**Other:**\n\tMLflow, Airflow, Kubeflow, dbt, Data Vault, dimensional modelling, ELT, Git, Looker, Tableau Software, Qlik, Power BI, fluency in French and English, communication skills, agile environment, self-starter"
}