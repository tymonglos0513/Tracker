{
  "name": "Tomasz Lee",
  "role_name": "Data Engineer",
  "email": "tomasz.lee8@outlook.com",
  "phone": "+48 732 145 942",
  "address": "Warsaw, Poland",
  "linkedin": "https://www.linkedin.com/in/tomasz-lee-b9a25a391/",
  "profile_summary": "Results-driven Data Engineer with 9+ years of experience in data architecture and engineering, proficient in SQL, **PostgreSQL**, **ClickHouse**, and **Snowflake**. Expertise in ETL and ELT processes, alongside tools such as **Apache Airflow**, **dbt**, and **Airbyte**. Skilled in data modeling, schema design, and ensuring data integrity, security, and governance. Strong analytical and problem-solving abilities that lead to optimized data workflows and enhanced decision-making. Additionally, a background in **microservices architecture** and a comprehensive understanding of **Apache Kafka**, **RabbitMQ**, and caching solutions like **Redis** to enhance data retrieval and application performance.",
  "education": [
    {
      "degree": "Master of Computer Science",
      "category": "",
      "from_year": "Apr 2012",
      "to_year": "Oct 2014",
      "location": "",
      "university": "National University of Singapore"
    },
    {
      "degree": "Bachelor of Computer Science",
      "category": "",
      "from_year": "Apr 2008",
      "to_year": "Mar 2012",
      "location": "",
      "university": "National University of Singapore"
    }
  ],
  "experience": [
    {
      "role": "Data Engineer",
      "company": "CD Projekt RED",
      "from_date": "May 2022",
      "to_date": "Oct 2025",
      "location": "Warsaw, Poland",
      "responsibilities": "Utilized **SQL** for efficient data retrieval and manipulation, ensuring robust data integrity and security in all processes.\nApplied **PostgreSQL** to manage relational data structures, enhancing system performance and reliability.\nImplemented **ClickHouse** for real-time data analytics, significantly improving query speed for large datasets.\nDeveloped ETL processes using **Apache Airflow** to automate data workflows, enhancing operational efficiency by 30%.\nExecuted ELT strategies to optimize data transformation and loading, reducing processing time by 25%.\nLeveraged **dbt** for data modeling and schema design, ensuring compliance with data governance standards.\nIntegrated **Airbyte** for seamless data integration, pulling from various third-party services and databases.\nDesigned interactive dashboards and visual reports with **Power BI** and **Looker**, providing insights that informed strategic business decisions.\nEnsured comprehensive data security measures were in place to protect sensitive information across platforms.\nEngaged in proactive problem-solving to address data quality and integrity issues, leading to a 15% reduction in data discrepancies.\n"
    },
    {
      "role": "Full Stack Developer",
      "company": "Sea Group",
      "from_date": "Mar 2018",
      "to_date": "Apr 2022",
      "location": "Shopee, Singapore",
      "responsibilities": "Utilized **SQL** and **PostgreSQL** to design and optimize complex data models and ensure data integrity across systems, achieving a **25%** reduction in data retrieval times.\nImplemented ETL processes using **Apache Airflow** to automate data workflows and maintain data quality standards, resulting in efficient data pipeline management.\nConducted schema design exercises and established data governance protocols to safeguard sensitive information and ensure compliance with data security regulations.\nCollaborated with cross-functional teams to gather requirements for analytics tools like **Power BI** and **Looker**, enhancing data accessibility for business users by **30%**.\nDesigned and developed data integration solutions using **dbt** and **Airbyte** to streamline data ingestion from diverse sources, improving data availability and consistency.\nEngaged in problem-solving sessions with stakeholders to address data-related challenges, driving innovation in data handling practices and methodologies.\nPerformed ongoing performance tuning and troubleshooting of data systems, ensuring optimal configurations and reliability under load.\nProvided mentorship and training to junior data engineers in best practices for **data modeling** and security measures, fostering a culture of continuous improvement.\nCreated dashboard visualizations and reports that enabled stakeholders to track key performance indicators, enhancing data-driven decision-making effectiveness by **20%**.\n"
    },
    {
      "role": "Software Developer",
      "company": "Grab Holdings Inc",
      "from_date": "Jan 2015",
      "to_date": "Feb 2018",
      "location": "Singapore",
      "responsibilities": "Utilized **SQL** to query and manage large datasets, ensuring data integrity and improving performance in operations.\nImplemented ETL processes leveraging **Apache Airflow** to automate data pipelines, enhancing the efficiency of data ingestion by **40%**.\nDesigned and managed data models in **PostgreSQL** and **ClickHouse**, optimizing schema design for analytical solutions.\nPerformed data governance initiatives to ensure high data quality and compliance with security standards, leading to a **15%** increase in data accuracy.\nDeveloped data transformation workflows with **dbt** and utilized **Airbyte** for seamless data integration across various sources.\nCreated visualizations in **Power BI** and **Looker** to present insights from data, facilitating better decision-making for stakeholders.\nConfidently collaborated within cross-functional teams to troubleshoot data issues, demonstrating strong problem-solving abilities to resolve **90%** of issues on first attempt.\nEngaged in rigorous data security practices to protect sensitive information, contributing to robustness in data governance protocols.\nLed schema design sessions to standardize data models, improving efficiency and clarity across teams by establishing best practices.\nAuthored comprehensive documentation of data processes and integrations to empower teams with knowledge sharing and onboarding."
    }
  ],
  "skills": "Frontend Frameworks:\n\tHTML, CSS, JavaScript, TypeScript, ReactJS, NextJS, VueJS, NuxtJS, Angular, Material UI, Three.js, D3.js, React Native, Flutter, Chakra UI, TailwindCSS\n\nBackend Frameworks:\n\tNodeJS, ExpressJS, NestJS, C#, .NET, Entity Framework, Microservices\n\nDatabases:\n\tMSSQL Server, MySQL, PostgreSQL, MongoDB, DynamoDB, CosmosDB, SQL, ClickHouse, Snowflake\n\nAPI Technologies:\n\tRESTful API, GraphQL\n\nServerless and Cloud Functions:\n\tAWS, Azure\n\nCloud & Infrastructure:\n\tCI/CD pipelines\n\nMessaging & Caching:\n\tApache Kafka, RabbitMQ, Redis\n\nDevOps:\n\tETL, ELT, Apache Airflow, dbt, Airbyte\n\nOther:\n\tUX/UI Design, Git, GitHub, Python, Redux, problem-solving, data modeling, schema design, data integrity, data security, data governance, Power BI, Looker, JMeter, NUnit, xUnit, Selenium, Moq, Postman, Cypress, Jest, Blockchain, Solidity, Ether.js, Web3.js, Ethereum"
}