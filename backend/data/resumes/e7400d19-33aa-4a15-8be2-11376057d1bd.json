{
  "name": "Damian Franciszek Pospiech",
  "role_name": "Senior Software Engineer",
  "email": "damianpos127@outlook.com",
  "phone": "+48 732 143 608",
  "address": "Mikolow, Poland",
  "linkedin": "https://www.linkedin.com/in/damian-pospiech-261821397/",
  "profile_summary": "Results-driven Senior Software Engineer with 13+ years of experience specializing in **Python**, **SQL**, **DBT**, and **Airflow** for advanced data engineering solutions. Proven ability in data modeling, ETL processes, and building robust data warehousing systems. Expert in developing and managing APIs to streamline data accessibility and efficiency.\nDemonstrated success in utilizing **Lean** and **Agile** methodologies to enhance team performance and ensure quality deliverables. Adept in fostering teamwork, while maintaining effective communication and a strong sense of autonomy.\nPassionate about applying critical thinking and empathy in collaborative environments, contributing to the development of high-performance applications in the healthcare and financial sectors. Additionally skilled in **JavaScript/TypeScript**, **Flutter**, **React**, **Next.js**, **Vue**, **Node.js**, **FastAPI**, and **Django**, with hands-on experience in microservices and cloud-native deployment on **AWS** and **Azure**.",
  "education": [
    {
      "degree": "Bachelor's degree in Computer Science",
      "category": "Computer Science",
      "from_year": "2007",
      "to_year": "2012",
      "location": "UK",
      "university": "University of Cambridge"
    }
  ],
  "experience": [
    {
      "role": "Senior Software Engineer",
      "company": "Codebridge",
      "from_date": "Apr 2021",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "Utilized **Python** and **SQL** for advanced data modeling and ETL processes, ensuring efficient data flow and transformation in data warehousing environments.\nImplemented **Airflow** for managing and orchestrating complex data pipelines that supported various analytics and reporting needs, consistently meeting project timelines.\nDesigned and developed robust APIs for data access and manipulation, following best practices in Agile methodologies to enhance collaboration and communication within cross-functional teams.\nEngaged in Lean strategies to optimize workflows and eliminate waste, resulting in a **30%** increase in team productivity over the past year.\nExhibited autonomy and proactivity by identifying and resolving data quality issues, fostering a culture of continuous improvement within the software engineering team.\nDemonstrated critical thinking skills when designing solutions that align with user needs and business objectives, while employing empathy and active listening to gather feedback effectively from stakeholders.\nSpearheaded the integration of third-party tools to enhance data visualization capabilities, enabling real-time insights and informed decision-making across the organization.\nCollaborated effectively with other software engineers and data scientists to create and deploy machine learning models, contributing to projects that achieved significant business impact.\nConducted regular code reviews and mentoring sessions, promoting teamwork and knowledge sharing to elevate overall team performance and code quality.\nLed initiatives to enhance documentation and communication practices, ensuring that all technical materials were accessible and comprehensible to both technical and non-technical team members."
    },
    {
      "role": "Software Engineer",
      "company": "Grupa Azoty",
      "from_date": "Oct 2015",
      "to_date": "Mar 2021",
      "location": "Poland",
      "responsibilities": "Utilized **Python** to develop ETL pipelines, enhancing data integration from internal and third-party financial sources, and supporting **real-time** and **batch processing** operations through **Apache Airflow** (version 2.0) for efficient data handling.\nDesigned comprehensive data models and optimized **SQL** queries for data warehousing solutions, ensuring high performance and accuracy in data retrieval and manipulation.\nImplemented robust APIs, following **Agile** methodologies to ensure iterative development and delivery of financial software solutions, fostering **teamwork** and effective **communication** throughout the project lifecycle.\nLed the migration of legacy systems to microservices using **Node.js** (NestJS/Express) and **Python** (FastAPI, Django), improving scalability and performance for high-volume transactions by over **50%**.\nBuilt interactive front-end applications with **React** (18), **Vue 3**, **Next.js**, and **TypeScript**, leveraging **Redux Toolkit** and **Tailwind CSS** for responsiveness and user engagement, resulting in an increase in user retention by **30%**.\nCreated and maintained data pipelines for analytics, enabling real-time reporting and insights through **Power BI Embedded** and **D3.js**, enhancing operational efficiency by providing instant access to critical data insights.\nFostered a proactive development culture by utilizing **Lean** principles, applying critical thinking to problem-solving and encouraging **autonomy** within the engineering team, leading to a **25%** reduction in incident resolution time.\nCollaborated in the development of machine learning models for fraud detection, incorporating **XGBoost**, **scikit-learn**, and leveraging **Azure ML** for deployment, resulting in a **40%** reduction in fraud incidents."
    },
    {
      "role": "Software Engineer",
      "company": "GoodCore",
      "from_date": "Jan 2012",
      "to_date": "Sep 2015",
      "location": "UK",
      "responsibilities": "Leveraged **Python** for backend development, implementing ETL processes and data modeling to support efficient data workflows in a senior engineering capacity.\nDeveloped robust **APIs** to facilitate data access and integration with various modules, emphasizing high performance and reliability.\nDesigned and maintained data warehousing solutions, ensuring optimized data storage and retrieval strategies using **SQL** while employing **DBT** for data transformation workflows.\nCollaborated effectively within an **Agile** team environment, utilizing **Lean** methodologies to drive continuous improvement and accelerate project delivery.\nDemonstrated autonomy and proactivity by leading the design of scalable data pipelines with **Airflow**, enhancing system efficiency and streamlining ETL processes across multiple projects.\nEngaged in critical thinking and problem-solving to optimize application performance, leveraging teamwork and active listening skills to incorporate feedback and address requirements.\nUtilized effective communication to relay complex technical concepts to non-technical stakeholders, ensuring alignment on project goals and timelines.\nFostered a culture of collaboration through regular knowledge sharing sessions, contributing to team development and enhancing overall project outcomes."
    }
  ],
  "skills": " **Programming Languages:**\n\tPython, SQL\n\n**Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n**Frontend Frameworks:**\n\tJavaScript/TypeScript: React, Vue, Angular\n\n**API Technologies:**\n\tAPIs\n\n**Serverless and Cloud Functions:**\n\tAWS: ECS, Lambda, RDS, S3\n\tAzure: App Services, Blob Storage, SQL Database\n\n**Databases:**\n\tPostgreSQL (Fintech), MySQL (Healthcare)\n\tMongoDB (Gaming), Redis\n\n**DevOps:**\n\tDocker, Kubernetes\n\tGitHub Actions, GitLab CI/CD\n\tTerraform, Ansible, Helm, Docker Compose\n\n**Cloud & Infrastructure:**\n\tAWS, Azure\n\n**Other:**\n\tMLflow, Airflow, Kubeflow\n\tDBT\n\tData Modeling\n\tETL\n\tData Warehousing\n\tLean\n\tAgile\n\tTeamwork\n\tCommunication\n\tAutonomy\n\tProactivity\n\tCritical Thinking\n\tEmpathy\n\tActive Listening\n\tKeycloak (OIDC, RBAC), OAuth2, JWT\n\tNginx, Letâ€™s Encrypt, Certbot",
  "apply_company": "Clarity AI"
}