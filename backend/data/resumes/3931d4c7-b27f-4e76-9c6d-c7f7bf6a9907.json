{
  "name": "Rei Taro",
  "role_name": "AI Engineer",
  "email": "rei515@outlook.com",
  "phone": "+48732529451",
  "address": "Warszawa, Poland",
  "linkedin": "https://www.linkedin.com/in/rei-taro-81a410391/",
  "profile_summary": "Results-driven AI Engineer with over 10 years of backend development experience, specializing in **AI systems**, **LLM production**, and **large data pipelines**. Proficient in **Python** (FastAPI, Django, Flask) and **TypeScript**, with a strong focus on building and integrating **high-performing APIs** while leveraging cloud services such as **AWS**. Demonstrated ability in **model evaluation**, **document automation**, and managing **distributed systems**. Skilled in orchestrating complex workflows with **orchestration frameworks** and optimizing data strategies using **vector databases** and **embeddings**. Proven success in executing impactful projects across renowned firms like VISA, Sii Poland, and Reply Polska.",
  "education": [
    {
      "degree": "Bachelor’s Degree in Computer Science",
      "category": "",
      "from_year": "2010",
      "to_year": "2015",
      "location": "Japan",
      "university": "Keio University"
    }
  ],
  "experience": [
    {
      "role": "AI Engineer",
      "company": "Leobit",
      "from_date": "Aug 2022",
      "to_date": "Present",
      "location": "Poland",
      "responsibilities": "Engineered AI systems to optimize **LLM production** workflows, leveraging **Python** for backend integrations and **APIs** for data access.\nDeveloped document automation solutions incorporating **OCR** technologies, enhancing data processing efficiency by **30%**.\nUtilized **TypeScript** and **React** to build intuitive front-end applications that interact seamlessly with backend services.\nImplemented model evaluation techniques to fine-tune algorithms, improving performance metrics by **15%**.\nDesigned and orchestrated **large data pipelines** utilizing **Apache Airflow** and **AWS**, ensuring robust data flow management across distributed systems.\nIntegrated **vector databases** and **embeddings** to enhance search and retrieval functionalities within AI applications.\nCollaborated with cross-functional teams to address AI system integration challenges and ensure compliance with industry standards."
    },
    {
      "role": "Senior Software Engineer",
      "company": "Innovature",
      "from_date": "Nov 2018",
      "to_date": "Jun 2022",
      "location": "Japan",
      "responsibilities": "Utilized **Python** and **APIs** to develop and automate document workflows, enhancing user onboarding processes and streamlining reporting functionalities.\nImplemented **AI systems** and **LLM Production** techniques to create intelligent document automation solutions, achieving a **30%** reduction in processing time.\nEngineered event-driven microservices using **Redis** and **Celery** to facilitate asynchronous processing of financial data and transaction requests, resulting in improved system responsiveness by **40%**.\nManaged deployment of applications on **AWS** and **Azure App Services**, applying **Terraform** for infrastructure automation to maintain a consistent environment across **3 different project deployments**.\nDesigned and orchestrated **large data pipelines** with **Apache Airflow** and **Azure Functions**, enabling the secure exchange of regulatory data and boosting data flow efficiency by **25%**.\nConducted comprehensive security audits, ensuring compliance with industry standards, while integrating **OAuth2** and **Azure AD B2C** for robust authentication and access control mechanisms.\nCollaborated with cross-functional teams to ensure successful integration of systems, regulatory compliance, and efficient management of releases, contributing to a **100%** on-time project delivery rate."
    },
    {
      "role": "Software Developer",
      "company": "Wizcorp",
      "from_date": "Apr 2015",
      "to_date": "Nov 2018",
      "location": "Japan",
      "responsibilities": "• Developed AI systems leveraging **Python** and **TypeScript** to enhance model evaluation and document automation, ensuring robust performance metrics.\n• Engineered large data pipelines utilizing **AWS** services to facilitate efficient orchestration of distributed systems, optimizing data flow and processing.\n• Created and integrated REST APIs for seamless communication between backend services and frontend frameworks like **React**, ensuring a user-friendly experience.\n• Implemented advanced vector databases and embeddings techniques to improve the search and retrieval capabilities of AI models.\n• Introduced job queuing solutions using **Celery** and **RabbitMQ** to manage backend tasks efficiently and support large-scale data operations.\n• Collaborated with cross-functional teams to deliver production-ready LLM solutions while ensuring compliance with internal protocols and regulatory standards.\n• Conducted extensive public contributions and code reviews to maintain high code quality and facilitate knowledge sharing across teams.\n• Developed comprehensive test suites using **PyTest** and mock servers, resulting in a **30%** reduction in bugs and enhancing CI/CD processes."
    }
  ],
  "skills": " **Programming Languages**\n\tPython, TypeScript, SQL, Bash, JavaScript\n\n**Backend Frameworks**\n\tFastAPI, Flask, Django, Celery\n\n**Frontend Frameworks**\n\tReact\n\n**API Technologies**\n\tREST/gRPC APIs, APIs\n\n**Serverless and Cloud Functions**\n\tAWS (EC2, S3, Lambda)\n\n**Databases**\n\tPostgreSQL, MySQL, MongoDB, Redis, Vector databases\n\n**DevOps**\n\tDocker, Kubernetes, GitHub Actions, Azure DevOps, CI/CD\n\n**Cloud & Infrastructure**\n\tAzure\n\n**Other**\n\tAI systems, LLM Production, Model evaluation, Document automation, Embeddings, Orchestration frameworks, Large data pipelines, Distributed systems, Kafka, PyTest, Git, OCR, Public contributions"
}