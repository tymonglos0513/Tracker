{
  "name": "Tomasz Lee",
  "role_name": "Senior AI Engineer",
  "email": "tomasz.lee8@outlook.com",
  "phone": "+48 732 145 942",
  "address": "Warsaw, Poland",
  "linkedin": "https://www.linkedin.com/in/tomasz-lee-b9a25a391/",
  "profile_summary": "Results-driven Senior AI Engineer with 9+ years of comprehensive experience in data engineering and machine learning (ML), proficient in implementing complex applications using **Python**, **TensorFlow**, **PyTorch**, and **LangChain**. Expertise in **AWS** and **GCP** cloud services, coupled with a deep understanding of LLM and MLOps practices. Experienced in designing ETL and ELT processes, utilizing tools like **dbt** and **Airflow** for effective data pipeline management. Skilled in fostering collaboration and communication across teams, while mentoring junior developers to drive innovation. Proven track record in optimizing performance via robust solutions and streamlining development processes in distributed systems.",
  "education": [
    {
      "degree": "Master of Computer Science",
      "category": "",
      "from_year": "Apr 2012",
      "to_year": "Oct 2014",
      "location": "",
      "university": "National University of Singapore"
    },
    {
      "degree": "Bachelor of Computer Science",
      "category": "",
      "from_year": "Apr 2008",
      "to_year": "Mar 2012",
      "location": "",
      "university": "National University of Singapore"
    }
  ],
  "experience": [
    {
      "role": "Senior AI Engineer",
      "company": "CD Projekt RED",
      "from_date": "May 2022",
      "to_date": "Oct 2025",
      "location": "Warsaw, Poland",
      "responsibilities": "Leveraged **Python** and **TensorFlow** to develop and deploy machine learning models, increasing predictive accuracy by 30%.\nDesigned and implemented MLOps pipelines on **AWS** and **GCP**, facilitating integration and deployment of multiple models with a 25% reduction in time to production.\nUtilized **Kafka** for efficient data streaming, improving data ingestion rates by 40% and ensuring real-time analytics capabilities.\nCreated ETL and ELT processes using **Airflow** and **dbt**, optimizing data transformation and loading workflows, resulting in a throughput increase of 50%.\nCollaborated effectively with cross-functional teams to redefine project scopes and deliverables, ensuring alignment with business objectives and achieving project completion rates of 95% on time.\nMentored junior engineers and data scientists on best practices in machine learning and data engineering, resulting in enhanced team productivity and skill development.\nEmployed **ML frameworks** such as **PyTorch** and **LangChain** for advanced model training and inference, resulting in a deployment model with an efficiency improvement of 35%.\nImplemented robust CI/CD strategies for machine learning pipelines, achieving a seamless integration process that reduced integration errors by 20%.\nExecuted comprehensive testing protocols for models and APIs developed, ensuring system reliability and performance adherence to standards with over 98% uptime."
    },
    {
      "role": "Full Stack Developer",
      "company": "Sea Group",
      "from_date": "Mar 2018",
      "to_date": "Apr 2022",
      "location": "Shopee, Singapore",
      "responsibilities": "Utilized **Python** and **TensorFlow** to develop machine learning models that increased prediction accuracy by **20%**.\nImplemented **ML Ops** strategies for streamlined model deployment and monitoring, reducing model deployment time by **40%**.\nDesigned and managed data pipelines using **Apache Airflow** and **Kafka** for efficient ETL/ELT processes, improving data processing speed by **30%**.\nDeveloped and integrated LLM solutions with **LangChain** to enhance natural language processing capabilities for various applications.\nLed CI/CD initiatives leveraging **AWS** and **GCP** cloud services, resulting in a **30%** decrease in production issues.\nConducted collaborative sessions to define AI project requirements, facilitating effective communication with stakeholders.\nMentored junior data engineers in data engineering best practices, improving team collaboration and productivity metrics.\nAnalyzed and visualized data insights using **dbt** and other tools to support decision-making processes for multiple projects.\nWorked on enhancing existing data structures and frameworks to support object-oriented designs, leading to increased project flexibility.\nRegularly conducted code reviews to improve code quality and maintainability across the team."
    },
    {
      "role": "Software Developer",
      "company": "Grab Holdings Inc",
      "from_date": "Jan 2015",
      "to_date": "Feb 2018",
      "location": "Singapore",
      "responsibilities": "Leveraged **Python** and **TensorFlow** to build machine learning models, enhancing predictive analytics capabilities by **30%**.\nImplemented **AWS** services for model deployment, ensuring scalability and resilience, which reduced downtime by **15%**.\nOptimized data pipelines using **Airflow** for efficient data flow and management, decreasing processing time by **25%**.\nUtilized **Kafka** for real-time data ingestion, improving data availability and system responsiveness.\nDeveloped and executed **ETL** processes to transform raw data into actionable insights, driving decision-making across departments.\nCollaborated with cross-functional teams to align ML initiatives with business objectives, improving team collaboration and communication.\nMentored junior data engineers on best practices in **MLOps**, fostering a culture of innovation and continuous learning.\nCreated technical documentation on **dbt** workflows and data engineering methodologies, enhancing understanding among stakeholders.\nParticipated in code reviews to ensure adherence to coding standards and promote quality in development practices.\nAssisted in integrating **LangChain** into existing workflows, facilitating enhanced language model capabilities."
    }
  ],
  "skills": "**Programming Languages**\n\tPython, JavaScript, TypeScript, C#, Solidity\n\n**Backend Frameworks**\n\tNodeJS, ExpressJS, NestJS, .NET, Microservices\n\n**Frontend Frameworks**\n\tReactJS, NextJS, VueJS, NuxtJS, Angular, Material UI, Three.js, D3.js, React Native, Flutter, Chakra UI, TailwindCSS\n\n**API Technologies**\n\tRESTful API, GraphQL\n\n**Serverless and Cloud Functions**\n\tAWS, Azure, GCP\n\n**Databases**\n\tMSSQL Server, MySQL, PostgreSQL, MongoDB, DynamoDB, CosmosDB\n\n**DevOps**\n\tCI/CD pipelines\n\n**Cloud & Infrastructure**\n\tAirflow, dbt, data engineering, ETL, ELT, MLOps, Kafka\n\n**Other**\n\tMessaging & Caching: Apache Kafka, RabbitMQ, Redis, UX/UI Design, Git, GitHub, Testing Tools: NUnit, xUnit, Selenium, Moq, Postman, Cypress, JMeter, Jest, collaboration, communication, mentoring, LLM, ML, TensorFlow, PyTorch, LangChain",
  "apply_company": "aPriori Technologies"
}