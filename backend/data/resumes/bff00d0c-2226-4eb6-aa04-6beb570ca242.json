{
  "name": "Marcin Karol Kotlinski",
  "role_name": "Senior Data Engineer",
  "email": "marcinkot55@outlook.com",
  "phone": "+48 732 779 243",
  "address": "Zgorzelec, Poland",
  "linkedin": "https://www.linkedin.com/in/marcin-k-a54a89395/",
  "profile_summary": "Results-driven Senior Data Engineer with 8 years of comprehensive experience in **SQL**, **ETL**, and data visualization using tools such as **PowerBI**, **Looker**, and **Tableau**. Proficient in **data analytics** and storytelling to effectively communicate insights to stakeholders, enhancing decision-making processes. Strong expertise in using **GitHub** for version control and collaboration, alongside experience with **Airflow** for orchestrating complex data workflows. I possess deep knowledge in data engineering principles, developing scalable data pipelines, and utilizing **DBT** for transformation processes.\n\nAdditionally, I have a solid foundation in full-stack development with **JavaScript/TypeScript**, **Python**, and **Flutter**, employing frameworks such as **React**, **Next.js**, **Node.js**, and back-end solutions with **FastAPI** and **Django**. My background includes leveraging cloud services like **Azure** and **AWS**, along with experience in building enterprise-grade platforms that incorporate AI/ML capabilities. With a strong emphasis on compliance standards such as HIPAA, FHIR, PCI DSS, and SOC 2, I am well-equipped to deliver secure and high-performance data solutions.",
  "education": [
    {
      "degree": "Master’s Degree in Computer Science",
      "category": "",
      "from_year": "2017",
      "to_year": "2018",
      "location": "UK",
      "university": "University of Oxford"
    },
    {
      "degree": "Bachelor’s Degree in Computer Science",
      "category": "",
      "from_year": "2015",
      "to_year": "2017",
      "location": "UK",
      "university": "University of Oxford"
    }
  ],
  "experience": [
    {
      "role": "Senior Data Engineer",
      "company": "EVNE Developers",
      "from_date": "Oct 2023",
      "to_date": "Present",
      "location": "UK",
      "responsibilities": "- Utilized **SQL** for efficient data manipulation and extraction to enhance data analytics capabilities, ensuring accurate reporting and insights.\n- Developed interactive data visualizations using **Power BI** and **Tableau**, enabling stakeholders to derive actionable insights and drive data-driven decision-making.\n- Executed ETL processes to streamline and optimize data flow from multiple sources into centralized data storage, utilizing **Airflow** for orchestrating complex workflows.\n- Collaborated with stakeholders to gather requirements and present findings through compelling storytelling techniques, enhancing the understanding of data-driven insights.\n- Leveraged **DBT** for effective data modeling and transformation, ensuring data integrity and consistency across analytical platforms.\n- Managed code versions and collaboration through **GitHub**, applying version control best practices to maintain seamless workflows among team members.\n- Integrated third-party tools such as **Salesforce**, **Marketo**, and **Amplitude** to enrich data sets and enhance customer insights, facilitating targeted marketing strategies.\n- Conducted robust data analytics to drive business performance, measuring KPIs and operational metrics, ensuring accountability and transparency.\n- Coordinated with cross-functional teams to align data initiatives with organizational goals, fostering stakeholder management and collaboration for successful data projects."
    },
    {
      "role": "Software Engineer",
      "company": "Air Force",
      "from_date": "Oct 2021",
      "to_date": "Sep 2023",
      "location": "Poland",
      "responsibilities": "Utilized SQL to design and manage complex database queries and ETL processes for financial data ingestion and processing, ensuring data accuracy and reliability across systems.\nDeveloped data visualization solutions with **Power BI**, using analytics dashboards to present key insights, driving data-driven decision-making and stakeholder management.\nOversaw the implementation of **Airflow** for orchestrating ETL workflows, managing scheduling and dependencies for the batch and real-time processing of financial data.\nCollaborated with cross-functional teams to integrate data analytics solutions with **Tableau**, enabling effective storytelling and visualization of analytical findings to non-technical stakeholders.\nManaged version control and collaboration on code with **GitHub**, ensuring code quality and facilitating teamwork in a continuous development environment.\nDesigned and optimized ETL pipelines with **DBT**, achieving performance improvements in data transformation processes by over **30%**.\nCreated and refined robust dashboards utilizing **Amplitude** and **Looker** for insightful business metrics, providing actionable analytics to upper management within the financial domain.\nEngaged with stakeholders to ensure alignment on analytics strategy, translating business requirements into technical specifications that improve project outcomes effectively. \nImplemented best practices for data stewardship and quality checks within financial datasets, ensuring operational efficiency in a high-volume environment."
    },
    {
      "role": "Software Engineer",
      "company": "DeepInspire",
      "from_date": "Sep 2018",
      "to_date": "Aug 2021",
      "location": "UK",
      "responsibilities": "Utilized **SQL** for efficient data extraction, transformation, and loading (ETL) processes, driving data-driven insights across business functions by developing complex queries, stored procedures, and views.\nLeveraged **PowerBI**, **Tableau**, and **Looker** to create interactive data visualizations that effectively communicate analytics findings to stakeholders and enhance decision-making processes.\nStreamlined data workflows using **Airflow** to orchestrate ETL tasks, ensuring reliable data pipelines and timely delivery of analytics for operational and strategic use.\nCollaborated with cross-functional teams to identify KPIs and utilize **Amplitude** for product analytics, fostering stakeholder engagement through effective storytelling with data.\nManaged version control and collaboration on data projects using **GitHub**, ensuring maintainability and consistency across all data initiatives.\nImplemented **DBT** for data modeling, enabling robust and tested transformations in our analytics environment, fostering a culture of data quality and accuracy.\nEngaged in stakeholder management through regular updates and insights sharing, demonstrating the value of analytics solutions and enhancing business intelligence across the organization.\nConducted data analysis and reporting using **Salesforce** and **Marketo** for marketing insights, aligning data initiatives with marketing strategies to drive performance improvements.\nEnhanced data pipelines and visualizations, contributing to an analytics culture that empowers teams with insights for strategic decision-making."
    }
  ],
  "skills": "**Programming Languages:**\n\tPython, JavaScript, TypeScript\n\n**Backend Frameworks:**\n\tFastAPI, Flask, Django\n\n**Frontend Frameworks:**\n\tReact, Vue, Angular\n\n**API Technologies:**\n\tNginx, Keycloak (OIDC, RBAC), JWT, OAuth2, Let’s Encrypt\n\n**Serverless and Cloud Functions:**\n\tAWS (Lambda, ECS), Azure (App Services)\n\n**Databases:**\n\tPostgreSQL, MySQL, MongoDB, Redis, SQL\n\n**DevOps:**\n\tDocker, Kubernetes, GitHub Actions, GitLab CI/CD, Terraform, Ansible, Helm, Docker Compose\n\n**Cloud & Infrastructure:**\n\tAWS (RDS, S3), Azure (Blob, SQL)\n\n**Other:**\n\tMLflow, Airflow, Kubeflow, ETL, Data Visualization, Data Analytics, Stakeholder Management, Storytelling, Amplitude, Salesforce, Marketo, PowerBI, Looker, Tableau, DBT",
  "apply_company": "Autodesk"
}